Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'nbc'], random_seed=2, runner='mcts_clustered', save_batch=False, skip_layers=[0, 5], tc1=<function tc1 at 0x7f02bb968f28>, tc2=<function tc2 at 0x7f02bb97a048>, tc3=<function tc3 at 0x7f02bb97a158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 9.50704
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0220786f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 9.507042253521126
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3514f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f020678c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3462860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3462080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5d30> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 9.507042253521126
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3514f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3462cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f022077f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 0.7042253521126778 5
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3462588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 0.7042253521126778 6
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5588> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 1.4084507042253556 7
Completed Iteration #11
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 1.4084507042253556 8
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5780> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 1.7605633802816936 5
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 1.7605633802816936 9
Completed Iteration #16
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e3462f60> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5828> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5780> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 2.4647887323943714 6
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 2.4647887323943714 10
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e34852e8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 2.8169014084507094 7
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 2.8169014084507094 11
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e3485630> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5828> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5780> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 3.1690140845070474 8
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 3.1690140845070474 12
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5cf8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5828> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5780> 1.7605633802816918 5
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 3.5211267605633854 9
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 3.5211267605633854 13
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 3.5211267605633854 10
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 3.5211267605633854 14
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e34a05c0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5828> 1.7605633802816918 5
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5780> 2.11267605633803 6
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 3.8732394366197234 11
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 3.8732394366197234 15
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e3485f28> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485ac8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462588> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 4.225352112676061 12
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 4.225352112676061 16
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e34624a8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 4.929577464788739 13
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 4.929577464788739 17
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9668> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 5.633802816901417 14
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 5.633802816901417 18
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
coverage_call_count 100
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 5.633802816901417 15
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 5.633802816901417 19
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7908> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 6.338028169014095 16
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 6.338028169014095 20
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7fd0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 7.0422535211267725 17
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 7.0422535211267725 21
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 3.521126760563389 6
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 7.74647887323945 18
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 7.74647887323945 22
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 3.521126760563389 6
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 4.225352112676067 7
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 8.450704225352128 19
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 8.450704225352128 23
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef908> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6d8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 4.577464788732405 8
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 8.802816901408466 20
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 8.802816901408466 24
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e26eff28> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26efcf8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5588> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 3.873239436619727 7
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 4.929577464788743 9
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 9.154929577464804 21
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 9.154929577464804 25
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e26e12e8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6d8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 5.281690140845081 10
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 9.507042253521142 22
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 9.507042253521142 26
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 3.873239436619727 8
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 5.281690140845081 11
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 9.507042253521142 23
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 9.507042253521142 27
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #2
root->8->8
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26e15f8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26efcf8> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5588> 1.7605633802816936 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 4.577464788732405 9
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 5.9859154929577585 12
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 10.21126760563382 24
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 10.21126760563382 28
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef630> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef940> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26eff28> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26efcf8> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5588> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 4.929577464788743 10
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 6.3380281690140965 13
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 10.563380281690158 25
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 10.563380281690158 29
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #3
root->8->8->8
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc6d8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc7f0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 5.6338028169014205 11
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 7.042253521126774 14
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 11.267605633802836 26
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 11.267605633802836 30
Completed Iteration #5
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26ccc88> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 6.338028169014098 12
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 7.746478873239452 15
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 11.971830985915513 27
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 11.971830985915513 31
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad160> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267eda0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ccc88> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 2.4647887323943714 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 3.169014084507049 6
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 6.690140845070436 13
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 8.09859154929579 16
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 12.323943661971851 28
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 12.323943661971851 32
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad908> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 3.169014084507049 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 3.873239436619727 7
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 7.394366197183114 14
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 8.802816901408468 17
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 13.02816901408453 29
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 13.02816901408453 33
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7a20> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26efd68> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 4.225352112676065 8
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 7.746478873239452 15
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 9.154929577464806 18
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 13.380281690140867 30
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 13.380281690140867 34
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7fd0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26efd68> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 4.929577464788743 9
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 8.45070422535213 16
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 9.859154929577484 19
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 14.084507042253545 31
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 14.084507042253545 35
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #4
root->8->8->8->6
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9c18> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 3.873239436619727 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 5.6338028169014205 10
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 9.154929577464808 17
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 10.563380281690161 20
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 14.788732394366223 32
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 14.788732394366223 36
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26d77b8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1a90> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad908> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 4.577464788732405 8
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 6.338028169014098 11
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 9.859154929577485 18
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 11.26760563380284 21
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 15.4929577464789 33
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 15.4929577464789 37
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26ccac8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc898> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc6d8> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc7f0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 3.521126760563389 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 5.2816901408450825 9
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 7.042253521126776 12
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 10.563380281690163 19
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 11.971830985915517 22
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 16.19718309859158 34
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 16.19718309859158 38
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26c97f0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 5.98591549295776 10
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 7.746478873239454 13
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 11.267605633802841 20
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 12.676056338028195 23
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 16.90140845070426 35
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 16.90140845070426 39
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad208> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc7f0> 1.7605633802816936 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 3.873239436619727 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 6.338028169014098 11
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 8.098591549295792 14
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 11.619718309859179 21
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 13.028169014084533 24
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 17.253521126760596 36
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 17.253521126760596 40
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad198> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 4.577464788732405 8
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 7.042253521126776 12
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 8.80281690140847 15
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 12.323943661971857 22
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 13.73239436619721 25
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 17.957746478873275 37
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 17.957746478873275 41
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e263e2b0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e3c8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ccc88> 1.7605633802816936 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 7.746478873239454 13
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 9.507042253521147 16
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 13.028169014084535 23
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 14.436619718309888 26
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 18.661971830985955 38
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 18.661971830985955 42
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e263eac8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1a90> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad908> 1.7605633802816936 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 2.4647887323943714 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 4.929577464788743 9
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 8.098591549295792 14
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 9.859154929577485 17
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 13.380281690140873 24
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 14.788732394366226 27
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 19.01408450704229 39
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 19.01408450704229 43
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26601d0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 8.80281690140847 15
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 10.563380281690163 18
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 14.08450704225355 25
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 15.492957746478904 28
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 19.71830985915497 40
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 19.71830985915497 44
Completed Iteration #22
Best Reward: 0.7042253521126778
coverage_call_count 200
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e3485d30> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 9.507042253521147 16
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 11.267605633802841 19
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 14.788732394366228 26
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 16.19718309859158 29
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 20.42253521126765 41
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 20.42253521126765 45
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #5
root->8->8->8->6->8
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7710> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7b38> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad198> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 2.8169014084507094 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 5.281690140845081 10
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 9.859154929577485 17
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 11.619718309859179 20
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 15.140845070422566 27
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 16.549295774647916 30
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 20.774647887323987 42
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 20.774647887323987 46
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5f8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7b38> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad198> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 3.1690140845070474 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 5.633802816901419 11
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 10.211267605633823 18
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 11.971830985915517 21
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 15.492957746478904 28
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 16.901408450704253 31
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 21.126760563380323 43
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 21.126760563380323 47
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e2660208> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 3.873239436619725 8
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 6.3380281690140965 12
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 10.915492957746501 19
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 12.676056338028195 22
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 16.19718309859158 29
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 17.605633802816932 32
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 21.830985915493002 44
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 21.830985915493002 48
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e263e8d0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc7f0> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 6.6901408450704345 13
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 11.26760563380284 20
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 13.028169014084533 23
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 16.549295774647916 30
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 17.95774647887327 33
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 22.18309859154934 45
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 22.18309859154934 49
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e2600908> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660fd0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26d77b8> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1a90> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad908> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 4.225352112676063 9
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 7.0422535211267725 14
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 11.619718309859177 21
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 13.38028169014087 24
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 16.901408450704253 31
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 18.309859154929605 34
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 22.535211267605675 46
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 22.535211267605675 50
Completed Iteration #23
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e2600ef0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d30> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad208> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc7f0> 2.4647887323943696 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 7.3943661971831105 15
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 11.971830985915515 22
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 13.732394366197209 25
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 17.25352112676059 32
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 18.66197183098594 35
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 22.88732394366201 47
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 22.88732394366201 51
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #6
root->8->8->8->6->8->2
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e260c8d0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c5c0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5f8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7b38> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad198> 1.7605633802816918 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 4.577464788732401 10
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 7.7464788732394485 16
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 12.323943661971853 23
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 14.084507042253547 26
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 17.605633802816925 33
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 19.014084507042277 36
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 23.239436619718347 48
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 23.239436619718347 52
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9208> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1a90> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad908> 2.8169014084507094 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 5.281690140845079 11
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 8.450704225352126 17
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 13.028169014084531 24
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 14.788732394366225 27
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 18.309859154929605 34
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 19.718309859154957 37
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 23.943661971831027 49
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 23.943661971831027 53
Completed Iteration #3
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef828> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1a90> 2.8169014084507094 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad908> 3.521126760563387 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 5.985915492957757 12
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 9.154929577464804 18
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 13.732394366197209 25
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 15.492957746478902 28
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 19.014084507042284 35
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 20.422535211267636 38
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 24.647887323943706 50
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 24.647887323943706 54
Completed Iteration #4
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e263ef28> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7b38> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad198> 2.11267605633803 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 6.338028169014095 13
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 9.507042253521142 19
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 14.084507042253547 26
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 15.84507042253524 29
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 19.36619718309862 36
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 20.774647887323972 39
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 25.000000000000043 51
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 25.000000000000043 55
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e2600390> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 7.0422535211267725 14
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 10.21126760563382 20
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 14.788732394366225 27
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 16.549295774647916 30
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 20.0704225352113 37
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 21.478873239436652 40
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 25.704225352112722 52
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 25.704225352112722 56
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e263e080> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 7.74647887323945 15
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 10.915492957746498 21
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 15.492957746478902 28
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 17.253521126760596 31
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 20.77464788732398 38
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 22.18309859154933 41
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 26.4084507042254 53
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 26.4084507042254 57
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ccda0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad198> 2.464788732394368 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 8.098591549295788 16
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 11.267605633802836 22
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 15.84507042253524 29
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 17.605633802816932 32
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 21.126760563380316 39
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 22.535211267605668 42
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 26.760563380281738 54
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 26.760563380281738 58
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e260c550> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1a90> 3.521126760563387 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad908> 4.225352112676065 8
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 8.802816901408466 17
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 11.971830985915513 23
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 16.549295774647916 30
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 18.30985915492961 33
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 21.830985915492995 40
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 23.239436619718347 43
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 27.464788732394418 55
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 27.464788732394418 59
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e26281d0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260cfd0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600390> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 9.154929577464804 18
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 12.323943661971851 24
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 16.901408450704253 31
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 18.661971830985948 34
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 22.18309859154933 41
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 23.591549295774684 44
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 27.816901408450754 56
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 27.816901408450754 60
Completed Iteration #19
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e26ade80> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7b38> 2.11267605633803 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad198> 3.1690140845070456 8
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 9.859154929577482 19
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 13.02816901408453 25
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 17.605633802816932 32
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 19.366197183098627 35
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 22.88732394366201 42
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 24.295774647887363 45
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 28.521126760563433 57
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 28.521126760563433 61
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01e263e4e0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 10.56338028169016 20
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 13.732394366197207 26
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 18.30985915492961 33
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 20.070422535211307 36
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 23.59154929577469 43
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 25.000000000000043 46
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 29.225352112676113 58
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 29.225352112676113 62
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #7
root->8->8->8->6->8->2->8
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad9b0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660fd0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26d77b8> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1a90> 3.873239436619725 8
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad908> 4.577464788732403 9
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 10.915492957746498 21
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 14.084507042253545 27
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 18.661971830985948 34
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 20.422535211267643 37
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 23.943661971831027 44
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 25.35211267605638 47
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 29.57746478873245 59
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 29.57746478873245 63
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e2660860> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263ec18> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef828> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1a90> 4.225352112676063 9
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad908> 4.929577464788741 10
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 11.267605633802836 22
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 14.436619718309883 28
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 19.014084507042284 35
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 20.77464788732398 38
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 24.295774647887363 45
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 25.704225352112715 48
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 29.929577464788785 60
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 29.929577464788785 64
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e2628828> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628630> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad908> 5.281690140845079 11
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 11.619718309859174 23
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 14.788732394366221 29
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 19.36619718309862 36
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 21.126760563380316 39
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 24.6478873239437 46
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 26.05633802816905 49
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 30.28169014084512 61
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 30.28169014084512 65
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628630> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad908> 5.633802816901417 12
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada20> 11.971830985915512 24
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 15.140845070422559 30
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1b70> 19.718309859154957 37
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1240> 21.478873239436652 40
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5e10> 25.000000000000036 47
backprop <src.mcts.MCTS_Node object at 0x7f01e34622e8> 26.408450704225388 50
backprop <src.mcts.MCTS_Node object at 0x7f01e3462438> 30.633802816901458 62
backprop <src.mcts.MCTS_Node object at 0x7f01e3485518> 30.633802816901458 66
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #8
root->8->8->8->6->8->2->8->2
Best Reward: 0.7042253521126778
iteration: 2
found coverage increase 0.7042253521126778
Current Total Coverage 10.211267605633804
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2660550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2660630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ccc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ccc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3485b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2637400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2637518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26376a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2637198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26379e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637ac8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3485898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c09e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c09e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d33c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ade10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b84e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d02540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad978> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d02542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02622e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d02629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0262898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d02780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02622e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d02544a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0278828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0278ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0278748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d02784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0278f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d02783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0278080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d02629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d02629e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02548d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02549b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0278cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d02542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b88d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02549b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0278e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2637da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25d34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d34a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2584588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad710> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2637400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0262438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0262438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3b00> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01eafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01eaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eaeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eaeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9828> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25841d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25841d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ada58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eaef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2600c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea5f8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2600a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2600cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26007b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2600e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260c860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2600668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2600d68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e267e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e267e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e267e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26e19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 8
Completed Iteration #6
Best Reward: 0
coverage_call_count 600
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e267e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26e10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2600be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e267e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e267e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2600390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2600c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2600400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26adef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26adcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26adcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e260cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267eba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26d74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26d72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e17b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9518> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 10.211267605633804
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5940> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 0.3521126760563362 4
Completed Iteration #5
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f022077f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 0.3521126760563362 5
Completed Iteration #6
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 0.3521126760563362 6
Completed Iteration #7
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e3462a90> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 0.7042253521126725 7
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3462668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 0.7042253521126725 8
Completed Iteration #9
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e3462f60> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.0563380281690087 9
Completed Iteration #10
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.0563380281690087 10
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3462b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5940> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.0563380281690087 11
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3462518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462f60> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 1.0563380281690087 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.0563380281690087 12
Completed Iteration #13
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d020e2b0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.408450704225345 13
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.408450704225345 14
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.408450704225345 15
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.408450704225345 16
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0240079748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.408450704225345 17
Completed Iteration #19
Best Reward: 0.3521126760563362
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3d30> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462cc0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5940> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 1.7605633802816811 9
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.7605633802816811 18
Completed Iteration #21
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.7605633802816811 19
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 1.7605633802816811 10
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.7605633802816811 20
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 1.7605633802816811 11
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 1.7605633802816811 21
Completed Iteration #0
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f022077f358> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 2.1126760563380174 12
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 2.1126760563380174 22
Completed Iteration #1
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d57b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5940> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 2.4647887323943536 13
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 2.4647887323943536 23
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3462748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f022077f358> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 2.4647887323943536 14
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 2.4647887323943536 24
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e3514eb8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 2.81690140845069 15
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 2.81690140845069 25
Completed Iteration #4
Best Reward: 0.3521126760563362
coverage_call_count 700
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d020eef0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020e4a8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3514eb8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 3.169014084507026 16
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 3.169014084507026 26
Completed Iteration #5
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462f60> 0.3521126760563362 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 3.169014084507026 17
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 3.169014084507026 27
Completed Iteration #6
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3e10> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 3.5211267605633623 18
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 3.5211267605633623 28
Completed Iteration #7
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3550> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3c88> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5940> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 3.8732394366196985 19
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 3.8732394366196985 29
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.225352112676035 20
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.225352112676035 30
Completed Iteration #9
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3e10> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.225352112676035 21
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.225352112676035 31
Completed Iteration #10
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462f60> 0.3521126760563362 5
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.225352112676035 22
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.225352112676035 32
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3514eb8> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.225352112676035 23
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.225352112676035 33
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3630> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.577464788732371 24
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.577464788732371 34
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f022077f358> 0.3521126760563362 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.577464788732371 25
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.577464788732371 35
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462a90> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.577464788732371 26
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.577464788732371 36
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d020e6d8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3fd0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3e10> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.929577464788707 27
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.929577464788707 37
Completed Iteration #17
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3462208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.929577464788707 28
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.929577464788707 38
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26c91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462f60> 0.3521126760563362 6
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.929577464788707 29
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.929577464788707 39
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020e2b0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.929577464788707 30
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.929577464788707 40
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020e4a8> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01e3514eb8> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.929577464788707 31
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.929577464788707 41
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.929577464788707 32
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.929577464788707 42
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.929577464788707 33
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.929577464788707 43
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 0.3521126760563362 4
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 0.7042253521126725 6
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 4.929577464788707 34
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 4.929577464788707 44
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 1.0563380281690087 7
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 5.281690140845043 35
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 5.281690140845043 45
Completed Iteration #4
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 1.0563380281690087 8
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 5.281690140845043 36
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 5.281690140845043 46
Completed Iteration #5
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 1.0563380281690087 9
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 5.281690140845043 37
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 5.281690140845043 47
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3438> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 1.0563380281690087 6
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 1.408450704225345 10
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 5.63380281690138 38
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 5.63380281690138 48
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2584e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 1.0563380281690087 7
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 1.408450704225345 11
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 5.63380281690138 39
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 5.63380281690138 49
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e2584240> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25848d0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 1.7605633802816811 12
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 5.985915492957716 40
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 5.985915492957716 50
Completed Iteration #13
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad7b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263ef28> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3438> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 2.1126760563380174 13
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 6.338028169014052 41
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 6.338028169014052 51
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e263e550> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 1.7605633802816811 9
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 2.4647887323943536 14
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 6.690140845070388 42
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 6.690140845070388 52
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 2.4647887323943536 15
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 6.690140845070388 43
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 6.690140845070388 53
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2600b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 2.4647887323943536 16
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 6.690140845070388 44
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 6.690140845070388 54
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 2.4647887323943536 17
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 6.690140845070388 45
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 6.690140845070388 55
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0278> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0f28> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 2.81690140845069 18
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 7.0422535211267245 46
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 7.0422535211267245 56
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2600cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25848d0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 2.81690140845069 19
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 7.0422535211267245 47
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 7.0422535211267245 57
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 2.1126760563380174 10
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 3.169014084507026 20
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 7.394366197183061 48
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 7.394366197183061 58
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #2
root->0->4
Best Reward: 0.3521126760563362
Completed Iteration #0
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 2.1126760563380174 11
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 3.169014084507026 21
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 7.394366197183061 49
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 7.394366197183061 59
Completed Iteration #1
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e260c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 2.1126760563380174 12
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 3.169014084507026 22
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 7.394366197183061 50
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 7.394366197183061 60
Completed Iteration #2
Best Reward: 0.3521126760563362
Completed Iteration #3
Best Reward: 0.3521126760563362
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 2.1126760563380174 13
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 3.169014084507026 23
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 7.394366197183061 51
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 7.394366197183061 61
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e2637080> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0860> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3630> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 2.4647887323943536 14
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 3.5211267605633623 24
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 7.746478873239397 52
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 7.746478873239397 62
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d020e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0860> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3630> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 2.4647887323943536 15
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 3.5211267605633623 25
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 7.746478873239397 53
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 7.746478873239397 63
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26373c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 2.4647887323943536 16
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 3.5211267605633623 26
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 7.746478873239397 54
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 7.746478873239397 64
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0240> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad710> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e550> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 2.81690140845069 17
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 3.8732394366196985 27
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 8.098591549295733 55
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 8.098591549295733 65
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0860> 0.3521126760563362 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3630> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 2.81690140845069 18
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 3.8732394366196985 28
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 8.098591549295733 56
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 8.098591549295733 66
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0438> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3588> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3630> 1.0563380281690087 6
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 3.169014084507026 19
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 4.225352112676035 29
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 8.45070422535207 57
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 8.45070422535207 67
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e2637550> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0470> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0438> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3588> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3630> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 3.5211267605633623 20
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 4.577464788732371 30
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 8.802816901408406 58
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 8.802816901408406 68
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #3
root->0->4->2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad128> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 3.8732394366196985 21
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 4.929577464788707 31
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 9.154929577464742 59
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 9.154929577464742 69
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d0278f60> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad128> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 4.225352112676035 22
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 5.281690140845043 32
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 9.507042253521078 60
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 9.507042253521078 70
Completed Iteration #3
Best Reward: 0.3521126760563362
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3208> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 1.7605633802816811 6
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 4.577464788732371 23
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 5.63380281690138 33
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 9.859154929577414 61
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 9.859154929577414 71
Completed Iteration #8
Best Reward: 0.3521126760563362
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Completed Iteration #12
Best Reward: 0.3521126760563362
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e263e748> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 1.7605633802816811 6
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 4.929577464788707 24
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 5.985915492957716 34
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 10.21126760563375 62
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 10.21126760563375 72
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e25adc88> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600198> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 2.4647887323943536 8
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 5.281690140845043 25
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 6.338028169014052 35
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 10.563380281690087 63
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 10.563380281690087 73
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d02788d0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2600198> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 5.63380281690138 26
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 6.690140845070388 36
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 10.915492957746423 64
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 10.915492957746423 74
Completed Iteration #20
Best Reward: 0.3521126760563362
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d0278cc0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278b38> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25adc88> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2600198> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 3.169014084507026 10
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 5.985915492957716 27
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 7.0422535211267245 37
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 11.26760563380276 65
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 11.26760563380276 75
Completed Iteration #23
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e2628f98> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 3.5211267605633623 11
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 6.338028169014052 28
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 7.394366197183061 38
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 11.619718309859095 66
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 11.619718309859095 76
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #4
root->0->4->2->5
Best Reward: 0.3521126760563362
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26efba8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 2.4647887323943536 8
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 3.8732394366196985 12
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 6.690140845070388 29
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 7.746478873239397 39
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 11.971830985915432 67
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 11.971830985915432 77
Completed Iteration #3
Best Reward: 0.3521126760563362
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
coverage_call_count 800
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef160> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26efba8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 4.225352112676035 13
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 7.0422535211267245 30
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 8.098591549295733 40
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 12.323943661971768 68
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 12.323943661971768 78
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5e48> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 3.169014084507026 10
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 4.577464788732371 14
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 7.394366197183061 31
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 8.45070422535207 41
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 12.676056338028104 69
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 12.676056338028104 79
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5748> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 3.5211267605633623 11
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 4.929577464788707 15
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 7.746478873239397 32
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 8.802816901408406 42
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 13.02816901408444 70
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 13.02816901408444 80
Completed Iteration #12
Best Reward: 0.3521126760563362
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e2637898> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26d74a8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef160> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26efba8> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 3.8732394366196985 12
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 5.281690140845043 16
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 8.098591549295733 33
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 9.154929577464742 43
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 13.380281690140777 71
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 13.380281690140777 81
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Completed Iteration #20
Best Reward: 0.3521126760563362
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26287f0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad128> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 4.225352112676035 13
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 5.63380281690138 17
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 8.45070422535207 34
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 9.507042253521078 44
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 13.732394366197113 72
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 13.732394366197113 82
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #5
root->0->4->2->5->2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e2628b38> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628a90> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628f98> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 4.577464788732371 14
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 5.985915492957716 18
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 8.802816901408406 35
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 9.859154929577414 45
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 14.084507042253449 73
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 14.084507042253449 83
Completed Iteration #0
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 4.577464788732371 15
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 5.985915492957716 19
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 8.802816901408406 36
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 9.859154929577414 46
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 14.084507042253449 74
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 14.084507042253449 84
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef828> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 4.929577464788707 16
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 6.338028169014052 20
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 9.154929577464742 37
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 10.21126760563375 47
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 14.436619718309785 75
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 14.436619718309785 85
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5080> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5390> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5748> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 5.281690140845043 17
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 6.690140845070388 21
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 9.507042253521078 38
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 10.563380281690087 48
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 14.788732394366122 76
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 14.788732394366122 86
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 2.4647887323943536 9
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 5.63380281690138 18
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 7.0422535211267245 22
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 9.859154929577414 39
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 10.915492957746423 49
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 15.140845070422458 77
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 15.140845070422458 87
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e3485dd8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485940> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 2.4647887323943536 9
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 2.81690140845069 10
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 5.985915492957716 19
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 7.394366197183061 23
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 10.21126760563375 40
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 11.26760563380276 50
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 15.492957746478794 78
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 15.492957746478794 88
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Completed Iteration #20
Best Reward: 0.3521126760563362
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e2637a20> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485940> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 2.81690140845069 10
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 3.169014084507026 11
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 6.338028169014052 20
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 7.746478873239397 24
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 10.563380281690087 41
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 11.619718309859095 51
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 15.84507042253513 79
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 15.84507042253513 89
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 3.169014084507026 12
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 6.338028169014052 21
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 7.746478873239397 25
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 10.563380281690087 42
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 11.619718309859095 52
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 15.84507042253513 80
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 15.84507042253513 90
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #6
root->0->4->2->5->2->2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7c18> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7518> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 3.169014084507026 11
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 3.5211267605633623 13
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 6.690140845070388 22
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 8.098591549295733 26
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 10.915492957746423 43
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 11.971830985915432 53
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 16.197183098591466 81
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 16.197183098591466 91
Completed Iteration #0
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5470> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 3.5211267605633623 12
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 3.8732394366196985 14
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 7.0422535211267245 23
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 8.45070422535207 27
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 11.26760563380276 44
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 12.323943661971768 54
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 16.549295774647803 82
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 16.549295774647803 92
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Completed Iteration #3
Best Reward: 0.3521126760563362
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e34859e8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485588> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5748> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 3.8732394366196985 13
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 4.225352112676035 15
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 7.394366197183061 24
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 8.802816901408406 28
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 11.619718309859095 45
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 12.676056338028104 55
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 16.90140845070414 83
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 16.90140845070414 93
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Completed Iteration #12
Best Reward: 0.3521126760563362
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc5f8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 4.225352112676035 14
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 4.577464788732371 16
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 7.746478873239397 25
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 9.154929577464742 29
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 11.971830985915432 46
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 13.02816901408444 56
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 17.253521126760475 84
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 17.253521126760475 94
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc2b0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485940> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 1.7605633802816811 6
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 4.577464788732371 15
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 4.929577464788707 17
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 8.098591549295733 26
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 9.507042253521078 30
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 12.323943661971768 47
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 13.380281690140777 57
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 17.60563380281681 85
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 17.60563380281681 95
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc208> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0262668> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc5f8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 4.929577464788707 16
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 5.281690140845043 18
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 8.45070422535207 27
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 9.859154929577414 31
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 12.676056338028104 48
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 13.732394366197113 58
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 17.957746478873148 86
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 17.957746478873148 96
Completed Iteration #20
Best Reward: 0.3521126760563362
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26eff60> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5668> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc5f8> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 5.281690140845043 17
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 5.63380281690138 19
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 8.802816901408406 28
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 10.21126760563375 32
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 13.02816901408444 49
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 14.084507042253449 59
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 18.309859154929484 87
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 18.309859154929484 97
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #7
root->0->4->2->5->2->2->2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e3485e80> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34855f8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 5.63380281690138 18
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 5.985915492957716 20
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 9.154929577464742 29
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 10.563380281690087 33
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 13.380281690140777 50
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 14.436619718309785 60
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 18.66197183098582 88
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 18.66197183098582 98
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e3485be0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7518> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 2.4647887323943536 8
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 5.985915492957716 19
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 6.338028169014052 21
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 9.507042253521078 30
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 10.915492957746423 34
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 13.732394366197113 51
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 14.788732394366122 61
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 19.014084507042156 89
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 19.014084507042156 99
Completed Iteration #3
Best Reward: 0.3521126760563362
Completed Iteration #4
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc828> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34855f8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 6.338028169014052 20
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 6.690140845070388 22
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 9.859154929577414 31
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 11.26760563380276 35
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 14.084507042253449 52
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 15.140845070422458 62
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 19.366197183098492 90
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 19.366197183098492 100
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8400> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485940> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 3.169014084507026 10
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 6.690140845070388 21
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 7.0422535211267245 23
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 10.21126760563375 32
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 11.619718309859095 36
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 14.436619718309785 53
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 15.492957746478794 63
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 19.71830985915483 91
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 19.71830985915483 101
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8f28> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8c50> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485e80> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34855f8> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 3.5211267605633623 11
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 7.0422535211267245 22
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 7.394366197183061 24
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 10.563380281690087 33
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 11.971830985915432 37
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 14.788732394366122 54
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 15.84507042253513 64
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 20.070422535211165 92
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 20.070422535211165 102
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d0262320> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485940> 1.7605633802816811 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 3.8732394366196985 12
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 7.394366197183061 23
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 7.746478873239397 25
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 10.915492957746423 34
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 12.323943661971768 38
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 15.140845070422458 55
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 16.197183098591466 65
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 20.4225352112675 93
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 20.4225352112675 103
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d0254ba8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02545f8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 4.225352112676035 13
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 7.746478873239397 24
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 8.098591549295733 26
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 11.26760563380276 35
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 12.676056338028104 39
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 15.492957746478794 56
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 16.549295774647803 66
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 20.774647887323837 94
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 20.774647887323837 104
Completed Iteration #20
Best Reward: 0.3521126760563362
Completed Iteration #21
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e2637278> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485940> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 4.577464788732371 14
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 8.098591549295733 25
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 8.45070422535207 27
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 11.619718309859095 36
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 13.02816901408444 40
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 15.84507042253513 57
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 16.90140845070414 67
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 21.126760563380174 95
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 21.126760563380174 105
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc630> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02621d0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc828> 1.0563380281690105 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34855f8> 1.760563380281683 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 5.281690140845045 15
backprop <src.mcts.MCTS_Node object at 0x7f01e2637d30> 8.802816901408407 26
backprop <src.mcts.MCTS_Node object at 0x7f01e26377b8> 9.154929577464744 28
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 12.32394366197177 37
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec88> 13.732394366197115 41
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3d68> 16.549295774647803 58
backprop <src.mcts.MCTS_Node object at 0x7f01e3462da0> 17.60563380281681 68
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 21.830985915492846 96
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9860> 21.830985915492846 106
Completed Iteration #24
Best Reward: 0.7042253521126742
Completed Iteration #25
Best Reward: 0.7042253521126742
Completed MCTS Level/Depth: #8
root->0->4->2->5->2->2->2->4
Best Reward: 0.7042253521126742
iteration: 18
found coverage increase 0.7042253521126742
Current Total Coverage 10.915492957746478
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3485438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0262400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d02545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0262400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0262400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0262128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ada58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ada58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d02549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0262400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628fd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 10.915492957746478
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26b72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2660588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00485f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26608d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26608d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26608d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 10.915492957746478
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00644e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00648d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00779e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00644e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 10.915492957746478
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00123c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00200b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00202e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00125c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00202e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0020198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00202e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00205c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0020860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00202e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0020a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048978> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 10.915492957746478
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00649e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d02627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00648d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f022077f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00649e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00648d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f01d0077d30> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 10.915492957746478
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0020780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0020748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0020550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0020dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0020550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00201d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0020240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0020dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcdd8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 10.915492957746478
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0020ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01d0064940> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3fd0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 0.3521126760563398 5
Completed Iteration #4
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87d83c8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3fd0> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 0.7042253521126796 6
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 0.7042253521126796 7
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8cc0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3fd0> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 1.0563380281690193 8
Completed Iteration #9
Best Reward: 0.3521126760563398
Completed Iteration #10
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d83c8> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3fd0> 1.0563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 1.0563380281690193 9
Completed Iteration #11
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4278> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 1.4084507042253591 10
Completed Iteration #12
Best Reward: 0.3521126760563398
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 1.4084507042253591 11
Completed Iteration #15
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 1.760563380281699 12
Completed Iteration #16
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4e48> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 2.1126760563380387 13
Completed Iteration #17
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 2.4647887323943785 14
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4278> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 1.4084507042253591 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 2.4647887323943785 15
Completed Iteration #21
Best Reward: 0.3521126760563398
Completed Iteration #22
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3fd0> 1.0563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 2.4647887323943785 16
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0e48> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0dd8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d83c8> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3fd0> 1.4084507042253591 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 2.8169014084507182 17
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3521126760563398
Completed Iteration #0
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0588> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 1.760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 3.169014084507058 18
Completed Iteration #1
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c877d390> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 2.1126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 3.521126760563398 19
Completed Iteration #2
Best Reward: 0.3521126760563398
Completed Iteration #3
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c877da20> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d7f0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4278> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 2.4647887323943785 9
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 3.8732394366197376 20
Completed Iteration #4
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3c50> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077208> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0588> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 2.8169014084507182 10
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 4.225352112676077 21
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8f98> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 3.169014084507058 11
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 4.577464788732417 22
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4400> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 3.521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 4.929577464788757 23
Completed Iteration #10
Best Reward: 0.3521126760563398
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d7f0> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4278> 0.7042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 3.521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 4.929577464788757 24
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8668> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d7f0> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4278> 1.0563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 3.8732394366197376 14
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 5.281690140845097 25
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Completed Iteration #22
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcf98> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 4.225352112676077 15
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 5.6338028169014365 26
Completed Iteration #23
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3128> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcc18> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8668> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c877d7f0> 1.0563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4278> 1.4084507042253591 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 4.577464788732417 16
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 5.985915492957776 27
Completed Iteration #24
Best Reward: 0.3521126760563398
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc2e8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b77b8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 4.929577464788757 17
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 6.338028169014116 28
Completed Iteration #0
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01d0012a90> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0020f98> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 1.760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 5.281690140845097 18
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 6.690140845070456 29
Completed Iteration #1
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc4a8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 1.760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 2.1126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 5.6338028169014365 19
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 7.042253521126796 30
Completed Iteration #2
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 2.1126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 5.6338028169014365 20
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 7.042253521126796 31
Completed Iteration #3
Best Reward: 0.3521126760563398
coverage_call_count 1100
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01d00644e0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 2.1126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 2.4647887323943785 9
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 5.985915492957776 21
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 7.394366197183135 32
Completed Iteration #4
Best Reward: 0.3521126760563398
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c877d1d0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00485f8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 2.8169014084507182 10
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 6.338028169014116 22
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 7.746478873239475 33
Completed Iteration #10
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c877dba8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00771d0> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 3.169014084507058 11
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 6.690140845070456 23
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 8.098591549295815 34
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Completed Iteration #13
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87a12b0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 2.4647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 3.521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 7.042253521126796 24
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 8.450704225352155 35
Completed Iteration #14
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c877dda0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1438> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877dba8> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01d00771d0> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 3.8732394366197376 13
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 7.394366197183135 25
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 8.802816901408494 36
Completed Iteration #15
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1438> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c877dba8> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f01d00771d0> 0.7042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 3.8732394366197376 14
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 7.394366197183135 26
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 8.802816901408494 37
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4a90> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00485f8> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 4.225352112676077 15
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 7.746478873239475 27
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 9.154929577464834 38
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00771d0> 0.7042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 4.225352112676077 16
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 7.746478873239475 28
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 9.154929577464834 39
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Completed Iteration #22
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00485f8> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 4.225352112676077 17
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 7.746478873239475 29
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 9.154929577464834 40
Completed Iteration #23
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 2.8169014084507182 9
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 4.577464788732417 18
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 8.098591549295815 30
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 9.507042253521174 41
Completed Iteration #24
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00485f8> 0.7042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 4.577464788732417 19
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 8.098591549295815 31
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 9.507042253521174 42
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #2
root->8->12
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 3.169014084507058 10
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 4.929577464788757 20
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 8.450704225352155 32
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 9.859154929577514 43
Completed Iteration #0
Best Reward: 0.3521126760563398
Completed Iteration #1
Best Reward: 0.3521126760563398
Completed Iteration #2
Best Reward: 0.3521126760563398
Completed Iteration #3
Best Reward: 0.3521126760563398
Completed Iteration #4
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01d00484a8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 3.521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 5.281690140845097 21
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 8.802816901408494 33
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 10.211267605633854 44
Completed Iteration #5
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877dd30> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a12b0> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 3.8732394366197376 12
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 5.6338028169014365 22
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 9.154929577464834 34
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 10.563380281690193 45
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Completed Iteration #10
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00484a8> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 3.8732394366197376 13
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 5.6338028169014365 23
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 9.154929577464834 35
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 10.563380281690193 46
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1cc0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4860> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00484a8> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 4.225352112676077 14
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 5.985915492957776 24
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 9.507042253521174 36
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 10.915492957746533 47
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d390> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 4.225352112676077 15
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 5.985915492957776 25
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 9.507042253521174 37
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 10.915492957746533 48
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c873e0f0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b77b8> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 1.760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 4.577464788732417 16
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 6.338028169014116 26
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 9.859154929577514 38
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 11.267605633802873 49
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8710> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877dd30> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87a12b0> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 4.929577464788757 17
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 6.690140845070456 27
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 10.211267605633854 39
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 11.619718309859213 50
Completed Iteration #21
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87c32e8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 5.281690140845097 18
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 7.042253521126796 28
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 10.563380281690193 40
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 11.971830985915553 51
Completed Iteration #22
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4cc0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064668> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00644e0> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 5.6338028169014365 19
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 7.394366197183135 29
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 10.915492957746533 41
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 12.323943661971892 52
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #3
root->8->12->3
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1f60> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0020a58> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 2.1126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 5.985915492957776 20
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 7.746478873239475 30
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 11.267605633802873 42
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 12.676056338028232 53
Completed Iteration #0
Best Reward: 0.3521126760563398
Completed Iteration #1
Best Reward: 0.3521126760563398
Completed Iteration #2
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4780> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 2.4647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 6.338028169014116 21
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 8.098591549295815 31
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 11.619718309859213 43
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 13.028169014084572 54
Completed Iteration #3
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87b44a8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 2.8169014084507182 9
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 6.690140845070456 22
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 8.450704225352155 32
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 11.971830985915553 44
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 13.380281690140912 55
Completed Iteration #4
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c873e0b8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a10b8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1f60> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0020a58> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 3.169014084507058 10
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 7.042253521126796 23
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 8.802816901408494 33
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 12.323943661971892 45
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 13.732394366197251 56
Completed Iteration #5
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e0f0> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26b77b8> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 3.169014084507058 11
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 7.042253521126796 24
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 8.802816901408494 34
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 12.323943661971892 46
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 13.732394366197251 57
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c873ec50> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0020a58> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 3.521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 7.394366197183135 25
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 9.154929577464834 35
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 12.676056338028232 47
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 14.084507042253591 58
Completed Iteration #8
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c875a278> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a0b8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 3.8732394366197376 13
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 7.746478873239475 26
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 9.507042253521174 36
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 13.028169014084572 48
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 14.436619718309931 59
Completed Iteration #9
Best Reward: 0.3521126760563398
Completed Iteration #10
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c875a710> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 4.225352112676077 14
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 8.098591549295815 27
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 9.859154929577514 37
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 13.380281690140912 49
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 14.78873239436627 60
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Completed Iteration #13
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873ec50> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0020a58> 1.0563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 4.225352112676077 15
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 8.098591549295815 28
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 9.859154929577514 38
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 13.380281690140912 50
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 14.78873239436627 61
Completed Iteration #14
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0be0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc8d0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4780> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 1.760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 4.577464788732417 16
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 8.450704225352155 29
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 10.211267605633854 39
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 13.732394366197251 51
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 15.14084507042261 62
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a0b8> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 4.577464788732417 17
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 8.450704225352155 30
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 10.211267605633854 40
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 13.732394366197251 52
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 15.14084507042261 63
Completed Iteration #21
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 4.577464788732417 18
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 8.450704225352155 31
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 10.211267605633854 41
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 13.732394366197251 53
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 15.14084507042261 64
Completed Iteration #22
Best Reward: 0.3521126760563398
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c875a1d0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 2.1126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 4.929577464788757 19
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 8.802816901408494 32
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 10.563380281690193 42
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 14.084507042253591 54
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 15.49295774647895 65
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #4
root->8->12->3->14
Best Reward: 0.3521126760563398
Completed Iteration #0
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c875ad68> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 2.4647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 5.281690140845097 20
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 9.154929577464834 33
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 10.915492957746533 43
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 14.436619718309931 55
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 15.84507042253529 66
Completed Iteration #1
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c875ab70> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 2.8169014084507182 9
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 5.6338028169014365 21
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 9.507042253521174 34
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 11.267605633802873 44
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 14.78873239436627 56
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 16.19718309859163 67
Completed Iteration #2
Best Reward: 0.3521126760563398
Completed Iteration #3
Best Reward: 0.3521126760563398
Completed Iteration #4
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b44a8> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 2.8169014084507182 10
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 5.6338028169014365 22
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 9.507042253521174 35
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 11.267605633802873 45
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 14.78873239436627 57
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 16.19718309859163 68
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 2.8169014084507182 11
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 5.6338028169014365 23
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 9.507042253521174 36
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 11.267605633802873 46
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 14.78873239436627 58
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 16.19718309859163 69
Completed Iteration #9
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd438> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 3.169014084507058 12
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 5.985915492957776 24
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 9.859154929577514 37
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 11.619718309859213 47
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 15.14084507042261 59
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 16.54929577464797 70
Completed Iteration #10
Best Reward: 0.3521126760563398
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1908> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc8d0> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4780> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 3.521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 6.338028169014116 25
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 10.211267605633854 38
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 11.971830985915553 48
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 15.49295774647895 60
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 16.90140845070431 71
Completed Iteration #15
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875ad68> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 3.521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 6.338028169014116 26
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 10.211267605633854 39
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 11.971830985915553 49
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 15.49295774647895 61
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 16.90140845070431 72
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c875a208> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 3.8732394366197376 15
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 6.690140845070456 27
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 10.563380281690193 40
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 12.323943661971892 50
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 15.84507042253529 62
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 17.25352112676065 73
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 3.8732394366197376 16
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 6.690140845070456 28
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 10.563380281690193 41
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 12.323943661971892 51
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 15.84507042253529 63
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 17.25352112676065 74
Completed Iteration #20
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875ab70> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 3.8732394366197376 17
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 6.690140845070456 29
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 10.563380281690193 42
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 12.323943661971892 52
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 15.84507042253529 64
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 17.25352112676065 75
Completed Iteration #21
Best Reward: 0.3521126760563398
Completed Iteration #22
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87745f8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87749e8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a208> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 4.225352112676077 18
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 7.042253521126796 30
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 10.915492957746533 43
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 12.676056338028232 53
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 16.19718309859163 65
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 17.60563380281699 76
Completed Iteration #23
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01d0048940> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774470> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a208> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 4.577464788732417 19
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 7.394366197183135 31
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 11.267605633802873 44
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 13.028169014084572 54
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 16.54929577464797 66
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 17.95774647887333 77
Completed Iteration #24
Best Reward: 0.3521126760563398
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #5
root->8->12->3->14->0
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c873e550> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc8d0> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4780> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 1.760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 4.929577464788757 20
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 7.746478873239475 32
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 11.619718309859213 45
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 13.380281690140912 55
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 16.90140845070431 67
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 18.30985915492967 78
Completed Iteration #0
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4780> 1.4084507042253591 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 1.4084507042253591 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 1.760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 4.929577464788757 21
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 7.746478873239475 33
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 11.619718309859213 46
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 13.380281690140912 56
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 16.90140845070431 68
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 18.30985915492967 79
Completed Iteration #1
Best Reward: 0.3521126760563398
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4780> 1.4084507042253591 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 1.4084507042253591 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 1.760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 4.929577464788757 22
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 7.746478873239475 34
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 11.619718309859213 47
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 13.380281690140912 57
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 16.90140845070431 69
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 18.30985915492967 80
Completed Iteration #2
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c8714160> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 1.760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 2.1126760563380387 9
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 5.281690140845097 23
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 8.098591549295815 35
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 11.971830985915553 48
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 13.732394366197251 58
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 17.25352112676065 70
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 18.66197183098601 81
Completed Iteration #3
Best Reward: 0.3521126760563398
Completed Iteration #4
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c8714630> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 2.1126760563380387 9
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 2.4647887323943785 10
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 5.6338028169014365 24
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 8.450704225352155 36
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 12.323943661971892 49
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 14.084507042253591 59
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 17.60563380281699 71
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 19.014084507042348 82
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Completed Iteration #10
Best Reward: 0.3521126760563398
Completed Iteration #11
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 2.4647887323943785 10
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 2.8169014084507182 11
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 5.985915492957776 25
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 8.802816901408494 37
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 12.676056338028232 50
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 14.436619718309931 60
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 17.95774647887333 72
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 19.366197183098688 83
Completed Iteration #12
Best Reward: 0.3521126760563398
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8da0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc8d0> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4780> 1.760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 2.8169014084507182 11
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 3.169014084507058 12
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 6.338028169014116 26
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 9.154929577464834 38
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 13.028169014084572 51
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 14.78873239436627 61
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 18.30985915492967 73
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 19.718309859155028 84
Completed Iteration #17
Best Reward: 0.3521126760563398
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c8714908> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 3.169014084507058 12
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 3.521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 6.690140845070456 27
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 9.507042253521174 39
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 13.380281690140912 52
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 15.14084507042261 62
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 18.66197183098601 74
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 20.070422535211367 85
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Completed Iteration #22
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87230b8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a390> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 3.8732394366197376 14
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 7.042253521126796 28
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 9.859154929577514 40
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 13.732394366197251 53
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 15.49295774647895 63
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 19.014084507042348 75
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 20.422535211267707 86
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8714d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8714160> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 3.169014084507058 13
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 3.8732394366197376 15
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 7.042253521126796 29
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 9.859154929577514 41
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 13.732394366197251 54
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 15.49295774647895 64
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 19.014084507042348 76
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 20.422535211267707 87
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #6
root->8->12->3->14->0->2
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8723668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8714630> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 3.169014084507058 14
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 3.8732394366197376 16
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 7.042253521126796 30
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 9.859154929577514 42
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 13.732394366197251 55
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 15.49295774647895 65
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 19.014084507042348 77
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 20.422535211267707 88
Completed Iteration #0
Best Reward: 0.3521126760563398
Completed Iteration #1
Best Reward: 0.3521126760563398
Completed Iteration #2
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87310f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1908> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc8d0> 1.4084507042253591 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4780> 1.760563380281699 9
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 3.169014084507058 15
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 3.8732394366197376 17
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 7.042253521126796 31
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 9.859154929577514 43
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 13.732394366197251 56
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 15.49295774647895 66
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 19.014084507042348 78
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 20.422535211267707 89
Completed Iteration #3
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c8731710> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 3.521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 4.225352112676077 18
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 7.394366197183135 32
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 10.211267605633854 44
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 14.084507042253591 57
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 15.84507042253529 67
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 19.366197183098688 79
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 20.774647887324047 90
Completed Iteration #4
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c873eeb8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0020240> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8714908> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 3.8732394366197376 17
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 4.577464788732417 19
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 7.746478873239475 33
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 10.563380281690193 45
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 14.436619718309931 58
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 16.19718309859163 68
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 19.718309859155028 80
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 21.126760563380387 91
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87141d0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc8d0> 1.760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4780> 2.1126760563380387 10
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 4.225352112676077 18
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 4.929577464788757 20
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 8.098591549295815 34
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 10.915492957746533 46
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 14.78873239436627 59
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 16.54929577464797 69
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 20.070422535211367 81
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 21.478873239436727 92
Completed Iteration #10
Best Reward: 0.3521126760563398
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c87230f0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723be0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 4.577464788732417 19
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 5.281690140845097 21
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 8.450704225352155 35
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 11.267605633802873 47
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 15.14084507042261 60
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 16.90140845070431 70
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 20.422535211267707 82
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 21.830985915493066 93
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c8731d68> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 4.929577464788757 20
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 5.6338028169014365 22
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 8.802816901408494 36
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 11.619718309859213 48
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 15.49295774647895 61
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 17.25352112676065 71
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 20.774647887324047 83
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 22.183098591549406 94
Completed Iteration #21
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd160> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723780> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8714630> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 5.281690140845097 21
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 5.985915492957776 23
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 9.154929577464834 37
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 11.971830985915553 49
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 15.84507042253529 62
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 17.60563380281699 72
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 21.126760563380387 84
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 22.535211267605746 95
Completed Iteration #22
Best Reward: 0.3521126760563398
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c8731d30> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 5.6338028169014365 22
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 6.338028169014116 24
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 9.507042253521174 38
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 12.323943661971892 50
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 16.19718309859163 63
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 17.95774647887333 73
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 21.478873239436727 85
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 22.887323943662086 96
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #7
root->8->12->3->14->0->2->5
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c86cda20> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723be0> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 5.985915492957776 23
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 6.690140845070456 25
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 9.859154929577514 39
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 12.676056338028232 51
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 16.54929577464797 64
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 18.30985915492967 74
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 21.830985915493066 86
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 23.239436619718425 97
Completed Iteration #0
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdf28> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdd68> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 6.338028169014116 24
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 7.042253521126796 26
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 10.211267605633854 40
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 13.028169014084572 52
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 16.90140845070431 65
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 18.66197183098601 75
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 22.183098591549406 87
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 23.591549295774765 98
Completed Iteration #1
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5400> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723be0> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 1.760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 6.690140845070456 25
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 7.394366197183135 27
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 10.563380281690193 41
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 13.380281690140912 53
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 17.25352112676065 66
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 19.014084507042348 76
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 22.535211267605746 88
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 23.943661971831105 99
Completed Iteration #2
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c875acc0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87140f0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87230f0> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8723be0> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 2.1126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 7.042253521126796 26
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 7.746478873239475 28
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 10.915492957746533 42
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 13.732394366197251 54
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 17.60563380281699 67
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 19.366197183098688 77
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 22.887323943662086 89
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 24.295774647887445 100
Completed Iteration #3
Best Reward: 0.3521126760563398
Completed Iteration #4
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c8714a20> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87148d0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 2.4647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 7.394366197183135 27
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 8.098591549295815 29
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 11.267605633802873 43
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 14.084507042253591 55
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 17.95774647887333 68
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 19.718309859155028 78
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 23.239436619718425 90
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 24.647887323943785 101
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Completed Iteration #10
Best Reward: 0.3521126760563398
Completed Iteration #11
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd5f8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdd68> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 2.8169014084507182 9
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 7.746478873239475 28
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 8.450704225352155 30
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 11.619718309859213 44
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 14.436619718309931 56
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 18.30985915492967 69
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 20.070422535211367 79
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 23.591549295774765 91
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 25.000000000000124 102
Completed Iteration #12
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c86d51d0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5320> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8714a20> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87148d0> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 3.169014084507058 10
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 8.098591549295815 29
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 8.802816901408494 31
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 11.971830985915553 45
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 14.78873239436627 57
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 18.66197183098601 70
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 20.422535211267707 80
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 23.943661971831105 92
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 25.352112676056464 103
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Completed Iteration #15
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5908> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87148d0> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 3.521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 8.450704225352155 30
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 9.154929577464834 32
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 12.323943661971892 46
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 15.14084507042261 58
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 19.014084507042348 71
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 20.774647887324047 81
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 24.295774647887445 93
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 25.704225352112804 104
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Completed Iteration #18
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c86f00b8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0080> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd5f8> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdd68> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 3.8732394366197376 12
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 8.802816901408494 31
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 9.507042253521174 33
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 12.676056338028232 47
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 15.49295774647895 59
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 19.366197183098688 72
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 21.126760563380387 82
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 24.647887323943785 94
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 26.056338028169144 105
Completed Iteration #19
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0748> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdd68> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 4.225352112676077 13
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 9.154929577464834 32
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4588> 9.859154929577514 34
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3828> 13.028169014084572 48
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ac8> 15.84507042253529 60
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0128> 19.718309859155028 73
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 21.478873239436727 83
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e10> 25.000000000000124 95
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3518> 26.408450704225483 106
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Completed Iteration #22
Best Reward: 0.3521126760563398
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #8
root->8->12->3->14->0->2->5->2
Best Reward: 0.3521126760563398
iteration: 25
found coverage increase 0.3521126760563398
Current Total Coverage 11.267605633802818
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87319e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87319e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87319e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8714390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd710> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 11.267605633802818
cluster_index 12
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86960b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86f07b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 0.3521126760563362 3
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 0.3521126760563362 4
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8696ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 0.3521126760563362 5
Completed Iteration #4
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8696c50> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d68> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 0.7042253521126725 6
Completed Iteration #5
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c869f0f0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d68> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 1.0563380281690087 7
Completed Iteration #6
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8696ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696c50> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d68> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 1.0563380281690087 8
Completed Iteration #7
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0da0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0048> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 1.408450704225345 9
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c869f5c0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 0.3521126760563362 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 1.7605633802816811 10
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5b00> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 2.1126760563380174 11
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86f07b8> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 2.1126760563380174 12
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 2.1126760563380174 13
Completed Iteration #13
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8714eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 2.1126760563380174 14
Completed Iteration #14
Best Reward: 0.3521126760563362
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8696be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d68> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 2.1126760563380174 15
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0da0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0048> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 2.1126760563380174 16
Completed Iteration #17
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c869f7f0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869f080> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5b00> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 1.0563380281690087 6
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 2.4647887323943536 17
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c869fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869f080> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5b00> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 1.0563380281690087 7
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 2.4647887323943536 18
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 2.81690140845069 19
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c869f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86961d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 2.81690140845069 20
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6278> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 1.7605633802816811 9
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 3.169014084507026 21
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3521126760563362
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6710> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86b65f8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6278> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 2.1126760563380174 10
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 3.5211267605633623 22
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6cc0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86b65f8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6278> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 2.4647887323943536 11
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 3.8732394366196985 23
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6fd0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 2.81690140845069 12
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 4.225352112676035 24
Completed Iteration #4
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8644320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869f080> 0.3521126760563362 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5b00> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 2.81690140845069 13
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 4.225352112676035 25
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86446a0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 3.169014084507026 14
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 4.577464788732371 26
Completed Iteration #7
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869f5c0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 3.169014084507026 15
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 4.577464788732371 27
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8644be0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86b65f8> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6278> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 3.5211267605633623 16
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 4.929577464788707 28
Completed Iteration #9
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86440b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 3.8732394366196985 17
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 5.281690140845043 29
Completed Iteration #10
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86550b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 4.225352112676035 18
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 5.63380281690138 30
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8655400> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655198> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5b00> 1.0563380281690087 6
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 4.577464788732371 19
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 5.985915492957716 31
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86440b8> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 4.577464788732371 20
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 5.985915492957716 32
Completed Iteration #13
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8696f60> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cda58> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 4.929577464788707 21
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 6.338028169014052 33
Completed Iteration #14
Best Reward: 0.3521126760563362
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c869f9b0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 5.281690140845043 22
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 6.690140845070388 34
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 5.281690140845043 23
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 6.690140845070388 35
Completed Iteration #19
Best Reward: 0.3521126760563362
Completed Iteration #20
Best Reward: 0.3521126760563362
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6710> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86b65f8> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6278> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 5.281690140845043 24
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 6.690140845070388 36
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.3521126760563362
Completed Iteration #0
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8655080> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cda58> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 5.63380281690138 25
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 7.0422535211267245 37
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8655ac8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 5.985915492957716 26
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 7.394366197183061 38
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8655da0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cda58> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 1.7605633802816811 6
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 6.338028169014052 27
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 7.746478873239397 39
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 6.338028169014052 28
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 7.746478873239397 40
Completed Iteration #7
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8676400> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676208> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696f60> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cda58> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 6.690140845070388 29
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 8.098591549295733 41
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8676710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696f60> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86cda58> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 6.690140845070388 30
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 8.098591549295733 42
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 2.4647887323943536 10
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 7.0422535211267245 31
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 8.45070422535207 43
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8676fd0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 7.394366197183061 32
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 8.802816901408406 44
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97be3c8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97be0f0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 3.169014084507026 12
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 7.746478873239397 33
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 9.154929577464742 45
Completed Iteration #13
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86556a0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97be6a0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 3.5211267605633623 13
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 8.098591549295733 34
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 9.507042253521078 46
Completed Iteration #14
Best Reward: 0.3521126760563362
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97be6a0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 3.5211267605633623 14
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 8.098591549295733 35
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 9.507042253521078 47
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86552e8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 3.8732394366196985 15
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 8.45070422535207 36
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 9.859154929577414 48
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86559e8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cda58> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 4.225352112676035 16
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 8.802816901408406 37
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 10.21126760563375 49
Completed Iteration #20
Best Reward: 0.3521126760563362
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8644438> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 4.577464788732371 17
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 9.154929577464742 38
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 10.563380281690087 50
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8676a58> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676d30> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 4.929577464788707 18
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 9.507042253521078 39
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 10.915492957746423 51
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #2
root->0->2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6668> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 5.281690140845043 19
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 9.859154929577414 40
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 11.26760563380276 52
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86d57b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869f208> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676fd0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 2.4647887323943536 9
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 5.63380281690138 20
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 10.21126760563375 41
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 11.619718309859095 53
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 2.4647887323943536 10
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 5.63380281690138 21
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 10.21126760563375 42
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 11.619718309859095 54
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8676e80> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 5.985915492957716 22
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 10.563380281690087 43
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 11.971830985915432 55
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97be0f0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 2.81690140845069 12
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 5.985915492957716 23
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 10.563380281690087 44
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 11.971830985915432 56
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5160> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 3.169014084507026 13
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 6.338028169014052 24
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 10.915492957746423 45
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 12.323943661971768 57
Completed Iteration #11
Best Reward: 0.3521126760563362
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c869f9e8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97be860> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655ac8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 3.5211267605633623 14
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 6.690140845070388 25
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 11.26760563380276 46
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 12.676056338028104 58
Completed Iteration #13
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5978> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 3.8732394366196985 15
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 7.0422535211267245 26
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 11.619718309859095 47
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 13.02816901408444 59
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5cc0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 4.225352112676035 16
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 7.394366197183061 27
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 11.971830985915432 48
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 13.380281690140777 60
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97da0f0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5e80> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97be3c8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97be0f0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 4.577464788732371 17
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 7.746478873239397 28
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 12.323943661971768 49
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 13.732394366197113 61
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8644b38> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 4.929577464788707 18
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 8.098591549295733 29
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 12.676056338028104 50
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 14.084507042253449 62
Completed Iteration #17
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86960f0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 5.281690140845043 19
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 8.45070422535207 30
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 13.02816901408444 51
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 14.436619718309785 63
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8676f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5cc0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 5.281690140845043 20
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 8.45070422535207 31
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 13.02816901408444 52
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 14.436619718309785 64
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869f208> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8676fd0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 5.281690140845043 21
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 8.45070422535207 32
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 13.02816901408444 53
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 14.436619718309785 65
Completed Iteration #20
Best Reward: 0.3521126760563362
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
coverage_call_count 1400
Completed Iteration #23
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869f9e8> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97be860> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8655ac8> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 5.281690140845043 22
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 8.45070422535207 33
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 13.02816901408444 54
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 14.436619718309785 66
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #3
root->0->2->2
Best Reward: 0.3521126760563362
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Completed Iteration #3
Best Reward: 0.3521126760563362
Completed Iteration #4
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97da198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 5.281690140845043 23
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 8.45070422535207 34
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 13.02816901408444 55
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 14.436619718309785 67
Completed Iteration #5
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97da6a0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 1.7605633802816811 8
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 5.63380281690138 24
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 8.802816901408406 35
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 13.380281690140777 56
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 14.788732394366122 68
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97dae10> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97daf28> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97be3c8> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97be0f0> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 5.985915492957716 25
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 9.154929577464742 36
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 13.732394366197113 57
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 15.140845070422458 69
Completed Iteration #9
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676a58> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8676d30> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 2.1126760563380174 10
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 5.985915492957716 26
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 9.154929577464742 37
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 13.732394366197113 58
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 15.140845070422458 70
Completed Iteration #10
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa438> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 2.4647887323943536 11
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 6.338028169014052 27
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 9.507042253521078 38
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 14.084507042253449 59
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 15.492957746478794 71
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676a58> 0.3521126760563362 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8676d30> 0.3521126760563362 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 2.4647887323943536 12
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 6.338028169014052 28
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 9.507042253521078 39
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 14.084507042253449 60
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 15.492957746478794 72
Completed Iteration #12
Best Reward: 0.3521126760563362
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97820b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97be0f0> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 2.81690140845069 13
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 6.690140845070388 29
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 9.859154929577414 40
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 14.436619718309785 61
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 15.84507042253513 73
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6c88> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 3.169014084507026 14
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 7.0422535211267245 30
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 10.21126760563375 41
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 14.788732394366122 62
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 16.197183098591466 74
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da6a0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 3.169014084507026 15
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 7.0422535211267245 31
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 10.21126760563375 42
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 14.788732394366122 63
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 16.197183098591466 75
Completed Iteration #20
Best Reward: 0.3521126760563362
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97faeb8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa7b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa438> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 3.5211267605633623 16
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 7.394366197183061 32
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 10.563380281690087 43
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 15.140845070422458 64
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 16.549295774647803 76
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #4
root->0->2->2->14
Best Reward: 0.3521126760563362
Completed Iteration #0
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da6a0> 0.3521126760563362 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 3.5211267605633623 17
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 7.394366197183061 33
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 10.563380281690087 44
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 15.140845070422458 65
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 16.549295774647803 77
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 1.7605633802816811 8
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 3.8732394366196985 18
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 7.746478873239397 34
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 10.915492957746423 45
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 15.492957746478794 66
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 16.90140845070414 78
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97829b0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 4.225352112676035 19
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 8.098591549295733 35
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 11.26760563380276 46
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 15.84507042253513 67
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 17.253521126760475 79
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a979e358> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 2.4647887323943536 10
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 4.577464788732371 20
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 8.45070422535207 36
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 11.619718309859095 47
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 16.197183098591466 68
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 17.60563380281681 80
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a979e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97faeb8> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa7b8> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa438> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 2.4647887323943536 11
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 4.577464788732371 21
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 8.45070422535207 37
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 11.619718309859095 48
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 16.197183098591466 69
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 17.60563380281681 81
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a979edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6c88> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 2.4647887323943536 12
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 4.577464788732371 22
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 8.45070422535207 38
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 11.619718309859095 49
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 16.197183098591466 70
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 17.60563380281681 82
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6c88> 0.3521126760563362 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 2.4647887323943536 13
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 4.577464788732371 23
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 8.45070422535207 39
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 11.619718309859095 50
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 16.197183098591466 71
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 17.60563380281681 83
Completed Iteration #17
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e34850f0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da518> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6c88> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 2.81690140845069 14
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 4.929577464788707 24
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 8.802816901408406 40
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 11.971830985915432 51
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 16.549295774647803 72
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 17.957746478873148 84
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54a8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 3.169014084507026 15
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 5.281690140845043 25
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 9.154929577464742 41
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 12.323943661971768 52
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 16.90140845070414 73
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 18.309859154929484 85
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa400> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa0b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 3.5211267605633623 16
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 5.63380281690138 26
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 9.507042253521078 42
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 12.676056338028104 53
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 17.253521126760475 74
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 18.66197183098582 86
Completed Iteration #21
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a979e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54a8> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 3.5211267605633623 17
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 5.63380281690138 27
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 9.507042253521078 43
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 12.676056338028104 54
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 17.253521126760475 75
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 18.66197183098582 87
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa048> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e668> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34850f0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97da518> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86b6c88> 1.0563380281690087 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 3.8732394366196985 18
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 5.985915492957716 28
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 9.859154929577414 44
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 13.02816901408444 55
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 17.60563380281681 76
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 19.014084507042156 88
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #5
root->0->2->2->14->1
Best Reward: 0.3521126760563362
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa0b8> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 3.8732394366196985 19
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 5.985915492957716 29
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 9.859154929577414 45
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 13.02816901408444 56
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 17.60563380281681 77
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 19.014084507042156 89
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa400> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa0b8> 0.3521126760563362 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 3.8732394366196985 20
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 5.985915492957716 30
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 9.859154929577414 46
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 13.02816901408444 57
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 17.60563380281681 78
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 19.014084507042156 90
Completed Iteration #4
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97aad30> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 1.0563380281690087 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 4.225352112676035 21
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 6.338028169014052 31
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 10.21126760563375 47
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 13.380281690140777 58
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 17.957746478873148 79
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 19.366197183098492 91
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a9782668> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa710> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aad30> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 4.577464788732371 22
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 6.690140845070388 32
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 10.563380281690087 48
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 13.732394366197113 59
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 18.309859154929484 80
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 19.71830985915483 92
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 1.7605633802816811 8
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 4.929577464788707 23
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 7.0422535211267245 33
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 10.915492957746423 49
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 14.084507042253449 60
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 18.66197183098582 81
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 20.070422535211165 93
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97d59e8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa0b8> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 5.281690140845043 24
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 7.394366197183061 34
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 11.26760563380276 50
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 14.436619718309785 61
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 19.014084507042156 82
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 20.4225352112675 94
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a979eeb8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782c88> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 2.4647887323943536 10
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 5.63380281690138 25
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 7.746478873239397 35
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 11.619718309859095 51
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 14.788732394366122 62
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 19.366197183098492 83
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 20.774647887323837 95
Completed Iteration #13
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782c88> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 5.985915492957716 26
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 8.098591549295733 36
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 11.971830985915432 52
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 15.140845070422458 63
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 19.71830985915483 84
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 21.126760563380174 96
Completed Iteration #14
Best Reward: 0.3521126760563362
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782c88> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 2.81690140845069 12
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 5.985915492957716 27
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 8.098591549295733 37
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 11.971830985915432 53
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 15.140845070422458 64
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 19.71830985915483 85
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 21.126760563380174 97
Completed Iteration #19
Best Reward: 0.3521126760563362
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8676128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782c88> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 2.81690140845069 13
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 5.985915492957716 28
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 8.098591549295733 38
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 11.971830985915432 54
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 15.140845070422458 65
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 19.71830985915483 86
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 21.126760563380174 98
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97825c0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cc0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782668> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa710> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97aad30> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 3.169014084507026 14
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 6.338028169014052 29
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 8.45070422535207 39
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 12.323943661971768 55
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 15.492957746478794 66
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 20.070422535211165 87
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 21.47887323943651 99
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9743908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 3.169014084507026 15
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 6.338028169014052 30
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 8.45070422535207 40
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 12.323943661971768 56
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 15.492957746478794 67
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 20.070422535211165 88
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 21.47887323943651 100
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #6
root->0->2->2->14->1->11
Best Reward: 0.3521126760563362
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aad30> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 3.169014084507026 16
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 6.338028169014052 31
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 8.45070422535207 41
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 12.323943661971768 57
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 15.492957746478794 68
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 20.070422535211165 89
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 21.47887323943651 101
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97526d8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9752390> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 1.7605633802816811 8
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 3.5211267605633623 17
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 6.690140845070388 32
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 8.802816901408406 42
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 12.676056338028104 58
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 15.84507042253513 69
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 20.4225352112675 90
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 21.830985915492846 102
Completed Iteration #3
Best Reward: 0.3521126760563362
Completed Iteration #4
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5da0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9752390> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 3.8732394366196985 18
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 7.0422535211267245 33
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 9.154929577464742 43
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 13.02816901408444 59
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 16.197183098591466 70
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 20.774647887323837 91
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 22.183098591549182 103
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Completed Iteration #9
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaef0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa4a8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 2.4647887323943536 10
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 4.225352112676035 19
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 7.394366197183061 34
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 9.507042253521078 44
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 13.380281690140777 60
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 16.549295774647803 71
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 21.126760563380174 92
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 22.53521126760552 104
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Completed Iteration #12
Best Reward: 0.3521126760563362
Completed Iteration #13
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d30> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 4.577464788732371 20
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 7.746478873239397 35
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 9.859154929577414 45
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 13.732394366197113 61
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 16.90140845070414 72
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 21.47887323943651 93
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 22.887323943661855 105
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01c8676b00> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aafd0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 3.169014084507026 12
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 4.929577464788707 21
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 8.098591549295733 36
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 10.21126760563375 46
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 14.084507042253449 62
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 17.253521126760475 73
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 21.830985915492846 94
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 23.23943661971819 106
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a9752b38> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9752ba8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aad30> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 3.5211267605633623 13
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 5.281690140845043 22
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 8.45070422535207 37
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 10.563380281690087 47
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 14.436619718309785 63
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 17.60563380281681 74
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 22.183098591549182 95
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 23.591549295774527 107
Completed Iteration #19
Best Reward: 0.3521126760563362
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97633c8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9763198> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d30> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 3.8732394366196985 14
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 5.63380281690138 23
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 8.802816901408406 38
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 10.915492957746423 48
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 14.788732394366122 64
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 17.957746478873148 75
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 22.53521126760552 96
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 23.943661971830863 108
Completed Iteration #21
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d30> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 3.8732394366196985 15
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 5.63380281690138 24
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 8.802816901408406 39
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 10.915492957746423 49
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 14.788732394366122 65
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 17.957746478873148 76
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 22.53521126760552 97
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 23.943661971830863 109
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
coverage_call_count 1500
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a9752fd0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 4.225352112676035 16
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 5.985915492957716 25
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 9.154929577464742 40
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 11.26760563380276 50
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 15.140845070422458 66
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 18.309859154929484 77
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 22.887323943661855 98
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 24.2957746478872 110
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #7
root->0->2->2->14->1->11->0
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a9763f98> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9763dd8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676b00> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97aafd0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 4.577464788732371 17
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 6.338028169014052 26
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 9.507042253521078 41
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 11.619718309859095 51
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 15.492957746478794 67
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 18.66197183098582 78
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 23.23943661971819 99
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 24.647887323943536 111
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9743be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9752390> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 4.577464788732371 18
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 6.338028169014052 27
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 9.507042253521078 42
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 11.619718309859095 52
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 15.492957746478794 68
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 18.66197183098582 79
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 23.23943661971819 100
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 24.647887323943536 112
Completed Iteration #3
Best Reward: 0.3521126760563362
Completed Iteration #4
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97520b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97dacc0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97526d8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9752390> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 2.4647887323943536 10
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 4.929577464788707 19
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 6.690140845070388 28
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 9.859154929577414 43
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 11.971830985915432 53
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 15.84507042253513 69
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 19.014084507042156 80
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 23.591549295774527 101
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 24.999999999999872 113
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9752908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676b00> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97aafd0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 2.4647887323943536 11
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 4.929577464788707 20
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 6.690140845070388 29
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 9.859154929577414 44
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 11.971830985915432 54
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 15.84507042253513 70
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 19.014084507042156 81
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 23.591549295774527 102
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 24.999999999999872 114
Completed Iteration #7
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9763400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9763ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5da0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9752390> 1.0563380281690087 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 2.4647887323943536 12
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 4.929577464788707 21
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 6.690140845070388 30
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 9.859154929577414 45
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 11.971830985915432 55
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 15.84507042253513 71
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 19.014084507042156 82
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 23.591549295774527 103
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 24.999999999999872 115
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a9763b38> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97dacc0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97526d8> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7f01a9752390> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 2.81690140845069 13
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 5.281690140845043 22
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 7.0422535211267245 31
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 10.21126760563375 46
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 12.323943661971768 56
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 16.197183098591466 72
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 19.366197183098492 83
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 23.943661971830863 104
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 25.35211267605621 116
Completed Iteration #9
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a976e2b0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976e1d0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 3.169014084507026 14
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 5.63380281690138 23
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 7.394366197183061 32
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 10.563380281690087 47
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 12.676056338028104 57
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 16.549295774647803 73
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 19.71830985915483 84
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 24.2957746478872 105
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 25.704225352112545 117
Completed Iteration #10
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a976e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 3.169014084507026 15
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 5.63380281690138 24
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 7.394366197183061 33
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 10.563380281690087 48
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 12.676056338028104 58
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 16.549295774647803 74
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 19.71830985915483 85
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 24.2957746478872 106
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 25.704225352112545 118
Completed Iteration #11
Best Reward: 0.3521126760563362
Completed Iteration #12
Best Reward: 0.3521126760563362
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa828> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aafd0> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 3.5211267605633623 16
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 5.985915492957716 25
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 7.746478873239397 34
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 10.915492957746423 49
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 13.02816901408444 59
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 16.90140845070414 75
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 20.070422535211165 86
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 24.647887323943536 107
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 26.05633802816888 119
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01a9752c18> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696a90> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 3.8732394366196985 17
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 6.338028169014052 26
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 8.098591549295733 35
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 11.26760563380276 50
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 13.380281690140777 60
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 17.253521126760475 76
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 20.4225352112675 87
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 24.999999999999872 108
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 26.408450704225217 120
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9763978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 3.8732394366196985 18
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 6.338028169014052 27
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 8.098591549295733 36
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 11.26760563380276 51
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 13.380281690140777 61
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 17.253521126760475 77
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 20.4225352112675 88
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 24.999999999999872 109
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 26.408450704225217 121
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa4a8> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97432b0> 3.8732394366196985 19
backprop <src.mcts.MCTS_Node object at 0x7f01a97aaa90> 6.338028169014052 28
backprop <src.mcts.MCTS_Node object at 0x7f01a97823c8> 8.098591549295733 37
backprop <src.mcts.MCTS_Node object at 0x7f01a97da5c0> 11.26760563380276 52
backprop <src.mcts.MCTS_Node object at 0x7f01c8676ac8> 13.380281690140777 62
backprop <src.mcts.MCTS_Node object at 0x7f01c8655898> 17.253521126760475 78
backprop <src.mcts.MCTS_Node object at 0x7f01c869fdd8> 20.4225352112675 89
backprop <src.mcts.MCTS_Node object at 0x7f01c86966a0> 24.999999999999872 110
backprop <src.mcts.MCTS_Node object at 0x7f01c86964e0> 26.408450704225217 122
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #8
root->0->2->2->14->1->11->0->11
Best Reward: 0.3521126760563362
iteration: 27
found coverage increase 0.3521126760563362
Current Total Coverage 11.619718309859154
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9716160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97166a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9716588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a976e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97169e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9716748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9716128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9716748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9716f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9716e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9716fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9716cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9716748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9716358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9725470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9716e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9725630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9716358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9725898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9725be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97254a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9725fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97254a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a96be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97254a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9716358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01a976eeb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 11.619718309859154
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9752eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97da278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9752128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9763a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9752eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97631d0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 0.7042253521126778 5
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a976e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 0.7042253521126778 6
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 1.4084507042253556 7
Completed Iteration #10
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9763eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9763518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 1.4084507042253556 8
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9763e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9763518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 1.4084507042253556 9
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9752588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 1.4084507042253556 5
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 1.4084507042253556 10
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9752940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 1.4084507042253556 6
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 1.4084507042253556 11
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9752c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9752908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 1.4084507042253556 7
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 1.4084507042253556 12
Completed Iteration #17
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9752748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 1.4084507042253556 13
Completed Iteration #18
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9743b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 1.4084507042253556 14
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a9763f28> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9752f60> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97631d0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 2.1126760563380333 8
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 2.1126760563380333 15
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9743978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 2.1126760563380333 16
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9763f28> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9752f60> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97631d0> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 2.1126760563380333 9
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 2.1126760563380333 17
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97aacf8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743eb8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9763f28> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01a9752f60> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97631d0> 2.1126760563380333 5
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 2.816901408450711 10
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 2.816901408450711 18
Completed Iteration #3
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a979e4e0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 3.521126760563389 11
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 3.521126760563389 19
Completed Iteration #4
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a979e400> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9752f60> 2.1126760563380333 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97631d0> 2.816901408450711 6
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 4.225352112676067 12
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 4.225352112676067 20
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a979ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 4.225352112676067 13
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 4.225352112676067 21
Completed Iteration #7
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a979eeb8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 4.9295774647887445 14
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 4.9295774647887445 22
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 4.9295774647887445 15
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 4.9295774647887445 23
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97436a0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 2.1126760563380333 5
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 5.633802816901422 16
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 5.633802816901422 24
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 5.633802816901422 17
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 5.633802816901422 25
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a979efd0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9763128> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97436a0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 2.816901408450711 6
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 6.3380281690141 18
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 6.3380281690141 26
Completed Iteration #22
Best Reward: 0.7042253521126778
coverage_call_count 1600
Completed Iteration #23
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a979e2e8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979eef0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e400> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9752f60> 2.4647887323943714 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97631d0> 3.169014084507049 7
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 6.690140845070438 19
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 6.690140845070438 27
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #1
root->4
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a9782160> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 3.521126760563389 7
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 7.394366197183116 20
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 7.394366197183116 28
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa4a8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 3.169014084507049 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 3.873239436619727 8
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 7.746478873239454 21
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 7.746478873239454 29
Completed Iteration #3
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 3.873239436619727 7
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 4.577464788732405 9
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 8.450704225352132 22
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 8.450704225352132 30
Completed Iteration #4
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97fabe0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa860> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979eeb8> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 4.577464788732405 8
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 5.2816901408450825 10
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 9.15492957746481 23
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 9.15492957746481 31
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa9b0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 5.2816901408450825 9
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 5.98591549295776 11
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 9.859154929577487 24
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 9.859154929577487 32
Completed Iteration #7
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97dada0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da390> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 6.690140845070438 12
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 10.563380281690165 25
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 10.563380281690165 33
Completed Iteration #8
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97faeb8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da4a8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 5.98591549295776 10
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 7.394366197183116 13
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 11.267605633802843 26
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 11.267605633802843 34
Completed Iteration #9
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a97da518> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782080> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782160> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 6.338028169014098 11
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 7.746478873239454 14
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 11.61971830985918 27
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 11.61971830985918 35
Completed Iteration #10
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97dae80> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97dab00> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa4a8> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 7.042253521126776 12
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 8.450704225352132 15
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 12.323943661971859 28
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 12.323943661971859 36
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9743be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa9b0> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 7.042253521126776 13
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 8.450704225352132 16
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 12.323943661971859 29
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 12.323943661971859 37
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a979ed68> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9763208> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97dada0> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97da390> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 8.80281690140847 17
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 12.676056338028197 30
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 12.676056338028197 38
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a97fae80> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa6d8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979ed68> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9763208> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97dada0> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97da390> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 9.154929577464808 18
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 13.028169014084535 31
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 13.028169014084535 39
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9782198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 9.154929577464808 19
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 13.028169014084535 32
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 13.028169014084535 40
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97da8d0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da390> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 9.859154929577485 20
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 13.732394366197212 33
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 13.732394366197212 41
Completed Iteration #22
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a9782d30> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97daa58> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa9b0> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 7.746478873239454 14
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 10.563380281690163 21
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 14.43661971830989 34
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 14.43661971830989 42
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97da860> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97dac18> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97436a0> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 8.450704225352132 15
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 11.267605633802841 22
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 15.140845070422568 35
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 15.140845070422568 43
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #2
root->4->1
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97d53c8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5f28> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782d30> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97daa58> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa9b0> 2.1126760563380333 5
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 9.15492957746481 16
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 11.971830985915519 23
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 15.845070422535246 36
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 15.845070422535246 44
Completed Iteration #1
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97d58d0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 9.859154929577487 17
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 12.676056338028197 24
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 16.549295774647923 37
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 16.549295774647923 45
Completed Iteration #2
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97d50b8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 10.563380281690165 18
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 13.380281690140874 25
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 17.253521126760603 38
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 17.253521126760603 46
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c8676d68> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 11.267605633802843 19
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 14.084507042253552 26
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 17.957746478873283 39
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 17.957746478873283 47
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97be470> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782080> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9782160> 1.7605633802816936 4
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 11.97183098591552 20
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 14.78873239436623 27
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 18.661971830985962 40
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 18.661971830985962 48
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97dab00> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa4a8> 1.0563380281690158 4
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 11.97183098591552 21
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 14.78873239436623 28
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 18.661971830985962 41
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 18.661971830985962 49
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a979e240> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d30> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fabe0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa860> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a979eeb8> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 12.676056338028198 22
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 15.492957746478908 29
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 19.36619718309864 42
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 19.36619718309864 50
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9782358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d58d0> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 12.676056338028198 23
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 15.492957746478908 30
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 19.36619718309864 43
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 19.36619718309864 51
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97fae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97daa58> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa9b0> 2.1126760563380333 6
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 12.676056338028198 24
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 15.492957746478908 31
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 19.36619718309864 44
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 19.36619718309864 52
Completed Iteration #16
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c8676278> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d30> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97fabe0> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa860> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01a979eeb8> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 13.380281690140876 25
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 16.197183098591587 32
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 20.07042253521132 45
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 20.07042253521132 53
Completed Iteration #17
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a97da668> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97dab00> 1.0563380281690158 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97aa4a8> 1.4084507042253538 5
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 13.732394366197214 26
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 16.549295774647923 33
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 20.422535211267657 46
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 20.422535211267657 54
Completed Iteration #18
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fabe0> 2.1126760563380333 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa860> 2.1126760563380333 5
backprop <src.mcts.MCTS_Node object at 0x7f01a979eeb8> 2.816901408450711 6
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 13.732394366197214 27
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 16.549295774647923 34
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 20.422535211267657 47
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 20.422535211267657 55
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97faf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8676a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d50b8> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 13.732394366197214 28
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 16.549295774647923 35
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 20.422535211267657 48
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 20.422535211267657 56
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a97636a0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 14.084507042253552 29
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 16.90140845070426 36
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 20.774647887323994 49
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 20.774647887323994 57
Completed Iteration #24
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5fd0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d50f0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97faeb8> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97da4a8> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 14.78873239436623 30
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 17.60563380281694 37
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 21.478873239436673 50
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 21.478873239436673 58
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #3
root->4->1->1
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 15.492957746478908 31
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 18.30985915492962 38
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 22.183098591549353 51
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 22.183098591549353 59
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c869f198> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869ff98> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 3.521126760563389 6
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 16.197183098591587 32
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 19.0140845070423 39
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 22.887323943662032 52
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 22.887323943662032 60
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a9752b70> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869ff98> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 4.225352112676067 7
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 16.901408450704267 33
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 19.718309859154978 40
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 23.591549295774712 53
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 23.591549295774712 61
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a979ebe0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d50f0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97faeb8> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97da4a8> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 4.9295774647887445 8
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 17.605633802816946 34
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 20.422535211267657 41
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 24.29577464788739 54
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 24.29577464788739 62
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c86765f8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 5.633802816901422 9
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 18.309859154929626 35
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 21.126760563380337 42
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 25.00000000000007 55
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 25.00000000000007 63
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a979eac8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 3.521126760563389 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 6.3380281690141 10
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 19.014084507042305 36
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 21.830985915493017 43
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 25.70422535211275 56
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 25.70422535211275 64
Completed Iteration #18
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5b70> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d57b8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a979eac8> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 4.225352112676067 7
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 7.042253521126778 11
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 19.718309859154985 37
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 22.535211267605696 44
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 26.40845070422543 57
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 26.40845070422543 65
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a97fada0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97bebe0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 7.746478873239456 12
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 20.422535211267665 38
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 23.239436619718376 45
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 27.11267605633811 58
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 27.11267605633811 66
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #4
root->4->1->1->12
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01c86555f8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 4.577464788732405 8
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 8.098591549295794 13
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 20.774647887324 39
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 23.591549295774712 46
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 27.464788732394446 59
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 27.464788732394446 67
Completed Iteration #0
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 4.577464788732405 9
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 8.098591549295794 14
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 20.774647887324 40
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 23.591549295774712 47
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 27.464788732394446 60
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 27.464788732394446 68
Completed Iteration #1
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8644710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86555f8> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 4.577464788732405 10
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 8.098591549295794 15
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 20.774647887324 41
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 23.591549295774712 48
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 27.464788732394446 61
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 27.464788732394446 69
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8644208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97beb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5b70> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97d57b8> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01a979eac8> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 4.577464788732405 11
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 8.098591549295794 16
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 20.774647887324 42
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 23.591549295774712 49
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 27.464788732394446 62
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 27.464788732394446 70
Completed Iteration #4
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c8644518> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644240> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86765f8> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 5.2816901408450825 12
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 8.802816901408471 17
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 21.47887323943668 43
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 24.29577464788739 50
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 28.169014084507126 63
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 28.169014084507126 71
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97dae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5b70> 0.7042253521126778 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97d57b8> 0.7042253521126778 4
backprop <src.mcts.MCTS_Node object at 0x7f01a979eac8> 1.4084507042253556 5
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 5.2816901408450825 13
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 8.802816901408471 18
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 21.47887323943668 44
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 24.29577464788739 51
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 28.169014084507126 64
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 28.169014084507126 72
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 5.2816901408450825 14
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 8.802816901408471 19
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 21.47887323943668 45
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 24.29577464788739 52
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 28.169014084507126 65
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 28.169014084507126 73
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8655b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 5.2816901408450825 15
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 8.802816901408471 20
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 21.47887323943668 46
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 24.29577464788739 53
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 28.169014084507126 66
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 28.169014084507126 74
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 5.98591549295776 16
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 9.50704225352115 21
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 22.18309859154936 47
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 25.00000000000007 54
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 28.873239436619805 67
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 28.873239436619805 75
Completed Iteration #17
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8644898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 5.98591549295776 17
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 9.50704225352115 22
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 22.18309859154936 48
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 25.00000000000007 55
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 28.873239436619805 68
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 28.873239436619805 76
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
coverage_call_count 1700
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #5
root->4->1->1->12->2
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d30> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644278> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9752b70> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01c869ff98> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 3.521126760563389 6
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 6.690140845070438 18
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 10.211267605633827 23
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 22.88732394366204 49
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 25.70422535211275 56
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 29.577464788732485 69
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 29.577464788732485 77
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01c8696160> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d68> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 3.873239436619727 7
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 7.042253521126776 19
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 10.563380281690165 24
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 23.239436619718376 50
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 26.056338028169087 57
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 29.92957746478882 70
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 29.92957746478882 78
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c86f07b8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d68> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 1.7605633802816936 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 1.7605633802816936 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 4.577464788732405 8
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 7.746478873239454 20
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 11.267605633802843 25
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 23.943661971831055 51
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 26.760563380281766 58
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 30.6338028169015 71
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 30.6338028169015 79
Completed Iteration #8
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869f198> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01c869ff98> 2.1126760563380333 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 4.577464788732405 9
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 7.746478873239454 21
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 11.267605633802843 26
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 23.943661971831055 52
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 26.760563380281766 59
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 30.6338028169015 72
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 30.6338028169015 80
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01c8655dd8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86557f0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 4.929577464788743 10
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 8.098591549295792 22
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 11.61971830985918 27
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 24.29577464788739 53
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 27.112676056338103 60
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 30.985915492957837 73
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 30.985915492957837 81
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a979e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c869ff98> 2.1126760563380333 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 4.929577464788743 11
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 8.098591549295792 23
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 11.61971830985918 28
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 24.29577464788739 54
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 27.112676056338103 61
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 30.985915492957837 74
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 30.985915492957837 82
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86f04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 4.929577464788743 12
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 8.098591549295792 24
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 11.61971830985918 29
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 24.29577464788739 55
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 27.112676056338103 62
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 30.985915492957837 75
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 30.985915492957837 83
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8696a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 4.929577464788743 13
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 8.098591549295792 25
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 11.61971830985918 30
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 24.29577464788739 56
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 27.112676056338103 63
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 30.985915492957837 76
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 30.985915492957837 84
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5c50> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0080> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d30> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8644278> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9752b70> 1.7605633802816936 4
backprop <src.mcts.MCTS_Node object at 0x7f01c869ff98> 2.4647887323943714 7
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 5.281690140845081 14
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 8.45070422535213 26
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 11.971830985915519 31
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 24.647887323943728 57
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 27.46478873239444 64
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 31.338028169014173 77
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 31.338028169014173 85
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #6
root->4->1->1->12->2->29
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 2.1126760563380316 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 5.281690140845081 15
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 8.45070422535213 27
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 11.971830985915519 32
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 24.647887323943728 58
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 27.46478873239444 65
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 31.338028169014173 78
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 31.338028169014173 86
Completed Iteration #1
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5358> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 2.8169014084507094 7
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 5.9859154929577585 16
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 9.154929577464808 28
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 12.676056338028197 33
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 25.352112676056407 59
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 28.16901408450712 66
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 32.04225352112685 79
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 32.04225352112685 87
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01c86d57f0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d68> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 2.4647887323943696 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 3.1690140845070474 8
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 6.3380281690140965 17
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 9.507042253521146 29
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 13.028169014084535 34
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 25.704225352112744 60
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 28.521126760563455 67
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 32.39436619718319 80
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 32.39436619718319 88
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c8714048> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8714eb8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5358> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 3.873239436619725 9
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 7.042253521126774 18
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 10.211267605633823 30
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 13.732394366197212 35
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 26.408450704225423 61
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 29.225352112676134 68
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 33.09859154929587 81
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 33.09859154929587 89
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8644c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8714eb8> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5358> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 3.873239436619725 10
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 7.042253521126774 19
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 10.211267605633823 31
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 13.732394366197212 36
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 26.408450704225423 62
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 29.225352112676134 69
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 33.09859154929587 82
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 33.09859154929587 90
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 3.873239436619725 11
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 7.042253521126774 20
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 10.211267605633823 32
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 13.732394366197212 37
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 26.408450704225423 63
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 29.225352112676134 70
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 33.09859154929587 83
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 33.09859154929587 91
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c86d54e0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5438> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8714048> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8714eb8> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5358> 2.1126760563380333 5
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 4.577464788732403 12
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 7.746478873239452 21
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 10.915492957746501 33
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 14.43661971830989 38
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 27.112676056338103 64
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 29.929577464788814 71
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 33.80281690140855 84
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 33.80281690140855 92
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8714048> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8714eb8> 1.4084507042253556 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5358> 2.1126760563380333 6
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 4.577464788732403 13
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 7.746478873239452 22
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 10.915492957746501 34
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 14.43661971830989 39
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 27.112676056338103 65
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 29.929577464788814 72
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 33.80281690140855 85
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 33.80281690140855 93
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8714898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 4.577464788732403 14
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 7.746478873239452 23
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 10.915492957746501 35
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 14.43661971830989 40
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 27.112676056338103 66
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 29.929577464788814 73
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 33.80281690140855 86
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 33.80281690140855 94
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c8714c50> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 5.281690140845081 15
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 8.45070422535213 24
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 11.619718309859179 36
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 15.140845070422568 41
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 27.816901408450782 67
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 30.633802816901493 74
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 34.50704225352123 87
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 34.50704225352123 95
Completed Iteration #22
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01c8723710> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5438> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8714048> 1.7605633802816936 5
backprop <src.mcts.MCTS_Node object at 0x7f01c8714eb8> 1.7605633802816936 6
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5358> 2.4647887323943714 7
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 5.633802816901419 16
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 8.802816901408468 25
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 11.971830985915517 37
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 15.492957746478906 42
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 28.16901408450712 68
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 30.98591549295783 75
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 34.859154929577564 88
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 34.859154929577564 96
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01c8723080> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 5.985915492957757 17
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 9.154929577464806 26
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 12.323943661971855 38
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 15.845070422535244 43
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 28.521126760563455 69
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 31.338028169014166 76
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 35.2112676056339 89
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 35.2112676056339 97
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #7
root->4->1->1->12->2->29->1
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9752ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86f07b8> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d68> 1.4084507042253538 5
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 2.4647887323943696 7
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 5.985915492957757 18
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 9.154929577464806 27
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 12.323943661971855 39
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 15.845070422535244 44
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 28.521126760563455 70
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 31.338028169014166 77
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 35.2112676056339 90
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 35.2112676056339 98
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d68> 1.4084507042253538 6
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 2.4647887323943696 8
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 5.985915492957757 19
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 9.154929577464806 28
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 12.323943661971855 40
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 15.845070422535244 45
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 28.521126760563455 71
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 31.338028169014166 78
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 35.2112676056339 91
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 35.2112676056339 99
Completed Iteration #4
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a9782b70> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86f03c8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 3.1690140845070474 9
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 6.6901408450704345 20
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 9.859154929577484 29
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 13.028169014084533 41
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 16.549295774647923 46
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 29.225352112676134 72
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 32.042253521126845 79
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 35.91549295774658 92
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 35.91549295774658 100
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8714278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86f03c8> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 3.1690140845070474 10
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 6.6901408450704345 21
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 9.859154929577484 30
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 13.028169014084533 42
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 16.549295774647923 47
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 29.225352112676134 73
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 32.042253521126845 80
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 35.91549295774658 93
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 35.91549295774658 101
Completed Iteration #8
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8723a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8655dd8> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86557f0> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 3.1690140845070474 11
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 6.6901408450704345 22
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 9.859154929577484 31
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 13.028169014084533 43
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 16.549295774647923 48
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 29.225352112676134 74
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 32.042253521126845 81
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 35.91549295774658 94
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 35.91549295774658 102
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d68> 1.4084507042253538 7
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 3.1690140845070474 12
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 6.6901408450704345 23
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 9.859154929577484 32
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 13.028169014084533 44
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 16.549295774647923 49
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 29.225352112676134 75
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 32.042253521126845 82
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 35.91549295774658 95
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 35.91549295774658 103
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01c8723e48> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdc50> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86f07b8> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8696d68> 2.1126760563380316 8
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 3.873239436619725 13
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 7.394366197183112 24
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 10.563380281690161 33
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 13.73239436619721 45
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 17.253521126760603 50
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 29.929577464788814 76
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 32.746478873239525 83
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 36.61971830985926 96
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 36.61971830985926 104
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01c8731828> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd0b8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9782b70> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86f03c8> 1.0563380281690158 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8644f28> 4.225352112676063 14
backprop <src.mcts.MCTS_Node object at 0x7f01a97da2b0> 7.74647887323945 25
backprop <src.mcts.MCTS_Node object at 0x7f01a97d54e0> 10.9154929577465 34
backprop <src.mcts.MCTS_Node object at 0x7f01a9782cf8> 14.084507042253549 46
backprop <src.mcts.MCTS_Node object at 0x7f01a97fa4e0> 17.60563380281694 51
backprop <src.mcts.MCTS_Node object at 0x7f01a979e780> 30.28169014084515 77
backprop <src.mcts.MCTS_Node object at 0x7f01a97632b0> 33.09859154929586 84
backprop <src.mcts.MCTS_Node object at 0x7f01a9743d68> 36.971830985915595 97
backprop <src.mcts.MCTS_Node object at 0x7f01a9743828> 36.971830985915595 105
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #8
root->4->1->1->12->2->29->1->2
Best Reward: 0.7042253521126778
iteration: 29
found coverage increase 0.7042253521126778
Current Total Coverage 12.323943661971832
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8723e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8714e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8714e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8644438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8723ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8731f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8723358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8696ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87238d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8723630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 6
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8696cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8644128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87743c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8723ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87743c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87743c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd048> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87747f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87747f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8731f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875a5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87747f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c875aac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87238d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86cde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c875aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8723a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8723dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8774f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8696ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8714f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87238d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8714ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fdb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87232b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8644048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c8723128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 8
Completed Iteration #12
Best Reward: 0
coverage_call_count 1900
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a12b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a12b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c877df98> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0064048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8696198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8644828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877da20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87a16d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87316d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87316a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8723668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0020f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0020c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00202e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00777b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0077f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86d52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0077198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0077518> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86cdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8644828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e44e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c39e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87a19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0048400> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 13
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8723eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0020198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00128d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c873e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00123c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00205f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c873e5c0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d02543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 4
Completed Iteration #6
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0254048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c873e438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01d01fccc0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0254208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8723cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0020550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8723668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d00649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c8723e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26cceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cccf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0012c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c875a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0020550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fcb00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8668> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c86fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c8774ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3485320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c86cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c877da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a97d5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3485208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0262748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87f0550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0064c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25b80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e3485828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0262ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e25b8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01fce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2660cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2660fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2660080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34859b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2660358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26efcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26efcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26efcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2628710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26b72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e2660208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2628a20> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26606a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2660ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 12.323943661971832
cluster_index 5
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e26efb38> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 0.7042253521126742 2
Completed Iteration #0
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 1.4084507042253485 3
Completed Iteration #1
Best Reward: 0.7042253521126742
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87c3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 1.4084507042253485 4
Completed Iteration #2
Best Reward: 0.7042253521126742
Completed Iteration #3
Best Reward: 0.7042253521126742
Completed Iteration #4
Best Reward: 0.7042253521126742
Completed Iteration #5
Best Reward: 0.7042253521126742
Completed Iteration #6
Best Reward: 0.7042253521126742
Completed Iteration #7
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01c877d630> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 2.1126760563380227 5
Completed Iteration #8
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4a58> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d630> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 2.816901408450697 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 2.816901408450697 6
Completed Iteration #9
Best Reward: 0.7042253521126742
Completed Iteration #10
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 3.521126760563371 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 3.521126760563371 7
Completed Iteration #11
Best Reward: 0.7042253521126742
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 3.521126760563371 8
Completed Iteration #12
Best Reward: 0.7042253521126742
Completed Iteration #13
Best Reward: 0.7042253521126742
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0048cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 3.521126760563371 9
Completed Iteration #14
Best Reward: 0.7042253521126742
Completed Iteration #15
Best Reward: 0.7042253521126742
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0262b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 3.521126760563371 10
Completed Iteration #16
Best Reward: 0.7042253521126742
Completed Iteration #17
Best Reward: 0.7042253521126742
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d01fc7b8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 1.0563380281690105 3
backprop <src.mcts.MCTS_Node object at 0x7f01c877d630> 1.7605633802816847 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 3.8732394366197074 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 3.8732394366197074 11
Completed Iteration #18
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01d00127b8> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 4.577464788732382 8
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 4.577464788732382 12
Completed Iteration #19
Best Reward: 0.7042253521126742
Completed Iteration #20
Best Reward: 0.7042253521126742
Completed Iteration #21
Best Reward: 0.7042253521126742
Completed Iteration #22
Best Reward: 0.7042253521126742
Completed Iteration #23
Best Reward: 0.7042253521126742
Completed Iteration #24
Best Reward: 0.7042253521126742
Completed Iteration #25
Best Reward: 0.7042253521126742
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126742
Completed Iteration #0
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5898> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 5.281690140845056 9
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 5.281690140845056 13
Completed Iteration #1
Best Reward: 0.7042253521126742
Completed Iteration #2
Best Reward: 0.7042253521126742
Completed Iteration #3
Best Reward: 0.7042253521126742
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e34b59e8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5320> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5898> 1.0563380281690105 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 5.633802816901392 10
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 5.633802816901392 14
Completed Iteration #4
Best Reward: 0.7042253521126742
Completed Iteration #5
Best Reward: 0.7042253521126742
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01d0278cc0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02785c0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00127b8> 1.0563380281690105 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 5.985915492957728 11
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 5.985915492957728 15
Completed Iteration #6
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e26b7048> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 6.6901408450704025 12
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 6.6901408450704025 16
Completed Iteration #7
Best Reward: 0.7042253521126742
Completed Iteration #8
Best Reward: 0.7042253521126742
Completed Iteration #9
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01c877dfd0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02785c0> 1.0563380281690105 3
backprop <src.mcts.MCTS_Node object at 0x7f01d00127b8> 1.7605633802816847 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 7.394366197183077 13
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 7.394366197183077 17
Completed Iteration #10
Best Reward: 0.7042253521126742
Completed Iteration #11
Best Reward: 0.7042253521126742
Completed Iteration #12
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef390> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 8.098591549295751 14
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 8.098591549295751 18
Completed Iteration #13
Best Reward: 0.7042253521126742
Completed Iteration #14
Best Reward: 0.7042253521126742
Completed Iteration #15
Best Reward: 0.7042253521126742
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7f01e2628ba8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26cc1d0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4a58> 1.0563380281690105 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87e4be0> 1.4084507042253467 4
backprop <src.mcts.MCTS_Node object at 0x7f01c877d630> 2.112676056338021 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 8.450704225352087 15
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 8.450704225352087 19
Completed Iteration #16
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5400> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5320> 1.0563380281690105 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5898> 1.7605633802816847 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 9.154929577464761 16
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 9.154929577464761 20
Completed Iteration #17
Best Reward: 0.7042253521126742
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0012b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5320> 1.0563380281690105 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5898> 1.7605633802816847 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 9.154929577464761 17
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 9.154929577464761 21
Completed Iteration #18
Best Reward: 0.7042253521126742
Completed Iteration #19
Best Reward: 0.7042253521126742
Completed Iteration #20
Best Reward: 0.7042253521126742
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d0278f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01c877d630> 2.112676056338021 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 9.154929577464761 18
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 9.154929577464761 22
Completed Iteration #21
Best Reward: 0.7042253521126742
Completed Iteration #22
Best Reward: 0.7042253521126742
Completed Iteration #23
Best Reward: 0.7042253521126742
Completed Iteration #24
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e25ada58> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d00121d0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef390> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 9.859154929577436 19
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 9.859154929577436 23
Completed Iteration #25
Best Reward: 0.7042253521126742
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.7042253521126742
Completed Iteration #0
Best Reward: 0.7042253521126742
Completed Iteration #1
Best Reward: 0.7042253521126742
Completed Iteration #2
Best Reward: 0.7042253521126742
Completed Iteration #3
Best Reward: 0.7042253521126742
Completed Iteration #4
Best Reward: 0.7042253521126742
Completed Iteration #5
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 10.56338028169011 20
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 10.56338028169011 24
Completed Iteration #6
Best Reward: 0.7042253521126742
Completed Iteration #7
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 2.816901408450697 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 11.267605633802784 21
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 11.267605633802784 25
Completed Iteration #8
Best Reward: 0.7042253521126742
Completed Iteration #9
Best Reward: 0.7042253521126742
Completed Iteration #10
Best Reward: 0.7042253521126742
Completed Iteration #11
Best Reward: 0.7042253521126742
Completed Iteration #12
Best Reward: 0.7042253521126742
Completed Iteration #13
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e25d33c8> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 2.816901408450697 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 2.816901408450697 5
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 3.521126760563371 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 11.971830985915458 22
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 11.971830985915458 26
Completed Iteration #14
Best Reward: 0.7042253521126742
Completed Iteration #15
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e2637f98> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 3.521126760563371 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 4.225352112676045 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 12.676056338028133 23
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 12.676056338028133 27
Completed Iteration #16
Best Reward: 0.7042253521126742
Completed Iteration #17
Best Reward: 0.7042253521126742
Completed Iteration #18
Best Reward: 0.7042253521126742
Completed Iteration #19
Best Reward: 0.7042253521126742
Completed Iteration #20
Best Reward: 0.7042253521126742
Completed Iteration #21
Best Reward: 0.7042253521126742
Completed Iteration #22
Best Reward: 0.7042253521126742
Completed Iteration #23
Best Reward: 0.7042253521126742
Completed Iteration #24
Best Reward: 0.7042253521126742
Completed Iteration #25
Best Reward: 0.7042253521126742
Completed MCTS Level/Depth: #2
root->2->9
Best Reward: 0.7042253521126742
Completed Iteration #0
Best Reward: 0.7042253521126742
coverage_call_count 2300
Completed Iteration #1
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9978> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 4.225352112676045 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 4.92957746478872 8
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 13.380281690140807 24
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 13.380281690140807 28
Completed Iteration #2
Best Reward: 0.7042253521126742
Completed Iteration #3
Best Reward: 0.7042253521126742
Completed Iteration #4
Best Reward: 0.7042253521126742
Completed Iteration #5
Best Reward: 0.7042253521126742
Completed Iteration #6
Best Reward: 0.7042253521126742
Completed Iteration #7
Best Reward: 0.7042253521126742
Completed Iteration #8
Best Reward: 0.7042253521126742
Completed Iteration #9
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e3485438> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 4.92957746478872 8
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 5.633802816901394 9
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 14.084507042253481 25
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 14.084507042253481 29
Completed Iteration #10
Best Reward: 0.7042253521126742
Completed Iteration #11
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e25ad8d0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 5.633802816901394 9
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 6.338028169014068 10
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 14.788732394366155 26
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 14.788732394366155 30
Completed Iteration #12
Best Reward: 0.7042253521126742
Completed Iteration #13
Best Reward: 0.7042253521126742
Completed Iteration #14
Best Reward: 0.7042253521126742
Completed Iteration #15
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e34b5d30> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 6.338028169014068 10
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 7.042253521126742 11
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 15.49295774647883 27
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 15.49295774647883 31
Completed Iteration #16
Best Reward: 0.7042253521126742
Completed Iteration #17
Best Reward: 0.7042253521126742
Completed Iteration #18
Best Reward: 0.7042253521126742
Completed Iteration #19
Best Reward: 0.7042253521126742
Completed Iteration #20
Best Reward: 0.7042253521126742
Completed Iteration #21
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e25c0a58> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3d68> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26c9978> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 7.042253521126742 11
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 7.7464788732394165 12
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 16.197183098591502 28
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 16.197183098591502 32
Completed Iteration #22
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3908> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 7.7464788732394165 12
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 8.45070422535209 13
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 16.901408450704174 29
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 16.901408450704174 33
Completed Iteration #23
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01d020e1d0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d36a0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e3485438> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 8.45070422535209 13
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 9.154929577464765 14
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 17.605633802816847 30
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 17.605633802816847 34
Completed Iteration #24
Best Reward: 0.7042253521126742
Completed Iteration #25
Best Reward: 0.7042253521126742
Completed MCTS Level/Depth: #3
root->2->9->2
Best Reward: 0.7042253521126742
Completed Iteration #0
Best Reward: 0.7042253521126742
Completed Iteration #1
Best Reward: 0.7042253521126742
Completed Iteration #2
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e34d56a0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 2.816901408450697 5
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 3.521126760563371 6
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 9.154929577464765 14
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 9.85915492957744 15
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 18.30985915492952 31
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 18.30985915492952 35
Completed Iteration #3
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e25d3208> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5cc0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e25d33c8> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 3.521126760563371 6
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 4.225352112676045 7
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 9.85915492957744 15
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 10.563380281690113 16
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 19.01408450704219 32
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 19.01408450704219 36
Completed Iteration #4
Best Reward: 0.7042253521126742
Completed Iteration #5
Best Reward: 0.7042253521126742
Completed Iteration #6
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e2600ac8> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5128> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2637c50> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 4.225352112676045 7
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 4.92957746478872 8
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 10.563380281690113 16
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 11.267605633802788 17
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 19.718309859154864 33
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 19.718309859154864 37
Completed Iteration #7
Best Reward: 0.7042253521126742
Completed Iteration #8
Best Reward: 0.7042253521126742
Completed Iteration #9
Best Reward: 0.7042253521126742
Completed Iteration #10
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad320> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26adda0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 4.92957746478872 8
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 5.633802816901394 9
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 11.267605633802788 17
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 11.971830985915462 18
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 20.422535211267537 34
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 20.422535211267537 38
Completed Iteration #11
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad208> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 5.633802816901394 9
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 6.338028169014068 10
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 11.971830985915462 18
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 12.676056338028136 19
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 21.12676056338021 35
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 21.12676056338021 39
Completed Iteration #12
Best Reward: 0.7042253521126742
Completed Iteration #13
Best Reward: 0.7042253521126742
Completed Iteration #14
Best Reward: 0.7042253521126742
Completed Iteration #15
Best Reward: 0.7042253521126742
Completed Iteration #16
Best Reward: 0.7042253521126742
Completed Iteration #17
Best Reward: 0.7042253521126742
Completed Iteration #18
Best Reward: 0.7042253521126742
Completed Iteration #19
Best Reward: 0.7042253521126742
Completed Iteration #20
Best Reward: 0.7042253521126742
Completed Iteration #21
Best Reward: 0.7042253521126742
Completed Iteration #22
Best Reward: 0.7042253521126742
Completed Iteration #23
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01d020e048> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 6.338028169014068 10
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 7.042253521126742 11
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 12.676056338028136 19
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 13.38028169014081 20
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 21.83098591549288 36
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 21.83098591549288 40
Completed Iteration #24
Best Reward: 0.7042253521126742
Completed Iteration #25
Best Reward: 0.7042253521126742
Completed MCTS Level/Depth: #4
root->2->9->2->7
Best Reward: 0.7042253521126742
Completed Iteration #0
Best Reward: 0.7042253521126742
Completed Iteration #1
Best Reward: 0.7042253521126742
Completed Iteration #2
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e2600f98> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f022077f358> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020e048> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 7.042253521126742 11
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 7.7464788732394165 12
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 13.38028169014081 20
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 14.084507042253485 21
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 22.535211267605554 37
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 22.535211267605554 41
Completed Iteration #3
Best Reward: 0.7042253521126742
Completed Iteration #4
Best Reward: 0.7042253521126742
Completed Iteration #5
Best Reward: 0.7042253521126742
Completed Iteration #6
Best Reward: 0.7042253521126742
Completed Iteration #7
Best Reward: 0.7042253521126742
Completed Iteration #8
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5eb8> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e668> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26ad208> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 7.7464788732394165 12
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 8.45070422535209 13
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 14.084507042253485 21
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 14.788732394366159 22
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 23.239436619718226 38
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 23.239436619718226 42
Completed Iteration #9
Best Reward: 0.7042253521126742
Completed Iteration #10
Best Reward: 0.7042253521126742
Completed Iteration #11
Best Reward: 0.7042253521126742
Completed Iteration #12
Best Reward: 0.7042253521126742
Completed Iteration #13
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e26d7128> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e26adda0> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 8.45070422535209 13
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 9.154929577464765 14
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 14.788732394366159 22
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 15.492957746478833 23
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 23.9436619718309 39
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 23.9436619718309 43
Completed Iteration #14
Best Reward: 0.7042253521126742
Completed Iteration #15
Best Reward: 0.7042253521126742
Completed Iteration #16
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e26e14e0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 9.154929577464765 14
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 9.85915492957744 15
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 15.492957746478833 23
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 16.19718309859151 24
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 24.64788732394357 40
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 24.64788732394357 44
Completed Iteration #17
Best Reward: 0.7042253521126742
Completed Iteration #18
Best Reward: 0.7042253521126742
Completed Iteration #19
Best Reward: 0.7042253521126742
Completed Iteration #20
Best Reward: 0.7042253521126742
Completed Iteration #21
Best Reward: 0.7042253521126742
Completed Iteration #22
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e263e710> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e0b8> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d56a0> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 9.85915492957744 15
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 10.563380281690113 16
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 16.19718309859151 24
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 16.90140845070418 25
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 25.352112676056244 41
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 25.352112676056244 45
Completed Iteration #23
Best Reward: 0.7042253521126742
Completed Iteration #24
Best Reward: 0.7042253521126742
Completed Iteration #25
Best Reward: 0.7042253521126742
Completed MCTS Level/Depth: #5
root->2->9->2->7->0
Best Reward: 0.7042253521126742
Completed Iteration #0
Best Reward: 0.7042253521126742
Completed Iteration #1
Best Reward: 0.7042253521126742
Completed Iteration #2
Best Reward: 0.7042253521126742
Completed Iteration #3
Best Reward: 0.7042253521126742
Completed Iteration #4
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 2.816901408450697 5
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 10.563380281690113 16
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 11.267605633802788 17
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 16.90140845070418 25
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 17.605633802816854 26
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 26.056338028168916 42
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 26.056338028168916 46
Completed Iteration #5
Best Reward: 0.7042253521126742
Completed Iteration #6
Best Reward: 0.7042253521126742
Completed Iteration #7
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3518> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 3.521126760563371 6
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 11.267605633802788 17
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 11.971830985915462 18
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 17.605633802816854 26
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 18.309859154929526 27
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 26.76056338028159 43
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 26.76056338028159 47
Completed Iteration #8
Best Reward: 0.7042253521126742
Completed Iteration #9
Best Reward: 0.7042253521126742
Completed Iteration #10
Best Reward: 0.7042253521126742
Completed Iteration #11
Best Reward: 0.7042253521126742
Completed Iteration #12
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e267e908> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 4.225352112676045 7
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 11.971830985915462 18
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 12.676056338028136 19
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 18.309859154929526 27
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 19.0140845070422 28
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 27.46478873239426 44
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 27.46478873239426 48
Completed Iteration #13
Best Reward: 0.7042253521126742
Completed Iteration #14
Best Reward: 0.7042253521126742
Completed Iteration #15
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01d020ef60> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 2.816901408450697 5
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 4.92957746478872 8
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 12.676056338028136 19
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 13.38028169014081 20
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 19.0140845070422 28
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 19.71830985915487 29
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 28.169014084506934 45
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 28.169014084506934 49
Completed Iteration #16
Best Reward: 0.7042253521126742
Completed Iteration #17
Best Reward: 0.7042253521126742
Completed Iteration #18
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e263e7b8> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 3.521126760563371 6
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 5.633802816901394 9
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 13.38028169014081 20
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 14.084507042253485 21
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 19.71830985915487 29
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 20.422535211267544 30
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 28.873239436619606 46
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 28.873239436619606 50
Completed Iteration #19
Best Reward: 0.7042253521126742
Completed Iteration #20
Best Reward: 0.7042253521126742
Completed Iteration #21
Best Reward: 0.7042253521126742
Completed Iteration #22
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e260ce48> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 4.225352112676045 7
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 6.338028169014068 10
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 14.084507042253485 21
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 14.788732394366159 22
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 20.422535211267544 30
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 21.126760563380216 31
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 29.57746478873228 47
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 29.57746478873228 51
Completed Iteration #23
Best Reward: 0.7042253521126742
Completed Iteration #24
Best Reward: 0.7042253521126742
Completed Iteration #25
Best Reward: 0.7042253521126742
Completed MCTS Level/Depth: #6
root->2->9->2->7->0->25
Best Reward: 0.7042253521126742
Completed Iteration #0
Best Reward: 0.7042253521126742
coverage_call_count 2400
Completed Iteration #1
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e25841d0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e2584f60> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3518> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 4.92957746478872 8
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 7.042253521126742 11
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 14.788732394366159 22
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 15.492957746478833 23
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 21.126760563380216 31
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 21.83098591549289 32
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 30.28169014084495 48
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 30.28169014084495 52
Completed Iteration #2
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea358> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 5.633802816901394 9
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 7.7464788732394165 12
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 15.492957746478833 23
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 16.19718309859151 24
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 21.83098591549289 32
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 22.53521126760556 33
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 30.985915492957623 49
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 30.985915492957623 53
Completed Iteration #3
Best Reward: 0.7042253521126742
Completed Iteration #4
Best Reward: 0.7042253521126742
Completed Iteration #5
Best Reward: 0.7042253521126742
Completed Iteration #6
Best Reward: 0.7042253521126742
Completed Iteration #7
Best Reward: 0.7042253521126742
Completed Iteration #8
Best Reward: 0.7042253521126742
Completed Iteration #9
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9dd8> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea390> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e263e7b8> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 6.338028169014068 10
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 8.45070422535209 13
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 16.19718309859151 24
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 16.90140845070418 25
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 22.53521126760556 33
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 23.239436619718234 34
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 31.690140845070296 50
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 31.690140845070296 54
Completed Iteration #10
Best Reward: 0.7042253521126742
Completed Iteration #11
Best Reward: 0.7042253521126742
Completed Iteration #12
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9240> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9278> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e267e908> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 2.816901408450697 5
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 7.042253521126742 11
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 9.154929577464765 14
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 16.90140845070418 25
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 17.605633802816854 26
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 23.239436619718234 34
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 23.943661971830906 35
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 32.39436619718297 51
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 32.39436619718297 55
Completed Iteration #13
Best Reward: 0.7042253521126742
Completed Iteration #14
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e263e5c0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea390> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e263e7b8> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 7.7464788732394165 12
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 9.85915492957744 15
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 17.605633802816854 26
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 18.309859154929526 27
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 23.943661971830906 35
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 24.64788732394358 36
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 33.09859154929564 52
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 33.09859154929564 56
Completed Iteration #15
Best Reward: 0.7042253521126742
Completed Iteration #16
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e26adac8> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3ba8> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020ef60> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 2.816901408450697 5
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 3.521126760563371 6
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 8.45070422535209 13
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 10.563380281690113 16
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 18.309859154929526 27
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 19.0140845070422 28
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 24.64788732394358 36
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 25.35211267605625 37
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 33.80281690140831 53
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 33.80281690140831 57
Completed Iteration #17
Best Reward: 0.7042253521126742
Completed Iteration #18
Best Reward: 0.7042253521126742
Completed Iteration #19
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01e267e630> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9278> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e267e908> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 3.521126760563371 6
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 4.225352112676045 7
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 9.154929577464765 14
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 11.267605633802788 17
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 19.0140845070422 28
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 19.71830985915487 29
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 25.35211267605625 37
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 26.056338028168923 38
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 34.507042253520986 54
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 34.507042253520986 58
Completed Iteration #20
Best Reward: 0.7042253521126742
Completed Iteration #21
Best Reward: 0.7042253521126742
Completed Iteration #22
Best Reward: 0.7042253521126742
Completed Iteration #23
Best Reward: 0.7042253521126742
Completed Iteration #24
Best Reward: 0.7042253521126742
Completed Iteration #25
Best Reward: 0.7042253521126742
Completed MCTS Level/Depth: #7
root->2->9->2->7->0->25->0
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01a976e630> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3ba8> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d020ef60> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 4.225352112676045 7
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 4.92957746478872 8
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 9.85915492957744 15
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 11.971830985915462 18
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 19.71830985915487 29
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 20.422535211267544 30
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 26.056338028168923 38
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 26.760563380281596 39
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 35.21126760563366 55
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 35.21126760563366 59
Completed Iteration #0
Best Reward: 0.7042253521126742
Completed Iteration #1
Best Reward: 0.7042253521126742
Completed Iteration #2
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01a976ec88> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 4.92957746478872 8
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 5.633802816901394 9
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 10.563380281690113 16
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 12.676056338028136 19
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 20.422535211267544 30
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 21.126760563380216 31
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 26.760563380281596 39
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 27.46478873239427 40
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 35.91549295774633 56
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 35.91549295774633 60
Completed Iteration #3
Best Reward: 0.7042253521126742
Completed Iteration #4
Best Reward: 0.7042253521126742
Completed Iteration #5
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01a9716b70> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 5.633802816901394 9
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 6.338028169014068 10
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 11.267605633802788 17
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 13.38028169014081 20
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 21.126760563380216 31
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 21.83098591549289 32
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 27.46478873239427 40
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 28.16901408450694 41
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 36.619718309859 57
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 36.619718309859 61
Completed Iteration #6
Best Reward: 0.7042253521126742
Completed Iteration #7
Best Reward: 0.7042253521126742
Completed Iteration #8
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01a9716518> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 6.338028169014068 10
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 7.042253521126742 11
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 11.971830985915462 18
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 14.084507042253485 21
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 21.83098591549289 32
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 22.53521126760556 33
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 28.16901408450694 41
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 28.873239436619613 42
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 37.323943661971676 58
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 37.323943661971676 62
Completed Iteration #9
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01a9725400> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9278> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01e267e908> 2.816901408450697 5
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 7.042253521126742 11
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 7.7464788732394165 12
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 12.676056338028136 19
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 14.788732394366159 22
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 22.53521126760556 33
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 23.239436619718234 34
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 28.873239436619613 42
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 29.577464788732286 43
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 38.02816901408435 59
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 38.02816901408435 63
Completed Iteration #10
Best Reward: 0.7042253521126742
Completed Iteration #11
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3320> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 7.7464788732394165 12
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 8.45070422535209 13
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 13.38028169014081 20
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 15.492957746478833 23
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 23.239436619718234 34
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 23.943661971830906 35
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 29.577464788732286 43
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 30.281690140844958 44
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 38.73239436619702 60
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 38.73239436619702 64
Completed Iteration #12
Best Reward: 0.7042253521126742
Completed Iteration #13
Best Reward: 0.7042253521126742
Completed Iteration #14
Best Reward: 0.7042253521126742
Completed Iteration #15
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01a976e0f0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976e0b8> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9716518> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 8.45070422535209 13
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 9.154929577464765 14
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 14.084507042253485 21
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 16.19718309859151 24
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 23.943661971830906 35
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 24.64788732394358 36
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 30.281690140844958 44
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 30.98591549295763 45
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 39.43661971830969 61
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 39.43661971830969 65
Completed Iteration #16
Best Reward: 0.7042253521126742
Completed Iteration #17
Best Reward: 0.7042253521126742
Completed Iteration #18
Best Reward: 0.7042253521126742
Completed Iteration #19
Best Reward: 0.7042253521126742
Completed Iteration #20
Best Reward: 0.7042253521126742
Completed Iteration #21
Best Reward: 0.7042253521126742
Completed Iteration #22
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01a9725be0> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9725c88> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976ec88> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 9.154929577464765 14
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 9.85915492957744 15
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 14.788732394366159 22
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 16.90140845070418 25
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 24.64788732394358 36
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 25.35211267605625 37
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 30.98591549295763 45
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 31.690140845070303 46
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 40.140845070422365 62
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 40.140845070422365 66
Completed Iteration #23
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01a9725160> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9278> 2.816901408450697 5
backprop <src.mcts.MCTS_Node object at 0x7f01e267e908> 3.521126760563371 6
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 9.85915492957744 15
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 10.563380281690113 16
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 15.492957746478833 23
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 17.605633802816854 26
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 25.35211267605625 37
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 26.056338028168923 38
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 31.690140845070303 46
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 32.394366197182975 47
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 40.84507042253504 63
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 40.84507042253504 67
Completed Iteration #24
Best Reward: 0.7042253521126742
Reward: 0.7042253521126742
backprop <src.mcts.MCTS_Node object at 0x7f01a9716898> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be278> 0.7042253521126742 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976e630> 1.4084507042253485 3
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3ba8> 2.1126760563380227 4
backprop <src.mcts.MCTS_Node object at 0x7f01d020ef60> 2.816901408450697 5
backprop <src.mcts.MCTS_Node object at 0x7f01e34d5240> 10.563380281690113 16
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3a58> 11.267605633802788 17
backprop <src.mcts.MCTS_Node object at 0x7f01d01c3898> 16.19718309859151 24
backprop <src.mcts.MCTS_Node object at 0x7f01d02784a8> 18.309859154929526 27
backprop <src.mcts.MCTS_Node object at 0x7f01d0278470> 26.056338028168923 38
backprop <src.mcts.MCTS_Node object at 0x7f01c87b4c18> 26.760563380281596 39
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef320> 32.394366197182975 47
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef6a0> 33.09859154929565 48
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef2e8> 41.54929577464771 64
backprop <src.mcts.MCTS_Node object at 0x7f01e26ef4e0> 41.54929577464771 68
Completed Iteration #25
Best Reward: 0.7042253521126742
Completed MCTS Level/Depth: #8
root->2->9->2->7->0->25->0->5
Best Reward: 0.7042253521126742
iteration: 47
found coverage increase 0.7042253521126742
Current Total Coverage 13.028169014084506
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a96be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a96be9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a96beb00> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 0.352112676056338 4
Completed Iteration #2
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a96bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 0.352112676056338 5
Completed Iteration #3
Best Reward: 0.352112676056338
Completed Iteration #4
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e34d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d020ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 0.352112676056338 6
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9716080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 0.352112676056338 7
Completed Iteration #8
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 0.352112676056338 8
Completed Iteration #9
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a9725a58> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 0.704225352112676 9
Completed Iteration #10
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9725ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 0.704225352112676 5
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 0.704225352112676 10
Completed Iteration #11
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 0.704225352112676 11
Completed Iteration #12
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9725860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 0.704225352112676 6
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 0.704225352112676 12
Completed Iteration #13
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 0.704225352112676 13
Completed Iteration #14
Best Reward: 0.352112676056338
Completed Iteration #15
Best Reward: 0.352112676056338
Completed Iteration #16
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 1.056338028169014 7
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 1.056338028169014 14
Completed Iteration #17
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a96be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9725860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 1.056338028169014 8
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 1.056338028169014 15
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a976eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 1.056338028169014 9
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 1.056338028169014 16
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a85ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 1.056338028169014 17
Completed Iteration #24
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a85ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96be898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 1.056338028169014 18
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #0
root
Best Reward: 0.352112676056338
Completed Iteration #0
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a85efe48> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85efc18> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 1.408450704225352 10
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 1.408450704225352 19
Completed Iteration #1
Best Reward: 0.352112676056338
Completed Iteration #2
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a858e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 1.408450704225352 11
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 1.408450704225352 20
Completed Iteration #3
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a85efe10> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a858e438> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beb00> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 1.76056338028169 12
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 1.76056338028169 21
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a858e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 1.76056338028169 13
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 1.76056338028169 22
Completed Iteration #7
Best Reward: 0.352112676056338
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a858eef0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a858eb38> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9725a58> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 2.112676056338028 14
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 2.112676056338028 23
Completed Iteration #10
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a859b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a859b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01ea898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 2.112676056338028 15
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 2.112676056338028 24
Completed Iteration #11
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a858ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a859b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a858eef0> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a858eb38> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9725a58> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 2.112676056338028 16
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 2.112676056338028 25
Completed Iteration #12
Best Reward: 0.352112676056338
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a858ec88> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beda0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 2.816901408450706 17
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 2.816901408450706 26
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a9716b38> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 3.169014084507044 18
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 3.169014084507044 27
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a858e198> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c34e0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85efe48> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85efc18> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 1.7605633802816918 5
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 3.521126760563382 19
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 3.521126760563382 28
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a858e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85efc18> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 1.7605633802816918 6
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 3.521126760563382 20
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 3.521126760563382 29
Completed Iteration #17
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a96becf8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a858e438> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96beb00> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 3.87323943661972 21
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 3.87323943661972 30
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e263e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9725860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 3.87323943661972 22
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 3.87323943661972 31
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a85ef710> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85efeb8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beb00> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 4.225352112676058 23
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 4.225352112676058 32
Completed Iteration #22
Best Reward: 0.7042253521126778
coverage_call_count 2500
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9725ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 4.225352112676058 24
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 4.225352112676058 33
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01e26e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beda0> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 1.7605633802816918 7
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 4.225352112676058 25
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 4.225352112676058 34
Completed Iteration #0
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a859b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01eac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a858ec88> 0.7042253521126778 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96beda0> 0.7042253521126778 4
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 1.7605633802816918 8
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 4.225352112676058 26
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 4.225352112676058 35
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a9716c50> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beda0> 1.0563380281690158 5
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 2.11267605633803 9
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 4.577464788732396 27
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 4.577464788732396 36
Completed Iteration #3
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a859b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a859b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 2.11267605633803 10
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 4.577464788732396 28
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 4.577464788732396 37
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beda0> 1.0563380281690158 6
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 2.11267605633803 11
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 4.577464788732396 29
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 4.577464788732396 38
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a85b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beda0> 1.0563380281690158 7
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 2.11267605633803 12
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 4.577464788732396 30
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 4.577464788732396 39
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1e80> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 2.464788732394368 13
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 4.929577464788734 31
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 4.929577464788734 40
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a859b6a0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 2.816901408450706 14
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 5.281690140845072 32
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 5.281690140845072 41
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a85ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a96beda0> 1.0563380281690158 8
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 2.816901408450706 15
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 5.281690140845072 33
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 5.281690140845072 42
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a85ba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01d01c34e0> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85efe48> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7f01a85efc18> 0.704225352112676 5
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 2.816901408450706 16
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 5.281690140845072 34
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 5.281690140845072 43
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #2
root->2->14
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01d01d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1e80> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 2.816901408450706 17
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 5.281690140845072 35
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 5.281690140845072 44
Completed Iteration #0
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a9716128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 0.704225352112676 5
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 2.816901408450706 18
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 5.281690140845072 36
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 5.281690140845072 45
Completed Iteration #1
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a858e940> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 1.056338028169014 6
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 3.169014084507044 19
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 5.63380281690141 37
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 5.63380281690141 46
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 1.408450704225352 7
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 3.521126760563382 20
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 5.985915492957748 38
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 5.985915492957748 47
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1f28> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1b70> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1e80> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 1.76056338028169 8
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 3.87323943661972 21
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 6.338028169014086 39
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 6.338028169014086 48
Completed Iteration #7
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a85ba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 1.76056338028169 9
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 3.87323943661972 22
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 6.338028169014086 40
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 6.338028169014086 49
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a859bc18> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1b70> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1e80> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 2.112676056338028 10
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 4.225352112676058 23
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 6.690140845070424 41
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 6.690140845070424 50
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a85bacc0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 2.464788732394366 11
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 4.577464788732396 24
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 7.042253521126762 42
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 7.042253521126762 51
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a8555780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a858e940> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 2.464788732394366 12
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 4.577464788732396 25
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 7.042253521126762 43
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 7.042253521126762 52
Completed Iteration #19
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a8555b38> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 2.816901408450704 13
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 4.929577464788734 26
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 7.3943661971831 44
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 7.3943661971831 53
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #3
root->2->14->0
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a8563550> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 3.169014084507042 14
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 5.281690140845072 27
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 7.746478873239438 45
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 7.746478873239438 54
Completed Iteration #0
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 1.76056338028169 6
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 3.52112676056338 15
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 5.63380281690141 28
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 8.098591549295776 46
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 8.098591549295776 55
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a8563f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8563550> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 1.408450704225352 6
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 1.76056338028169 7
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 3.52112676056338 16
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 5.63380281690141 29
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 8.098591549295776 47
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 8.098591549295776 56
Completed Iteration #3
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a85eff60> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 2.11267605633803 7
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 2.464788732394368 8
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 4.225352112676058 17
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 6.338028169014088 30
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 8.802816901408454 48
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 8.802816901408454 57
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a859b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 2.464788732394368 9
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 4.225352112676058 18
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 6.338028169014088 31
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 8.802816901408454 49
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 8.802816901408454 58
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a85ba710> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 2.464788732394368 8
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 2.816901408450706 10
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 4.577464788732396 19
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 6.690140845070426 32
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 9.154929577464792 50
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 9.154929577464792 59
Completed Iteration #8
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a8555278> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 2.816901408450706 9
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 3.169014084507044 11
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 4.929577464788734 20
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 7.042253521126764 33
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 9.50704225352113 51
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 9.50704225352113 60
Completed Iteration #9
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a85ba828> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8555860> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8555278> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 3.169014084507044 10
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 3.521126760563382 12
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 5.281690140845072 21
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 7.394366197183102 34
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 9.859154929577468 52
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 9.859154929577468 61
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a8563278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8555f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85bacc0> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 3.169014084507044 11
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 3.521126760563382 13
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 5.281690140845072 22
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 7.394366197183102 35
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 9.859154929577468 53
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 9.859154929577468 62
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a8563cf8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8563940> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 3.87323943661972 14
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 5.63380281690141 23
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 7.74647887323944 36
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 10.211267605633806 54
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 10.211267605633806 63
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a857c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a857c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 3.87323943661972 15
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 5.63380281690141 24
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 7.74647887323944 37
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 10.211267605633806 55
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 10.211267605633806 64
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a857c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 3.169014084507044 12
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 3.87323943661972 16
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 5.63380281690141 25
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 7.74647887323944 38
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 10.211267605633806 56
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 10.211267605633806 65
Completed Iteration #16
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a857c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 3.169014084507044 13
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 3.87323943661972 17
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 5.63380281690141 26
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 7.74647887323944 39
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 10.211267605633806 57
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 10.211267605633806 66
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a857cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8563208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85ba710> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 3.169014084507044 14
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 3.87323943661972 18
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 5.63380281690141 27
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 7.74647887323944 40
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 10.211267605633806 58
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 10.211267605633806 67
Completed Iteration #19
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 1.7605633802816936 4
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 3.8732394366197216 15
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 4.577464788732398 19
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 6.338028169014088 28
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 8.450704225352117 41
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 10.915492957746483 59
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 10.915492957746483 68
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a858e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a858e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8555b38> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 3.8732394366197216 16
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 4.577464788732398 20
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 6.338028169014088 29
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 8.450704225352117 42
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 10.915492957746483 60
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 10.915492957746483 69
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a85634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8555630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 4.577464788732398 21
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 6.338028169014088 30
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 8.450704225352117 43
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 10.915492957746483 61
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 10.915492957746483 70
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #4
root->2->14->0->3
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a85ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85bacc0> 0.352112676056338 4
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 3.8732394366197216 17
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 4.577464788732398 22
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 6.338028169014088 31
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 8.450704225352117 44
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 10.915492957746483 62
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 10.915492957746483 71
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a857c048> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 4.22535211267606 18
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 4.929577464788736 23
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 6.690140845070426 32
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 8.802816901408455 45
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 11.267605633802821 63
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 11.267605633802821 72
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a8512160> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 4.577464788732398 19
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 5.281690140845074 24
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 7.042253521126764 33
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 9.154929577464793 46
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 11.61971830985916 64
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 11.61971830985916 73
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a85ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8563d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85ba828> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a8555860> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a8555278> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 4.577464788732398 20
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 5.281690140845074 25
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 7.042253521126764 34
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 9.154929577464793 47
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 11.61971830985916 65
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 11.61971830985916 74
Completed Iteration #10
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a85129b0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 4.929577464788736 21
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 5.633802816901412 26
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 7.394366197183102 35
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 9.507042253521131 48
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 11.971830985915497 66
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 11.971830985915497 75
Completed Iteration #11
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a8512c88> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8512a58> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8563550> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 5.281690140845074 22
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 5.98591549295775 27
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 7.74647887323944 36
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 9.85915492957747 49
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 12.323943661971835 67
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 12.323943661971835 76
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a8523358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85129b0> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 5.281690140845074 23
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 5.98591549295775 28
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 7.74647887323944 37
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 9.85915492957747 50
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 12.323943661971835 68
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 12.323943661971835 77
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a857cb38> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8512be0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8555b38> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 5.633802816901412 24
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 6.338028169014088 29
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 8.098591549295778 38
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 10.211267605633807 51
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 12.676056338028173 69
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 12.676056338028173 78
Completed Iteration #16
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a97258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a976e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85ba710> 0.352112676056338 4
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 5.633802816901412 25
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 6.338028169014088 30
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 8.098591549295778 39
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 10.211267605633807 52
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 12.676056338028173 70
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 12.676056338028173 79
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a85b13c8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 5.98591549295775 26
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 6.690140845070426 31
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 8.450704225352116 40
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 10.563380281690145 53
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 13.028169014084511 71
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 13.028169014084511 80
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a85125c0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8512be0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a8555b38> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 6.338028169014088 27
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 7.042253521126764 32
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 8.802816901408454 41
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 10.915492957746483 54
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 13.38028169014085 72
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 13.38028169014085 81
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a8563978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8512160> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 6.338028169014088 28
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 7.042253521126764 33
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 8.802816901408454 42
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 10.915492957746483 55
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 13.38028169014085 73
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 13.38028169014085 82
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
coverage_call_count 2600
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #5
root->2->14->0->3->1
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a8523780> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85236d8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 2.4647887323943714 5
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 7.042253521126765 29
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 7.746478873239441 34
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 9.507042253521131 43
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 11.619718309859161 56
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 14.084507042253527 74
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 14.084507042253527 83
Completed Iteration #1
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a8523c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8523ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 2.1126760563380333 5
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 2.4647887323943714 6
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 7.042253521126765 30
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 7.746478873239441 35
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 9.507042253521131 44
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 11.619718309859161 57
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 14.084507042253527 75
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 14.084507042253527 84
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a8523b00> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 2.4647887323943714 6
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 2.8169014084507094 7
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 7.394366197183103 31
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 8.09859154929578 36
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 9.85915492957747 45
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 11.9718309859155 58
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 14.436619718309865 76
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 14.436619718309865 85
Completed Iteration #6
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a852e7b8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a852e470> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8523b00> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 2.8169014084507094 7
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 3.1690140845070474 8
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 7.746478873239441 32
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 8.450704225352117 37
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 10.211267605633807 46
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 12.323943661971837 59
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 14.788732394366203 77
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 14.788732394366203 86
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a8534470> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8534240> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8523780> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85236d8> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 1.7605633802816936 5
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 3.1690140845070474 8
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 3.5211267605633854 9
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 8.09859154929578 33
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 8.802816901408455 38
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 10.563380281690145 47
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 12.676056338028175 60
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 15.140845070422541 78
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 15.140845070422541 87
Completed Iteration #11
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a85ba080> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8555668> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 3.8732394366197234 10
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 8.450704225352117 34
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 9.154929577464793 39
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 10.915492957746483 48
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 13.028169014084513 61
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 15.49295774647888 79
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 15.49295774647888 88
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a8512ac8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a852e470> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a8523b00> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 3.5211267605633854 9
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 4.225352112676061 11
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 8.802816901408455 35
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 9.507042253521131 40
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 11.267605633802821 49
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 13.380281690140851 62
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 15.845070422535217 80
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 15.845070422535217 89
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a85234a8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 4.225352112676063 10
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 4.929577464788739 12
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 9.507042253521133 36
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 10.21126760563381 41
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 11.9718309859155 50
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 14.084507042253529 63
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 16.549295774647895 81
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 16.549295774647895 90
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a8523ef0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85236d8> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 2.1126760563380316 6
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 4.577464788732401 11
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 5.281690140845077 13
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 9.859154929577471 37
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 10.563380281690147 42
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 12.323943661971837 51
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 14.436619718309867 64
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 16.90140845070423 82
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 16.90140845070423 91
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a85340f0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a857c8d0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 5.985915492957755 14
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 10.563380281690149 38
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 11.267605633802825 43
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 13.028169014084515 52
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 15.140845070422545 65
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 17.60563380281691 83
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 17.60563380281691 92
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #6
root->2->14->0->3->1->2
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a84d15c0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a84d1390> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a852e7b8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a852e470> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7f01a8523b00> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 4.929577464788739 12
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 6.338028169014093 15
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 10.915492957746487 39
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 11.619718309859163 44
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 13.380281690140853 53
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 15.492957746478883 66
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 17.957746478873247 84
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 17.957746478873247 93
Completed Iteration #5
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a84d1ac8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a84d1908> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85eff60> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 5.281690140845077 13
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 6.690140845070431 16
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 11.267605633802825 40
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 11.971830985915501 45
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 13.732394366197191 54
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 15.84507042253522 67
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 18.309859154929583 85
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 18.309859154929583 94
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a84d9048> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a84d91d0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85234a8> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 5.633802816901415 14
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 7.042253521126769 17
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 11.619718309859163 41
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 12.323943661971839 46
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 14.084507042253529 55
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 16.19718309859156 68
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 18.66197183098592 86
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 18.66197183098592 95
Completed Iteration #8
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a84d96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 5.633802816901415 15
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 7.042253521126769 18
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 11.619718309859163 42
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 12.323943661971839 47
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 14.084507042253529 56
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 16.19718309859156 69
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 18.66197183098592 87
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 18.66197183098592 96
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a8534588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8523b00> 1.408450704225352 6
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 5.633802816901415 16
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 7.042253521126769 19
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 11.619718309859163 43
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 12.323943661971839 48
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 14.084507042253529 57
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 16.19718309859156 70
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 18.66197183098592 88
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 18.66197183098592 97
Completed Iteration #16
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a8534630> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 6.338028169014093 17
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 7.746478873239447 20
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 12.32394366197184 44
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 13.028169014084517 49
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 14.788732394366207 58
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 16.90140845070424 71
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 19.3661971830986 89
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 19.3661971830986 98
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a84d13c8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8523668> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85234a8> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 6.690140845070431 18
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 8.098591549295785 21
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 12.676056338028179 45
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 13.380281690140855 50
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 15.140845070422545 59
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 17.253521126760575 72
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 19.718309859154935 90
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 19.718309859154935 99
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a84d1a58> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a857c978> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 2.8169014084507094 7
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 7.394366197183109 19
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 8.802816901408463 22
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 13.380281690140857 46
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 14.084507042253533 51
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 15.845070422535223 60
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 17.957746478873254 73
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 20.422535211267615 91
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 20.422535211267615 100
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a84d94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 7.394366197183109 20
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 8.802816901408463 23
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 13.380281690140857 47
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 14.084507042253533 52
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 15.845070422535223 61
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 17.957746478873254 74
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 20.422535211267615 92
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 20.422535211267615 101
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #7
root->2->14->0->3->1->2->7
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a84d9ef0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85236d8> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 3.521126760563387 8
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 8.098591549295787 21
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 9.50704225352114 24
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 14.084507042253534 48
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 14.78873239436621 53
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 16.549295774647902 62
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 18.661971830985934 75
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 21.126760563380294 93
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 21.126760563380294 102
Completed Iteration #0
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a852e9e8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a84d1b38> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a84d1a58> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a857c978> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 3.873239436619725 9
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 8.450704225352125 22
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 9.859154929577478 25
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 14.436619718309872 49
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 15.140845070422548 54
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 16.90140845070424 63
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 19.01408450704227 76
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 21.47887323943663 94
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 21.47887323943663 103
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a84f7cf8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85236d8> 2.8169014084507094 6
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 4.577464788732403 10
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 9.154929577464802 23
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 10.563380281690156 26
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 15.14084507042255 50
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 15.845070422535226 55
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 17.605633802816918 64
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 19.71830985915495 77
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 22.18309859154931 95
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 22.18309859154931 104
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f01a84d9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85236d8> 2.8169014084507094 7
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 4.577464788732403 11
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 9.154929577464802 24
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 10.563380281690156 27
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 15.14084507042255 51
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 15.845070422535226 56
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 17.605633802816918 65
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 19.71830985915495 78
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 22.18309859154931 96
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 22.18309859154931 105
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a84d9fd0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a84d9940> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a84d9ef0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85236d8> 3.521126760563387 8
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 5.281690140845081 12
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 9.85915492957748 25
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 11.267605633802834 28
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 15.845070422535228 52
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 16.549295774647902 57
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 18.309859154929597 66
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 20.42253521126763 79
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 22.88732394366199 97
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 22.88732394366199 106
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a84d9b00> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a857c978> 1.7605633802816936 4
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 5.9859154929577585 13
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 10.563380281690158 26
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 11.971830985915512 29
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 16.549295774647906 53
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 17.25352112676058 58
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 19.014084507042277 67
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 21.12676056338031 80
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 23.59154929577467 98
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 23.59154929577467 107
Completed Iteration #16
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a84f7c88> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a84d1b38> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7f01a84d1a58> 1.7605633802816936 4
backprop <src.mcts.MCTS_Node object at 0x7f01a857c978> 2.4647887323943714 5
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 6.690140845070436 14
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 11.267605633802836 27
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 12.67605633802819 30
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 17.25352112676058 54
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 17.95774647887326 59
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 19.718309859154957 68
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 21.830985915492988 81
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 24.29577464788735 99
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 24.29577464788735 108
Completed Iteration #17
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a84d1780> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a857c978> 3.169014084507049 6
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 7.394366197183114 15
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 11.971830985915513 28
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 13.380281690140867 31
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 17.95774647887326 55
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 18.66197183098594 60
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 20.422535211267636 69
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 22.535211267605668 82
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 25.00000000000003 100
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 25.00000000000003 109
Completed Iteration #18
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a8480160> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a857c978> 3.873239436619727 7
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 8.098591549295792 16
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 12.676056338028191 29
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 14.084507042253545 32
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 18.66197183098594 56
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 19.36619718309862 61
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 21.126760563380316 70
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 23.239436619718347 83
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 25.704225352112708 101
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 25.704225352112708 110
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7f01a8480710> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a85efac8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 8.80281690140847 17
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 13.380281690140869 30
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 14.788732394366223 33
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 19.36619718309862 57
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 20.0704225352113 62
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 21.830985915492995 71
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 23.943661971831027 84
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 26.408450704225388 102
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 26.408450704225388 111
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7f01a8499080> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8480e80> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7f01a8523ef0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7f01a85236d8> 3.873239436619725 9
backprop <src.mcts.MCTS_Node object at 0x7f01a857ce48> 9.154929577464808 18
backprop <src.mcts.MCTS_Node object at 0x7f01a9725f60> 13.732394366197207 31
backprop <src.mcts.MCTS_Node object at 0x7f01a8563a90> 15.14084507042256 34
backprop <src.mcts.MCTS_Node object at 0x7f01a85babe0> 19.718309859154957 58
backprop <src.mcts.MCTS_Node object at 0x7f01a859b588> 20.422535211267636 63
backprop <src.mcts.MCTS_Node object at 0x7f01a85b1a90> 22.18309859154933 72
backprop <src.mcts.MCTS_Node object at 0x7f01a96bed30> 24.295774647887363 85
backprop <src.mcts.MCTS_Node object at 0x7f01a96beac8> 26.760563380281724 103
backprop <src.mcts.MCTS_Node object at 0x7f01a96be630> 26.760563380281724 112
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #8
root->2->14->0->3->1->2->7->0
Best Reward: 0.7042253521126778
iteration: 48
found coverage increase 0.7042253521126778
Current Total Coverage 13.732394366197184
initial coverage: 9.50704
time passed (minutes): 65.1316
iterations: 49
number of new inputs: 448
final coverage: 13.7324
total coverage increase: 4.22535
