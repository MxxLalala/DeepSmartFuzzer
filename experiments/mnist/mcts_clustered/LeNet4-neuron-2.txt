Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'neuron'], random_seed=2, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7f1a823d0f28>, tc2=<function tc2 at 0x7f1a823e2048>, tc3=<function tc3 at 0x7f1a823e2158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 69.0141
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186969e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865eb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865eb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18647358> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc67f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdab38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186740f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc65f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0facac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0facc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdad68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0faccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f421d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f802e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 200
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0face48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f429b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f422e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f421d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0faccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f429b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f506a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f509e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f500f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facc88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f500f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186740f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186740f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186740f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186742e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f207f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 300
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f207f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f207f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4e0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20a58> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0face48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e876d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e985f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a4e5abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e985f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e985f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb26d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e985f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb29e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18720668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e980f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186478d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e980f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0facbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f801d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0face10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f801d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f808d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f801d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f808d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f504e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f801d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f806a0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e980f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187044a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18647be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1048> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 600
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186471d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186740b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186471d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0face10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0face10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0face10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f672b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f675f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 700
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186964e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186964e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e875f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e875f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e875f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00984a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed95c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00aeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00981d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00aeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00981d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aeba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00aecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aeba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0facbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e980f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e980f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aeef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aeef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1e80> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00896a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00896a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00896a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00786d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00786a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 900
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00612e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00612e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00612e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00895c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00612e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00980f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00980f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae390> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0054400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00549b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f001c940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00546a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 1000
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d47b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00895c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72d49b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729da20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729da20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 1100
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00614e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00614e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac0f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0054cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00540b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f001c710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72107b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72202e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00782b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00782b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00782b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72100f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 1200
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a724af28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0527b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0527b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72ede80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0011d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0015c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0011d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a052ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029a58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0527f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0290b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a0296d8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d740f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1992d74898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00895c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00784e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00780f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0078a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f672e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f672e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc65f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc65f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00781d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff16d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18674e10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a908> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f426d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1aa0507ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f500b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00784a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00619b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 1700
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a4e5abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a4e5abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb25f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4c88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e874a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00613c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0faca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d16d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d16d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1a90> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed92e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9240> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00546d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00541d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186749b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00546d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00546d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b00> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e987f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e987f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 15
Completed Iteration #24
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e987f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0297f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186963c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0297f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0297f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18696438> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052208> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186749b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00546d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e874a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72101d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72101d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72101d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09bac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72107b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72107b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72eddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a898> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72716a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0014e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a727d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00aedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae9e8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d872e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d128> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d334a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d334a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 16
Completed Iteration #14
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d334a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33cc0> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.7042253521126725 10
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.7042253521126725 11
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.7042253521126725 12
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.7042253521126725 13
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.7042253521126725 14
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 1.408450704225345 15
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4dd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 2.1126760563380174 16
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 2.1126760563380174 17
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 2.1126760563380174 18
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1992d877f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4dd8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 2.81690140845069 19
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 2.81690140845069 10
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 2.81690140845069 20
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 2.81690140845069 21
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1992d87f98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 3.5211267605633623 12
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 3.5211267605633623 22
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 3.5211267605633623 13
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 3.5211267605633623 23
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 3.5211267605633623 14
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 3.5211267605633623 24
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4518> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 3.5211267605633623 15
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 3.5211267605633623 25
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 3.5211267605633623 16
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 3.5211267605633623 26
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 3.5211267605633623 17
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 3.5211267605633623 27
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 3.5211267605633623 18
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 3.5211267605633623 28
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 3.5211267605633623 19
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 3.5211267605633623 29
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19a724abe0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 4.225352112676035 20
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 4.225352112676035 30
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4518> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 4.225352112676035 21
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 4.225352112676035 31
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87e10> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4dd8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 4.225352112676035 22
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 4.225352112676035 32
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c96080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2780> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 4.929577464788707 12
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 4.929577464788707 23
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 4.929577464788707 33
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96080> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2780> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 4.929577464788707 13
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 4.929577464788707 24
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 4.929577464788707 34
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19a7210588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d877f0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d87e10> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4dd8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 5.63380281690138 14
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 5.63380281690138 25
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 5.63380281690138 35
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990d336a0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052358> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724abe0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2780> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 6.338028169014052 15
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 6.338028169014052 26
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 6.338028169014052 36
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d877f0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d87e10> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4dd8> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 6.338028169014052 16
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 6.338028169014052 27
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 6.338028169014052 37
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19a7271860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2780> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 7.0422535211267245 17
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 7.0422535211267245 28
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 7.0422535211267245 38
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052358> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724abe0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2780> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 7.0422535211267245 18
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 7.0422535211267245 29
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 7.0422535211267245 39
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c962e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4518> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 7.746478873239397 19
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 7.746478873239397 30
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 7.746478873239397 40
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c962e8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4518> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 7.746478873239397 20
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 7.746478873239397 31
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 7.746478873239397 41
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87f98> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4518> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 7.746478873239397 21
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 7.746478873239397 32
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 7.746478873239397 42
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c96c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c968d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96080> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2780> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 6.338028169014052 14
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 8.45070422535207 22
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 8.45070422535207 33
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 8.45070422535207 43
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990ca40f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2780> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 9.154929577464742 23
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 9.154929577464742 34
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 9.154929577464742 44
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 7.746478873239397 16
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 9.859154929577414 24
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 9.859154929577414 35
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 9.859154929577414 45
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87f98> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4518> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 9.859154929577414 25
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 9.859154929577414 36
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 9.859154929577414 46
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 9.859154929577414 26
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 9.859154929577414 37
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 9.859154929577414 47
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4668> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 7.746478873239397 17
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 9.859154929577414 27
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 9.859154929577414 38
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 9.859154929577414 48
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4518> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 10.563380281690087 28
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 10.563380281690087 39
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 10.563380281690087 49
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 8.45070422535207 18
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 11.26760563380276 29
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 11.26760563380276 40
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 11.26760563380276 50
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c96128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 11.971830985915432 30
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 11.971830985915432 41
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 11.971830985915432 51
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->4->19
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96128> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 9.154929577464742 20
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 11.971830985915432 31
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 11.971830985915432 42
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 11.971830985915432 52
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271860> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2780> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 9.154929577464742 21
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 11.971830985915432 32
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 11.971830985915432 43
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 11.971830985915432 53
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 4.929577464788707 12
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 9.154929577464742 22
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 11.971830985915432 33
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 11.971830985915432 44
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 11.971830985915432 54
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990ca49b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96128> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 9.859154929577414 23
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 12.676056338028104 34
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 12.676056338028104 45
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 12.676056338028104 55
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 10.563380281690087 24
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 13.380281690140777 35
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 13.380281690140777 46
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 13.380281690140777 56
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96c50> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c968d0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c96080> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2780> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 4.929577464788707 13
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 10.563380281690087 25
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 13.380281690140777 36
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 13.380281690140777 47
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 13.380281690140777 57
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 4.929577464788707 14
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 10.563380281690087 26
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 13.380281690140777 37
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 13.380281690140777 48
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 13.380281690140777 58
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 11.26760563380276 27
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 14.084507042253449 38
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 14.084507042253449 49
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 14.084507042253449 59
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990cf22b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 11.971830985915432 28
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 14.788732394366122 39
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 14.788732394366122 50
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 14.788732394366122 60
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c96c88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4668> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 12.676056338028104 29
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 15.492957746478794 40
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 15.492957746478794 51
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 15.492957746478794 61
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 4.929577464788707 15
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 12.676056338028104 30
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 15.492957746478794 41
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 15.492957746478794 52
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 15.492957746478794 62
Completed Iteration #14
Best Reward: 0.7042253521126725
coverage_call_count 2300
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990ca46a0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 13.380281690140777 31
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 16.197183098591466 42
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 16.197183098591466 53
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 16.197183098591466 63
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 14.084507042253449 32
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 16.90140845070414 43
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 16.90140845070414 54
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 16.90140845070414 64
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87e10> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4dd8> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 14.788732394366122 33
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 17.60563380281681 44
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 17.60563380281681 55
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 17.60563380281681 65
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->4->19->5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d5c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 15.492957746478794 34
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 18.309859154929484 45
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 18.309859154929484 56
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 18.309859154929484 66
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d5c0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d630> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 16.197183098591466 35
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 19.014084507042156 46
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 19.014084507042156 57
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 19.014084507042156 67
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dbe0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 16.90140845070414 36
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 19.71830985915483 47
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 19.71830985915483 58
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 19.71830985915483 68
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a1d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d630> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 17.60563380281681 37
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 20.4225352112675 48
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 20.4225352112675 59
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 20.4225352112675 69
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 17.60563380281681 38
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 20.4225352112675 49
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 20.4225352112675 60
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 20.4225352112675 70
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 17.60563380281681 39
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 20.4225352112675 50
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 20.4225352112675 61
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 20.4225352112675 71
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a9b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a7b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dbe0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 18.309859154929484 40
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 21.126760563380174 51
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 21.126760563380174 62
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 21.126760563380174 72
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a1d0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d630> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 6.338028169014052 12
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 7.0422535211267245 14
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 19.014084507042156 41
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 21.830985915492846 52
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 21.830985915492846 63
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 21.830985915492846 73
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 19.014084507042156 42
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 21.830985915492846 53
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 21.830985915492846 64
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 21.830985915492846 74
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 6.338028169014052 14
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 7.0422535211267245 16
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 19.014084507042156 43
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 21.830985915492846 54
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 21.830985915492846 65
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 21.830985915492846 75
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 7.0422535211267245 17
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 19.014084507042156 44
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 21.830985915492846 55
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 21.830985915492846 66
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 21.830985915492846 76
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->4->19->5->13
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c4deb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca49e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a9b0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a7b8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dbe0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 7.746478873239397 18
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 19.71830985915483 45
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 22.53521126760552 56
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 22.53521126760552 67
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 22.53521126760552 77
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 7.0422535211267245 16
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 7.746478873239397 19
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 19.71830985915483 46
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 22.53521126760552 57
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 22.53521126760552 68
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 22.53521126760552 78
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d630> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 7.0422535211267245 17
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 7.746478873239397 20
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 19.71830985915483 47
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 22.53521126760552 58
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 22.53521126760552 69
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 22.53521126760552 79
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a198> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a828> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a1d0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d630> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 7.0422535211267245 18
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 7.746478873239397 21
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 19.71830985915483 48
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 22.53521126760552 59
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 22.53521126760552 70
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 22.53521126760552 80
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c5af28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4278> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c96128> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 7.746478873239397 19
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 8.45070422535207 22
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 20.4225352112675 49
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 23.23943661971819 60
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 23.23943661971819 71
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 23.23943661971819 81
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 8.45070422535207 20
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 9.154929577464742 23
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 21.126760563380174 50
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 23.943661971830863 61
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 23.943661971830863 72
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 23.943661971830863 82
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 8.45070422535207 21
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 9.154929577464742 24
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 21.126760563380174 51
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 23.943661971830863 62
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 23.943661971830863 73
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 23.943661971830863 83
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca49b0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4278> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c96128> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 8.45070422535207 22
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 9.154929577464742 25
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 21.126760563380174 52
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 23.943661971830863 63
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 23.943661971830863 74
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 23.943661971830863 84
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 8.45070422535207 23
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 9.154929577464742 26
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 21.126760563380174 53
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 23.943661971830863 64
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 23.943661971830863 75
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 23.943661971830863 85
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbc27f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 9.154929577464742 24
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 9.859154929577414 27
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 21.830985915492846 54
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 24.647887323943536 65
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 24.647887323943536 76
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 24.647887323943536 86
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c70c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 9.859154929577414 25
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 10.563380281690087 28
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 22.53521126760552 55
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 25.35211267605621 66
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 25.35211267605621 77
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 25.35211267605621 87
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 10.563380281690087 26
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 11.26760563380276 29
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 23.23943661971819 56
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 26.05633802816888 67
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 26.05633802816888 78
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 26.05633802816888 88
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 10.563380281690087 27
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 11.26760563380276 30
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 23.23943661971819 57
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 26.05633802816888 68
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 26.05633802816888 79
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 26.05633802816888 89
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->4->19->5->13->6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 11.26760563380276 28
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 11.971830985915432 31
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 23.943661971830863 58
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 26.760563380281553 69
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 26.760563380281553 80
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 26.760563380281553 90
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 11.971830985915432 29
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 12.676056338028104 32
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 24.647887323943536 59
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 27.464788732394226 70
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 27.464788732394226 81
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 27.464788732394226 91
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 11.971830985915432 30
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 12.676056338028104 33
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 24.647887323943536 60
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 27.464788732394226 71
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 27.464788732394226 82
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 27.464788732394226 92
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990d33d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 12.676056338028104 31
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 13.380281690140777 34
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 25.35211267605621 61
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 28.169014084506898 72
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 28.169014084506898 83
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 28.169014084506898 93
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c967b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc27f0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 13.380281690140777 32
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 14.084507042253449 35
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 26.05633802816888 62
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 28.87323943661957 73
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 28.87323943661957 84
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 28.87323943661957 94
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbc28d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc29b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a438> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 14.084507042253449 33
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 14.788732394366122 36
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 26.760563380281553 63
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 29.577464788732243 74
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 29.577464788732243 85
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 29.577464788732243 95
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 14.788732394366122 34
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 15.492957746478794 37
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 27.464788732394226 64
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 30.281690140844916 75
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 30.281690140844916 86
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 30.281690140844916 96
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0a20> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 15.492957746478794 35
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 16.197183098591466 38
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 28.169014084506898 65
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 30.985915492957588 76
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 30.985915492957588 87
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 30.985915492957588 97
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0eb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 16.197183098591466 36
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 16.90140845070414 39
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 28.87323943661957 66
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 31.69014084507026 77
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 31.69014084507026 88
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 31.69014084507026 98
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 16.90140845070414 37
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 17.60563380281681 40
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 29.577464788732243 67
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 32.39436619718293 78
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 32.39436619718293 89
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 32.39436619718293 99
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a6d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70b00> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 17.60563380281681 38
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 18.309859154929484 41
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 30.281690140844916 68
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 33.098591549295605 79
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 33.098591549295605 90
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 33.098591549295605 100
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6f28> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a6d8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1240> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c70b00> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 17.60563380281681 39
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 18.309859154929484 42
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 30.281690140844916 69
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 33.098591549295605 80
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 33.098591549295605 91
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 33.098591549295605 101
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70b00> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 18.309859154929484 40
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 19.014084507042156 43
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 30.985915492957588 70
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 33.80281690140828 81
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 33.80281690140828 92
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 33.80281690140828 102
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 9.154929577464742 17
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 18.309859154929484 41
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 19.014084507042156 44
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 30.985915492957588 71
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 33.80281690140828 82
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 33.80281690140828 93
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 33.80281690140828 103
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1160> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70710> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbc27f0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 9.859154929577414 18
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 19.014084507042156 42
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 19.71830985915483 45
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 31.69014084507026 72
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 34.50704225352095 83
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 34.50704225352095 94
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 34.50704225352095 104
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->4->19->5->13->6->3
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1b38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 10.563380281690087 19
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 19.71830985915483 43
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 20.4225352112675 46
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 32.39436619718293 73
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 35.21126760563362 84
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 35.21126760563362 95
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 35.21126760563362 105
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a438> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 10.563380281690087 20
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 19.71830985915483 44
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 20.4225352112675 47
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 32.39436619718293 74
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 35.21126760563362 85
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 35.21126760563362 96
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 35.21126760563362 106
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0860> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 10.563380281690087 21
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 19.71830985915483 45
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 20.4225352112675 48
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 32.39436619718293 75
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 35.21126760563362 86
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 35.21126760563362 97
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 35.21126760563362 107
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70be0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 11.26760563380276 22
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 20.4225352112675 46
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 21.126760563380174 49
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 33.098591549295605 76
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 35.915492957746295 87
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 35.915492957746295 98
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 35.915492957746295 108
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f199a01ae10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 11.971830985915432 23
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 21.126760563380174 47
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 21.830985915492846 50
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 33.80281690140828 77
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 36.61971830985897 88
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 36.61971830985897 99
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 36.61971830985897 109
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0dd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 12.676056338028104 24
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 21.830985915492846 48
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 22.53521126760552 51
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 34.50704225352095 78
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 37.32394366197164 89
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 37.32394366197164 100
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 37.32394366197164 110
Completed Iteration #12
Best Reward: 0.7042253521126725
coverage_call_count 2400
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1c88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d780> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70be0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 10.563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 13.380281690140777 25
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 22.53521126760552 49
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 23.23943661971819 52
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 35.21126760563362 79
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 38.02816901408431 90
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 38.02816901408431 101
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 38.02816901408431 111
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1b38> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 10.563380281690087 19
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 13.380281690140777 26
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 22.53521126760552 50
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 23.23943661971819 53
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 35.21126760563362 80
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 38.02816901408431 91
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 38.02816901408431 102
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 38.02816901408431 112
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbdd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70b70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33d30> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 6.338028169014052 12
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 11.26760563380276 20
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 14.084507042253449 27
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 23.23943661971819 51
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 23.943661971830863 54
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 35.915492957746295 81
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 38.732394366196985 92
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 38.732394366196985 103
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 38.732394366196985 113
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bb95400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 14.788732394366122 28
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 23.943661971830863 52
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 24.647887323943536 55
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 36.61971830985897 82
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 39.43661971830966 93
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 39.43661971830966 104
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 39.43661971830966 114
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1b38> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 11.971830985915432 22
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 14.788732394366122 29
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 23.943661971830863 53
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 24.647887323943536 56
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 36.61971830985897 83
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 39.43661971830966 94
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 39.43661971830966 105
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 39.43661971830966 115
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->4->19->5->13->6->3->0
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95400> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 7.0422535211267245 14
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 11.971830985915432 23
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 14.788732394366122 30
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 23.943661971830863 54
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 24.647887323943536 57
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 36.61971830985897 84
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 39.43661971830966 95
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 39.43661971830966 106
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 39.43661971830966 116
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbe80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc29b0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a438> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 7.746478873239397 15
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 12.676056338028104 24
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 15.492957746478794 31
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 24.647887323943536 55
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 25.35211267605621 58
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 37.32394366197164 85
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 40.14084507042233 96
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 40.14084507042233 107
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 40.14084507042233 117
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a0f0> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 7.746478873239397 16
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 12.676056338028104 25
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 15.492957746478794 32
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 24.647887323943536 56
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 25.35211267605621 59
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 37.32394366197164 86
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 40.14084507042233 97
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 40.14084507042233 108
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 40.14084507042233 118
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bb95b38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95eb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 8.45070422535207 17
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 13.380281690140777 26
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 16.197183098591466 33
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 25.35211267605621 57
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 26.05633802816888 60
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 38.02816901408431 87
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 40.845070422535 98
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 40.845070422535 109
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 40.845070422535 119
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95eb8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 8.45070422535207 18
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 13.380281690140777 27
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 16.197183098591466 34
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 25.35211267605621 58
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 26.05633802816888 61
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 38.02816901408431 88
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 40.845070422535 99
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 40.845070422535 110
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 40.845070422535 120
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0860> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 8.45070422535207 19
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 13.380281690140777 28
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 16.197183098591466 35
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 25.35211267605621 59
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 26.05633802816888 62
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 38.02816901408431 89
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 40.845070422535 100
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 40.845070422535 111
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 40.845070422535 121
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bb9cd68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9cb38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95400> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 9.154929577464742 20
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2908> 14.084507042253449 29
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 16.90140845070414 36
backprop <src.mcts.MCTS_Node object at 0x7f1990c96fd0> 26.05633802816888 60
backprop <src.mcts.MCTS_Node object at 0x7f1990cc44a8> 26.760563380281553 63
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf278> 38.732394366196985 90
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2630> 41.549295774647675 101
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 41.549295774647675 112
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 41.549295774647675 122
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->4->19->5->13->6->3->0->16
Best Reward: 0.7042253521126725
iteration: 86
found coverage increase 0.7042253521126725
Current Total Coverage 69.71830985915493
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb37b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e10> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a6d8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d1d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bacbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbc88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 15
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf72e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badda90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00892b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c963c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990d33550> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c962b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c962b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d332e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf76d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf76d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198badd828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0014e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72714e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00aee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae198> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d877f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf74e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d877f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d877f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00610b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990ca47f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72101d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72101d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72101d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72101d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72101d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 9
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0299e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.7042253521126725 18
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.7042253521126725 19
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.7042253521126725 20
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.7042253521126725 21
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72202e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.7042253521126725 6
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.7042253521126725 22
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.7042253521126725 7
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 0.7042253521126725 23
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19a7220400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 1.408450704225345 24
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 2.1126760563380174 25
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a4e5abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 2.1126760563380174 10
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 2.1126760563380174 26
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 2.81690140845069 27
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 3.5211267605633623 12
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 3.5211267605633623 28
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 3.5211267605633623 13
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 3.5211267605633623 29
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d335f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 3.5211267605633623 14
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 3.5211267605633623 30
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf1d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 4.225352112676035 15
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 4.225352112676035 31
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f199a029828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 4.929577464788707 16
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 4.929577464788707 32
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c5abe0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0630> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ba8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 5.63380281690138 17
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 5.63380281690138 33
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 5.63380281690138 18
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 5.63380281690138 34
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9a90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ba8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 6.338028169014052 19
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 6.338028169014052 35
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 7.0422535211267245 20
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 7.0422535211267245 36
Completed Iteration #22
Best Reward: 0.7042253521126725
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5abe0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f198baf7470> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0630> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ba8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 7.0422535211267245 21
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 7.0422535211267245 37
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f199a0c08d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 7.746478873239397 22
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 7.746478873239397 38
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029828> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 7.746478873239397 23
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 7.746478873239397 39
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1992d87160> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ba8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 8.45070422535207 24
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 8.45070422535207 40
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e4a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09ba90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87160> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ba8> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 9.154929577464742 25
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 9.154929577464742 41
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 9.859154929577414 26
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 9.859154929577414 42
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f00616a0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72edcf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9a90> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ba8> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 10.563380281690087 27
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 10.563380281690087 43
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029828> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 10.563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 11.26760563380276 28
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 11.26760563380276 44
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf828> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a390> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 10.563380281690087 19
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 11.26760563380276 29
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 11.26760563380276 45
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19a7271c88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 11.26760563380276 20
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 11.971830985915432 30
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 11.971830985915432 46
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1992de3828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ba8> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 12.676056338028104 31
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 12.676056338028104 47
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19a729da20> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187045c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9a90> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ba8> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 12.676056338028104 22
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 13.380281690140777 32
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 13.380281690140777 48
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1992d87a20> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 13.380281690140777 23
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 14.084507042253449 33
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 14.084507042253449 49
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f001c2b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf1d0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 14.788732394366122 34
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 14.788732394366122 50
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c5af28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a390> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 14.788732394366122 25
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 15.492957746478794 35
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 15.492957746478794 51
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19a724a860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d208> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf1d0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 15.492957746478794 26
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 16.197183098591466 36
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 16.197183098591466 52
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->6->19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19a7271400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 16.197183098591466 27
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 16.90140845070414 37
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 16.90140845070414 53
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98cf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 16.90140845070414 28
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 17.60563380281681 38
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 17.60563380281681 54
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 17.60563380281681 29
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 18.309859154929484 39
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 18.309859154929484 55
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 10.563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 18.309859154929484 30
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 19.014084507042156 40
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 19.014084507042156 56
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1a186aae10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42eb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c2b0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d208> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf1d0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 19.014084507042156 31
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 19.71830985915483 41
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 19.71830985915483 57
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1a186475f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647dd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4e10> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4780> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 11.971830985915432 19
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 19.71830985915483 32
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 20.4225352112675 42
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 20.4225352112675 58
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 12.676056338028104 20
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 20.4225352112675 33
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 21.126760563380174 43
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 21.126760563380174 59
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271400> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 13.380281690140777 21
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 21.126760563380174 34
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 21.830985915492846 44
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 21.830985915492846 60
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c5afd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 14.084507042253449 22
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 21.830985915492846 35
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 22.53521126760552 45
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 22.53521126760552 61
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c08d0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 14.084507042253449 23
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 21.830985915492846 36
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 22.53521126760552 46
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 22.53521126760552 62
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac0b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271c88> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 14.788732394366122 24
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 22.53521126760552 37
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 23.23943661971819 47
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 23.23943661971819 63
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->6->19->8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4780> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 15.492957746478794 25
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 23.23943661971819 38
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 23.943661971830863 48
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 23.943661971830863 64
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4780> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 16.197183098591466 26
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 23.943661971830863 39
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 24.647887323943536 49
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 24.647887323943536 65
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50fd0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4780> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 16.197183098591466 27
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 23.943661971830863 40
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 24.647887323943536 50
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 24.647887323943536 66
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186475f8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1a18647dd8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4e10> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4780> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 16.90140845070414 28
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 24.647887323943536 41
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 25.35211267605621 51
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 25.35211267605621 67
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00787b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 9.154929577464742 17
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 16.90140845070414 29
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 24.647887323943536 42
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 25.35211267605621 52
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 25.35211267605621 68
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d940> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271400> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 9.859154929577414 18
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 17.60563380281681 30
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 25.35211267605621 43
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 26.05633802816888 53
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 26.05633802816888 69
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1a18674358> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 10.563380281690087 19
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 18.309859154929484 31
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 26.05633802816888 44
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 26.760563380281553 54
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 26.760563380281553 70
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1320> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186475f8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1a18647dd8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4e10> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4780> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 10.563380281690087 20
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 18.309859154929484 32
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 26.05633802816888 45
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 26.760563380281553 55
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 26.760563380281553 71
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0f504e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006ae10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6630> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 11.26760563380276 21
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 19.014084507042156 33
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 26.760563380281553 46
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 27.464788732394226 56
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 27.464788732394226 72
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->6->19->8->16
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 11.26760563380276 22
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 19.014084507042156 34
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 26.760563380281553 47
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 27.464788732394226 57
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 27.464788732394226 73
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006ae10> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6630> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 11.971830985915432 23
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 19.71830985915483 35
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 27.464788732394226 48
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 28.169014084506898 58
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 28.169014084506898 74
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0078668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f504e0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2006ae10> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6630> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 7.746478873239397 15
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 11.971830985915432 24
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 19.71830985915483 36
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 27.464788732394226 49
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 28.169014084506898 59
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 28.169014084506898 75
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d940> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7271400> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 7.746478873239397 16
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 11.971830985915432 25
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 19.71830985915483 37
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 27.464788732394226 50
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 28.169014084506898 60
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 28.169014084506898 76
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0098940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 8.45070422535207 17
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 12.676056338028104 26
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 20.4225352112675 38
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 28.169014084506898 51
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 28.87323943661957 61
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 28.87323943661957 77
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098940> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 8.45070422535207 18
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 12.676056338028104 27
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 20.4225352112675 39
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 28.169014084506898 52
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 28.87323943661957 62
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 28.87323943661957 78
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdada0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c08d0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 13.380281690140777 28
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 21.126760563380174 40
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 28.87323943661957 53
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 29.577464788732243 63
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 29.577464788732243 79
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1aa0507ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 9.859154929577414 20
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 14.084507042253449 29
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 21.830985915492846 41
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 29.577464788732243 54
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 30.281690140844916 64
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 30.281690140844916 80
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1990c96748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 10.563380281690087 21
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 14.788732394366122 30
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 22.53521126760552 42
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 30.281690140844916 55
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 30.985915492957588 65
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 30.985915492957588 81
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 11.26760563380276 22
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 15.492957746478794 31
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 23.23943661971819 43
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 30.985915492957588 56
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 31.69014084507026 66
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 31.69014084507026 82
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
coverage_call_count 3100
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa4a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cfd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87a20> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 11.971830985915432 23
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 16.197183098591466 32
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 23.943661971830863 44
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 31.69014084507026 57
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 32.39436619718293 67
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 32.39436619718293 83
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0098ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098940> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 12.676056338028104 24
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 16.90140845070414 33
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 24.647887323943536 45
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 32.39436619718293 58
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 33.098591549295605 68
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 33.098591549295605 84
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac978> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 13.380281690140777 25
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 17.60563380281681 34
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 25.35211267605621 46
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 33.098591549295605 59
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 33.80281690140828 69
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 33.80281690140828 85
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->6->19->8->16->7
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18674358> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 13.380281690140777 26
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 17.60563380281681 35
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 25.35211267605621 47
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 33.098591549295605 60
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 33.80281690140828 70
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 33.80281690140828 86
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1992d749e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 14.084507042253449 27
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 18.309859154929484 36
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 26.05633802816888 48
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 33.80281690140828 61
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 34.50704225352095 71
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 34.50704225352095 87
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1992d742e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d744e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d749e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 14.788732394366122 28
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 19.014084507042156 37
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 26.760563380281553 49
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 34.50704225352095 62
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 35.21126760563362 72
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 35.21126760563362 88
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 14.788732394366122 29
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 19.014084507042156 38
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 26.760563380281553 50
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 34.50704225352095 63
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 35.21126760563362 73
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 35.21126760563362 89
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc68d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 6.338028169014052 14
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 15.492957746478794 30
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 19.71830985915483 39
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 27.464788732394226 51
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 35.21126760563362 64
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 35.915492957746295 74
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 35.915492957746295 90
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cf28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cfd0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d87a20> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 16.197183098591466 31
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 20.4225352112675 40
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 28.169014084506898 52
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 35.915492957746295 65
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 36.61971830985897 75
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 36.61971830985897 91
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00789e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cf28> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cfd0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d87a20> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c978> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 7.0422535211267245 16
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 16.197183098591466 32
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 20.4225352112675 41
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 28.169014084506898 53
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 35.915492957746295 66
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 36.61971830985897 76
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 36.61971830985897 92
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 7.0422535211267245 17
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 16.197183098591466 33
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 20.4225352112675 42
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 28.169014084506898 54
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 35.915492957746295 67
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 36.61971830985897 77
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 36.61971830985897 93
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f1a18715160> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc68d0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67d30> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 7.746478873239397 18
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 16.90140845070414 34
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 21.126760563380174 43
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 28.87323943661957 55
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 36.61971830985897 68
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 37.32394366197164 78
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 37.32394366197164 94
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 7.746478873239397 19
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 16.90140845070414 35
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 21.126760563380174 44
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 28.87323943661957 56
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 36.61971830985897 69
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 37.32394366197164 79
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 37.32394366197164 95
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->6->19->8->16->7->2
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bacb198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbe10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc68d0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67d30> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 8.45070422535207 20
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 17.60563380281681 36
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 21.830985915492846 45
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 29.577464788732243 57
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 37.32394366197164 70
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 38.02816901408431 80
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 38.02816901408431 96
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc68d0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67d30> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 9.154929577464742 21
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 18.309859154929484 37
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 22.53521126760552 46
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 30.281690140844916 58
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 38.02816901408431 71
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 38.732394366196985 81
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 38.732394366196985 97
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67d30> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 9.859154929577414 22
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 19.014084507042156 38
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 23.23943661971819 47
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 30.985915492957588 59
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 38.732394366196985 72
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 39.43661971830966 82
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 39.43661971830966 98
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bacb7b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67d30> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 10.563380281690087 23
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 19.71830985915483 39
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 23.943661971830863 48
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 31.69014084507026 60
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 39.43661971830966 73
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 40.14084507042233 83
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 40.14084507042233 99
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc68d0> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67d30> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 10.563380281690087 24
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 19.71830985915483 40
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 23.943661971830863 49
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 31.69014084507026 61
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 39.43661971830966 74
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 40.14084507042233 84
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 40.14084507042233 100
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->6->19->8->16->7->2->8
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715160> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74240> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc68d0> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67d30> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 10.563380281690087 25
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 19.71830985915483 41
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 23.943661971830863 50
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 31.69014084507026 62
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 39.43661971830966 75
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 40.14084507042233 85
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 40.14084507042233 101
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbe10> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc68d0> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67d30> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 11.26760563380276 26
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 20.4225352112675 42
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 24.647887323943536 51
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 32.39436619718293 63
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 40.14084507042233 76
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 40.845070422535 86
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 40.845070422535 102
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bb18d68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715160> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d74240> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc68d0> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67d30> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 11.971830985915432 27
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 21.126760563380174 43
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 25.35211267605621 52
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 33.098591549295605 64
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 40.845070422535 77
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 41.549295774647675 87
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 41.549295774647675 103
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f198bbe10f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd04a8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f198bacbe10> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc68d0> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67d30> 6.338028169014052 12
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac2e8> 12.676056338028104 28
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0780> 21.830985915492846 44
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c940> 26.05633802816888 53
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 33.80281690140828 65
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 41.549295774647675 78
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 42.25352112676035 88
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc50> 42.25352112676035 104
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->6->19->8->16->7->2->8->10
Best Reward: 0.7042253521126725
iteration: 107
found coverage increase 0.7042253521126725
Current Total Coverage 70.4225352112676
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d746d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd09e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1be0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb953c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f60> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3df28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3df28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 3300
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb056a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb951d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb95240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb687b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4765c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb687b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb689b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b4762b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb320> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4148d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4148d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4148d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4148d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198bb05470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb056a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adedf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adedac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adedef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb180f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414eb8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfdeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad430f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adafd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad436d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 3600
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add5e10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad362b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad369e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad364e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad367b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad362b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad25da0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 3700
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad254e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad254e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad58eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad254e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198accae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac827f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac829e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198accaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36630> 0.0 2
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198accaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad36630> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36630> 0.0 4
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad36630> 0.0 5
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36630> 0.0 6
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36630> 0.0 7
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36630> 0.0 8
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36630> 0.0 9
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad36630> 0.0 10
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36630> 0.0 11
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad36630> 0.0 12
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad36630> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac820f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 8
Completed Iteration #6
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac826d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bcf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac828d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc7b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa1d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7420b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7427b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7429b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7420b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7420b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad584e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a742828> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad430f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad43358> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
coverage_call_count 4100
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad367f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adeda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adedb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adedf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad367f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adedbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad367f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198add5940> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198add50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4146d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4146d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 19
Completed Iteration #22
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c898> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb67f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb67f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb689b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb689b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad430f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad430f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adedeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb689b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 21
Completed Iteration #21
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe17b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0098ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe15c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe15c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1992d74278> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb9cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a742a20> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742a20> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742a20> 0.0 12
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f507f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 17
Completed Iteration #19
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0facef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f500f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d749e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a186aacc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa9b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad580f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb68240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18720828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e987f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0061cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00612e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00612e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d10f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c400> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729db00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0054208> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a187047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc65f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b4762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0523c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7220b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052be0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00aed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d877f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18715518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4762e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4762e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2005c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d870b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d870b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cf27b8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a729d3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f505f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0293c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0293c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18696908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ac8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089550> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089550> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f19f0089588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac828d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac820f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac828d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82e10> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0017b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198badd470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198baf7630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ef60> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad257f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 5000
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1a187049b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adafe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79acf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adafb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198badd8d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adafc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adafb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ceb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198acca9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198acca2e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accab70> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899849b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899849b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adaf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899849e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899455f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984710> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899544e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899544e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899545c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899545c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899545c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19899547f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198accacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899454a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a052048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 19
Completed Iteration #22
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984048> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198accae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198acca4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198991c978> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c99b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 5400
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c7f0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c94e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c94e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c94e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f82b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898869b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898869b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898869b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898866d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898866d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898869b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1989886518> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899849e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899849e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899849e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898860b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898a0320> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899454e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899454e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c97b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c97b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898545f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898545f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989871710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898549b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b1d30> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b19e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b19e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b19e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b19e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893cb7b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac252e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f748> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898549b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854f98> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198934d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198935d4a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893a3828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198935d940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893237f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989333470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989333860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989333860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989333860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989333470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a79acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72acac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ace48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ed9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72ace48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a052a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989954f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cb198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198930bb38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a79a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 5900
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a79a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19898714a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893d6b70> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a03c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198991ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a03c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871c88> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a03c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19898a0240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989323f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899699b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899699b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198accaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989945160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989969e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198accaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1989969ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899f7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899a7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989954fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19899f7128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899692e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a052668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989945208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899694a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899692e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899692e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899692e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989886cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19899690f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adafef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adafb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198991c240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893e8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adafa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7cceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7cccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a7cc860> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad0db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adafef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cbc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5c3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198bb05518> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989886a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198992c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899694a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad257f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad25b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0089cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
coverage_call_count 6200
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac821d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bacb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b476710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b476748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bacb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac820f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac821d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a7df160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198a7df128> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7df2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac82a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac6beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a09b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad25550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7dfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adaf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989871438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893d6470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893cba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989945208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac3b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d87c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d33828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0012e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc49b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990d339b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1865e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adafef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad0dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7210ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899a7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989871940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198930bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727d6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d320> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac7e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198992c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad25550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a09b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac3bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d336d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899f7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198930ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d336d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198badd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7210e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac5cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989954ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7271eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00ae518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18704e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a727da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a001f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e87e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001c0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f2ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19a72204a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0054c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f001ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f80dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a729d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990ca4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18715048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a029828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f001cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898710b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c4d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898710b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0054518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebde80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198acca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989969c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aca4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a187040b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ebd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7271908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a72ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a727dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198badd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac6b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992de3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198aca4668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00610b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00610b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00610b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0061a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0fc6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a2006a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d15c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 6500
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c4dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0ff1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b4142e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb3d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0eb2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0010b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cdf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00618d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a029278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb05d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00618d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a72d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d33208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a724aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18674358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18696a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a18647780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1a1870c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198b414588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d747f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0f98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb95ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb5afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baddc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb958d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb958d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb9c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c70438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cb64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0d30> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18704080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a724aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198accad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fda278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb95630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d742e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198b414048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0f28> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0f20160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989323630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb68cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198add5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198aca49b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad58cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989323630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad586a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad586a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 6700
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad58b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad580f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad36c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d87198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adc4dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198adedfd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0089710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f00d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990d333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0098828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0facb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c96ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cdfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c704a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad43d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7423c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992d74b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0fdabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c704a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c704a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb68668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990c70278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a01a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935db38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a001e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a1870cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f42b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992d74390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbe1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cc42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a18647898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992de3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bb18b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad7f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198a742860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac82b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990d333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c5aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a742e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad43d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c92b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198934d828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898546d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ad36cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198987fe80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898547b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f199a0c02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad7fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989969c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898c9ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990c96630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898547b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1a186aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19f0e98438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898c9ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adc4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198baf7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbfb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198a742b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989854dd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb18cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198adfdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c9b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198a7aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198baf7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0320> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980fef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989333d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893332b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989333d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198add5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19893b0d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989333cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19899845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19899846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989333cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893a3748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198935def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19893b0320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989854048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898547b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898b1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898c99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198987fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19893b00f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198adedf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898549b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19898f87b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1992dcf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882c9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19883144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19883147f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bb5a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbc2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198987fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19883144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19883149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198935d668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883142b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989854438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883142b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198ac25400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883142b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cf29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19883149b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882c9470> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0078438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882a0eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ad365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1990cb6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac8e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19893b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198934d358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19882a09b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198aded470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882c9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988314198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1989984ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882728d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882150b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882729e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882729e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882725f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272860> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbb3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19a7220cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827f978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1988215240> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882728d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198aded470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989984cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1988272f28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882b3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19883149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824b8d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973ddec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973ddefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973ddeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973ddec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973df42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973ddeeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973df42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973ddec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d83438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973df42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198824be48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d834e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d98208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d98358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d832e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198bbd0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973df4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973df4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973df4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d832e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d83cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d83a20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d83470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973ddeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973df44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973ddec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973ddec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882727b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d835f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1989333ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 7400
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d98b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d98a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d98588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d98c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d98fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d98a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973df4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198980f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d98438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d98a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973ddec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d602e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d602e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973d494a8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973df42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198980f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198ac25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d98400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d98b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d98fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19883145f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19f0f67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d98400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988215b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19882d8c18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988272630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973ddeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d83ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d83128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973ddefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882a0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19898f8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973ddefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1988272080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d605c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d98128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d604a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d706a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d49a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d706a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d707b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d705f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198827fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d382b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d705f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d604a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d38eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d387b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198827ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d389b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38eb8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d387b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d387f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d383c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882728d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973dde9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973df44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198824be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d70780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d702b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70780> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d49358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d702b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d29c50> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1973d60c88> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c97438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c97668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198824bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c97940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c845f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c97b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c97d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c97860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c97ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c97f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c97198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c97400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb36a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cc79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c840b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c97940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988215ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c840b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882f2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882728d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973cb31d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d603c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d29ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d603c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d603c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c72438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfae48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1973d388d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c72a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c72cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c727b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c72550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973c724e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c72550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c72358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c72828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c72978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c722e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c72860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d70080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198822d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f198934d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d60a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d38940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d38ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882f2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c72cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d60d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c97fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973c43ba8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cc7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19882729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c729b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c72080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 7800
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c729b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c439e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737e4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737d5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737e4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c729b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737e44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c439e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737e4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737e4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737e45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737f40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737f4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737e4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737e4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737e4f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737f47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737e4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737e42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19737e4a90> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c84198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1988314c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19898f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d83048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d29320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c84c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c43358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d55c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cb3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737f4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737a82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737a8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973d704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737f4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19882729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737a8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c43d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973dde978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973cfaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c72cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973cfae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737a8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737a89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737e4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d70198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19737f4eb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737a8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737a82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973740198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973740400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973740470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737a8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973740908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973740438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973740a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737f4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 7900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973740a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737400f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973740da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737a8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973740f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973740470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973756438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737a8ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973740358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737a8ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f19737d5c50> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973756860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973756b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737562e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973756c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737562e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973756eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973c0a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737a8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973c1b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973756e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737a87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973756a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973d98ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973756b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973740da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737562e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973740630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f19737405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f19737402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973740748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973740c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1973740470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1973756940> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1973756898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 70.4225352112676
initial coverage: 69.0141
time passed (minutes): 60.0335
iterations: 294
number of new inputs: 128
final coverage: 70.4225
total coverage increase: 1.40845
