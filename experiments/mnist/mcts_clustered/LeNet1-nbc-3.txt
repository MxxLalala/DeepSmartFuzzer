Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'nbc'], random_seed=3, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7fd47e934f28>, tc2=<function tc2 at 0x7fd47e945048>, tc3=<function tc3 at 0x7fd47e945158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 29.1667
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe779b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 3
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 11
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 12
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97793c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97605c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97605c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fda0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe774a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97798d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebcc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96beba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96beba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96beba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8470> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d82e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97604e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8278> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8cf8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80695c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80697f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80697f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80697f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ac50> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97baf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97badd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96beba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebeea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d55f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97793c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ac8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97608d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96743c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd68> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d81d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d81d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ab70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d544a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97baf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97baf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97baf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97baf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d546a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb080> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caea20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caea20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 1000
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caea20> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caefd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d464e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922696d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922916a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922910f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922910f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd392269518> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922513c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922519e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922515f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922515f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922513c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222eb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e668> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922514e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922514e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922512b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f37f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b06d8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391becb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391becd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391beccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b805f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 1300
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b805f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391beccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b90630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b809e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b805f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd44e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd44e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391becd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922916a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922916a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39222e3c8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b464e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b469b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b469b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b464e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b909e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b909e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd391b466a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80552b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80552b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391beceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922916d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922697b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031dfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922697b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031dfd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 1
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 1500
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf28> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d466a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d466a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d466a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d466a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe3c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96add68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97baba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97799b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97799b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97799b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46320> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d59e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96becf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96becf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 20
Completed Iteration #21
Best Reward: 0
coverage_call_count 1800
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be7b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d467b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1c18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b802e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922c14e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922510b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd392251eb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d545c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922519e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922519e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80696a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391beceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec4e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca50f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641fd0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd44e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a45c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391becf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ef28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a58> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922694e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922919e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b907b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd392291860> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80692b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80692b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bece48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96410b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80692b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922910b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bece48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80692b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce71d0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900331d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900335c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900332b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb748> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce76d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900334a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900334a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900334a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd390033f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900332e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900332b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391becf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80551d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e41d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80551d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e47f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a758208> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd710> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7689b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a44e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7580b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 2500
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 8
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 9
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 10
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 11
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c27f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c27f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c198> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900339b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900339b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900339b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900339b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd390033978> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 2600
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e27b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e27b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b27f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b27f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b27f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b27f0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2710> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2438> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 2700
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900599b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b905f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b905f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b905f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b905f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900599b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d16a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922d15f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b902e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96419b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 2800
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a45c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a45c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900599e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b6aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6aba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391becb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96419b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96419b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96419b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96bedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e80554e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391becb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391becdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807edd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be240> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96745f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96745f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97babe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe777b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe777b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe777b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0eb8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d460f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d460f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77dd8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 3200
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39031d2b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900331d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900335c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900335c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900335c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 3300
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e46d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd9e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 21
Completed Iteration #24
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7585c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f400> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7584e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7584e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7584e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d937b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7580b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d417b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 13
Completed Iteration #20
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d55320> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d672b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d552e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d552e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d135c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d139b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7682e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7682e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d137f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d25c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7580b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c423c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c560f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c560f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d938d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c794a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c260f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c260f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c260f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c110f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c560b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c798d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c382b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787804e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787804e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787802b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787972b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787805f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787805f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c381d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d413c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d413c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c567f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f98> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c115c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c115c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c115c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c115c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c790b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c79ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c115c0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787809b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787040f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 8
Completed Iteration #6
Best Reward: 0
coverage_call_count 4000
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787685c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768dd8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787685c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768128> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c790b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 4100
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd37872f128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c01d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d55748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7685f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96902b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d67710> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Completed Iteration #0
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a63feb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f390> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd390033ac8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 4300
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390033cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97792b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97792b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfecc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f34e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3710> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9779eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 14
Completed Iteration #20
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b00f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e974f8d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3caeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390033d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391beca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c26a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c26a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e972d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391becb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb208> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7681d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7681d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a758198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 21
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f780> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ceef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ceef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786cef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786cecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786cecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3900596a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfeb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf17f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf17f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd39004ff98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787802b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6ffd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787802b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6ffd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392269fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378d410b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc62b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e10> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c265c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 4800
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c265c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c26e48> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704e48> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb48d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ce80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c265c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c265c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd57f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c265c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c116d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd57f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c116a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9641e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787972e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c383c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c380b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11400> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787970b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787970b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c389e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c429e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c389e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c389e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787970b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c387f0> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c386d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c265c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c386d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378c38fd0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39032a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d934a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787806d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786efda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875ccf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56a20> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb49e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c116a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739dc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37739dc18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739dc18> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773500f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378797a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773634a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773634a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773634a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773733c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773733c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773633c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773083c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773086d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773086d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773083c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773086d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773083c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773083c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308400> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733cd68> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773632e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773508d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377308978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4b00> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377246fd0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37725b2b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725bc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725bc88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd37725b1d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733c128> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729dbe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d872e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 11
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 12
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dccf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772469b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 16
Completed Iteration #15
Best Reward: 0
coverage_call_count 5600
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87940> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6390> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d644a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d64c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d57a58> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6f28> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd376da6eb8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3772316a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d25908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d25908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d25d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d356a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d356a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d25908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d356a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce25c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce25c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce25c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbe10> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d356d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d35a90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb18d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d256d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c480f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d874a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d258d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c038d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1d68> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 5900
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c037b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c27438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c036d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c27860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c03a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c27ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c27c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c27e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c27908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39222ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c27278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39222e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c275f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c270f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37725b860> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37721ffd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721ffd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd377246d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b44e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd390059ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd377246c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773500f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773505f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773505f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37733c0f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392291eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786efc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786efba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392291f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786efba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786efba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37875c208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773084e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773089b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377246d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377350898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37874c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ca5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c27160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d64b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377350da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1198> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787973c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787973c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37739d908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c380b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773505f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773505f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392251b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773505f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c9def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c79d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c9def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d7c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d64ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c9de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c27160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787974a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3787970b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7c0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787970b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37725b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787970b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c38518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378cb47b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773084e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cd50f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37875c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d41f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922515c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922515c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 6300
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922515c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cccd68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37875cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ceda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf15c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cd5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378cf15c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a69e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c26b38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e2cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c79c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39030c5c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c27160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd392251b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786cea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37725b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37739d4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786cef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3772b46a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391beca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb44a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b90ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb44a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b467f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7587b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96e8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7587b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922f3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7587b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7587b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6abe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7586d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6acf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37739d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a78f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37874ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ced30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe6a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786cecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377350be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378797710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a758ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ced30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772e3320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c0f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ce7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37721fe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39030c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cf1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fe80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bd48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e80690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3900339e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391bd4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378797518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 12
Completed Iteration #17
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e974ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922b0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cdb390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b803c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37721fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97798d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cf12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39004f198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e966aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966aa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3902cb668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6b29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d6fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ebf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 6600
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a768940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a768c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fd240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46e48> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39032acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cb4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c27160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377246a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d93128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b46240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e977fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e97798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39004f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd390059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d558d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378cc6978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b6a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d558d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d555c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d2630> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c38d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a70ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787044e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c037b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c030f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37733cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c037b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c030f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c037b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e807e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c036a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391bec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c030f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c037b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3ccc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3787040f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c036a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c030f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd376c03978> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c032e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37872fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e807eef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d67160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3cfe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3ebe77f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378780a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b5b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd392269f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd391b80ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c489b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031def0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd39031def0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760cc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d0fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378780630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772310f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc9e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 8
Completed Iteration #9
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7a4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37729da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d41550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37729d748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e977f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39031def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ca54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37721fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377308160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37a6d26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d46f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e966add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376dfce80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d67ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c035f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5b00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d57160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d55f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d57780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cb19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d576a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 8
Completed Iteration #6
Best Reward: 0
coverage_call_count 6900
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3a3d54da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c48208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378cb44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37729deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96be208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c035f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccba90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378d13518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9760fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d871d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37728c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378780f60> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376ccbac8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d877b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c26cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3787685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d877b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf01d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773633c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cf01d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0a90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e9674240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a63f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37728c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d795c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d874e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377231128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a7e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c113c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d25400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d25780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377363668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c420f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d25400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd37720f6a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773736a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c11f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3773736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773736a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378c42a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773732b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd378c11f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3773736a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3773737f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
coverage_call_count 7100
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d790b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c11048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d790b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd391b46240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37872f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d255f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376c03278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cf0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d255f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd39030c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378704160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d35da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb9e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c48ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d79160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3772316d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757da080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757ccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757ccd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757da2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757da780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757ccc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757daac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c978> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3772316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e966add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a6c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376da6588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 16
Completed Iteration #21
Best Reward: 0
coverage_call_count 7200
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377231128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d25d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377363668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d25d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37720f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d25d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37579a1d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757584a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37579a3c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d35da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37579a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d79390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3786d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 20
Completed Iteration #19
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37a77f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a6d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e8069a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4390> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377363c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757dab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378c42160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd378768780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757060b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375706320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce25c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e97a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376ce25c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375706080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757065c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757068d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375706d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375706e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757065c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375706c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757dae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bcbe0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375731390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375731518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757314e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375731c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375731cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375731ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375731e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375731b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375731a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757314e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375731b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757310b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757314e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376cb1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757310b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375706cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375706c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375706e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757314e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd375731128> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ccb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375706198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757060b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757315f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757315f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757582b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376c03278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757060b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376da6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757582b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757060b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375706ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ce2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375731080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757da358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bccc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc710> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37578d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756872e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f96d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f96d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757da588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f96d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756872b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756870b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3e96adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756870b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37579abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375687cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756873c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dfc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd375687be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd377373400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757da710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375731080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d57ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375687898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d25b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375706828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757064a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757064a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569fa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758f60> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376ca5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37578dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375706b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd376d87e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 19
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571ab00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571ab00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4a8> 0.0 25
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375731f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375687b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569fb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3922a4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757da358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37564fa58> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3756877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37571a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756877f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37564f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3756f9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562da90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751db198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751db3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751db5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751db828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751dba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751db908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751dbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751dba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751dbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751dbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751dbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751dba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751dbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751dbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751db128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4be0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 297
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751db588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378704160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37720f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757da358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37579a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751db518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 298
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 7700
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376dcce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375e3c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375758400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3757a4278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37571a898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 299
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751a28d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562df98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 300
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375145400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d87be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751aca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37564f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3757cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 301
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375758400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37562d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37562d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751c46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e84a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37565fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569f2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37569fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8da0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 302
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 7800
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375145550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375145978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375145a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375145c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375145f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751acf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751acf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375145780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751459e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37510a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37510a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751459e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561da58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37567bcf8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 303
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375145710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37510a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37510a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37510a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37510a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37510a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37510a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37510a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37510ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37510a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37510a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37510a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37510ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37510a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37510af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375114748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375114978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37510a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37510a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37510a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37517be10> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 304
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375145cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375145f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd376d79390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37561d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37564fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd378768780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751452e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37573fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751452e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37569f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd375114ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd37517b080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 305
found coverage increase 0
Current Total Coverage 29.166666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37565f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37567bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37561d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3750c8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd37517b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3750c8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3750c8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3750c86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3750c8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3750c8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3750c88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3751141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3750c8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3750c8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd375145208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3750c81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3751a2fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3750c8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd37517b4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 7900
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd3750dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd3750c88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd375114d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 306
found coverage increase 0
Current Total Coverage 29.166666666666668
initial coverage: 29.1667
time passed (minutes): 60.1823
iterations: 307
number of new inputs: 0
final coverage: 29.1667
total coverage increase: 0
