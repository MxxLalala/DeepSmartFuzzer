Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'neuron'], random_seed=1, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7ffa816cbf28>, tc2=<function tc2 at 0x7ffa816dc048>, tc3=<function tc3 at 0x7ffa816dc158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 69.0141
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0feceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f886d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5aba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a400> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f889e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecda90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecda90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecda90> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb24e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e405c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e405c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e409e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f880f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7c50> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc88> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe80> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146952b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146956a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146952b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e530f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e530f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146952b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa147e37b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146952b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e37b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75f8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e401d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e404e0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e405f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e405f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40b70> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf60> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 69.01408450704226
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 0.7042253521126725 4
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 0.7042253521126725 5
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 0.7042253521126725 6
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 0.7042253521126725 7
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 0.7042253521126725 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 0.7042253521126725 8
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 1.408450704225345 9
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 1.408450704225345 10
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bba8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 1.408450704225345 11
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 1.408450704225345 12
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00397b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 1.408450704225345 13
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 1.408450704225345 14
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 1.408450704225345 15
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 1.408450704225345 9
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 1.408450704225345 16
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bba8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 2.1126760563380174 10
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 2.1126760563380174 17
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 2.1126760563380174 18
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 2.1126760563380174 19
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e00393c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 2.81690140845069 20
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 2.81690140845069 12
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 2.81690140845069 21
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 2.81690140845069 13
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 2.81690140845069 22
Completed Iteration #0
Best Reward: 0.7042253521126725
coverage_call_count 800
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 3.5211267605633623 14
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 3.5211267605633623 23
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 4.225352112676035 15
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 4.225352112676035 24
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 4.225352112676035 16
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 4.225352112676035 25
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 4.225352112676035 17
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 4.225352112676035 26
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cd68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bba8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 4.929577464788707 18
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 4.929577464788707 27
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 4.929577464788707 19
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 4.929577464788707 28
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ffa147e37b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9ef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00393c8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 5.63380281690138 20
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 5.63380281690138 29
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ffa14695518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94e0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 6.338028169014052 21
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 6.338028169014052 30
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94e0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 6.338028169014052 22
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 6.338028169014052 31
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 6.338028169014052 23
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 6.338028169014052 32
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 6.338028169014052 24
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 6.338028169014052 33
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 6.338028169014052 25
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 6.338028169014052 34
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 6.338028169014052 26
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 6.338028169014052 35
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 6.338028169014052 27
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 6.338028169014052 36
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b2b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 7.0422535211267245 28
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 7.0422535211267245 37
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cac8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94e0> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 7.0422535211267245 29
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 7.0422535211267245 38
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc240> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bba8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 7.746478873239397 30
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 7.746478873239397 39
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94e0> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 7.746478873239397 31
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 7.746478873239397 40
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bba8> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 7.746478873239397 32
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 7.746478873239397 41
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00393c8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 8.45070422535207 33
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 8.45070422535207 42
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00392b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc710> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 8.45070422535207 34
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 8.45070422535207 43
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40438> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e00393c8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 3.5211267605633623 10
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 8.45070422535207 35
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 8.45070422535207 44
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b3c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 9.154929577464742 36
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 9.154929577464742 45
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bc18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b9e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc710> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 4.929577464788707 12
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 9.859154929577414 37
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 9.859154929577414 46
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bc18> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b9e8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc710> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 4.929577464788707 13
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 9.859154929577414 38
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 9.859154929577414 47
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e00683c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 5.63380281690138 14
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 10.563380281690087 39
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 10.563380281690087 48
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 6.338028169014052 15
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 11.26760563380276 40
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 11.26760563380276 49
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 6.338028169014052 16
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 11.26760563380276 41
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 11.26760563380276 50
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 6.338028169014052 17
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 11.26760563380276 42
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 11.26760563380276 51
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d5f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 3.5211267605633623 10
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 7.0422535211267245 18
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 11.971830985915432 43
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 11.971830985915432 52
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ffa14695320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 7.746478873239397 19
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 12.676056338028104 44
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 12.676056338028104 53
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 8.45070422535207 20
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 13.380281690140777 45
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 13.380281690140777 54
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9ef0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e00393c8> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 8.45070422535207 21
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 13.380281690140777 46
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 13.380281690140777 55
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b358> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c2b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b3c8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 4.929577464788707 12
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 9.154929577464742 22
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 14.084507042253449 47
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 14.084507042253449 56
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e005be48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bd30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc710> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc9e8> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 9.859154929577414 23
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 14.788732394366122 48
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 14.788732394366122 57
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 9.859154929577414 24
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 14.788732394366122 49
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 14.788732394366122 58
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 9.859154929577414 25
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 14.788732394366122 50
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 14.788732394366122 59
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->8->15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068dd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 10.563380281690087 26
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 15.492957746478794 51
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 15.492957746478794 60
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e00686d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 11.26760563380276 27
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 16.197183098591466 52
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 16.197183098591466 61
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b7b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068dd8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 11.971830985915432 28
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 16.90140845070414 53
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 16.90140845070414 62
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b7b8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068dd8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 11.971830985915432 29
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 16.90140845070414 54
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 16.90140845070414 63
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6cc0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6a90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00686d8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 12.676056338028104 30
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 17.60563380281681 55
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 17.60563380281681 64
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40438> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e00393c8> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 6.338028169014052 14
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 12.676056338028104 31
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 17.60563380281681 56
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 17.60563380281681 65
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 13.380281690140777 32
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 18.309859154929484 57
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 18.309859154929484 66
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7da58> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00686d8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 7.746478873239397 16
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 14.084507042253449 33
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 19.014084507042156 58
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 19.014084507042156 67
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cd68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 8.45070422535207 17
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 14.788732394366122 34
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 19.71830985915483 59
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 19.71830985915483 68
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e00685f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bfd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cd68> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 9.154929577464742 18
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 15.492957746478794 35
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 20.4225352112675 60
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 20.4225352112675 69
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 9.859154929577414 19
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 16.197183098591466 36
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 21.126760563380174 61
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 21.126760563380174 70
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068dd8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 10.563380281690087 20
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 16.90140845070414 37
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 21.830985915492846 62
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 21.830985915492846 71
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6dd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a64e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7da58> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e00686d8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 11.26760563380276 21
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 17.60563380281681 38
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 22.53521126760552 63
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 22.53521126760552 72
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb390> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 11.971830985915432 22
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 18.309859154929484 39
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 23.23943661971819 64
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 23.23943661971819 73
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40438> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e00393c8> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 12.676056338028104 23
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 19.014084507042156 40
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 23.943661971830863 65
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 23.943661971830863 74
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->8->15->6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 13.380281690140777 24
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 19.71830985915483 41
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 24.647887323943536 66
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 24.647887323943536 75
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0a58> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 14.084507042253449 25
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 20.4225352112675 42
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 25.35211267605621 67
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 25.35211267605621 76
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 14.788732394366122 26
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 21.126760563380174 43
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 26.05633802816888 68
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 26.05633802816888 77
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd0b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00685f8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bfd0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cd68> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 15.492957746478794 27
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 21.830985915492846 44
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 26.760563380281553 69
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 26.760563380281553 78
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e10> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 15.492957746478794 28
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 21.830985915492846 45
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 26.760563380281553 70
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 26.760563380281553 79
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e10> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 15.492957746478794 29
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 21.830985915492846 46
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 26.760563380281553 71
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 26.760563380281553 80
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b828> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 15.492957746478794 30
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 21.830985915492846 47
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 26.760563380281553 72
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 26.760563380281553 81
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 16.197183098591466 31
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 22.53521126760552 48
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 27.464788732394226 73
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 27.464788732394226 82
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbac8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 7.0422535211267245 14
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 16.90140845070414 32
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 23.23943661971819 49
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 28.169014084506898 74
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 28.169014084506898 83
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bba90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 7.0422535211267245 14
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 7.746478873239397 15
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 17.60563380281681 33
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 23.943661971830863 50
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 28.87323943661957 75
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 28.87323943661957 84
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e10> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 7.746478873239397 16
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 17.60563380281681 34
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 23.943661971830863 51
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 28.87323943661957 76
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 28.87323943661957 85
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 7.746478873239397 16
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 8.45070422535207 17
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 18.309859154929484 35
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 24.647887323943536 52
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 29.577464788732243 77
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 29.577464788732243 86
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0898> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbac8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 8.45070422535207 17
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 9.154929577464742 18
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 19.014084507042156 36
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 25.35211267605621 53
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 30.281690140844916 78
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 30.281690140844916 87
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e10> 0.7042253521126725 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 8.45070422535207 18
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 19.014084507042156 37
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 25.35211267605621 54
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 30.281690140844916 79
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 30.281690140844916 88
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39750f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 9.859154929577414 20
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 19.71830985915483 38
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 26.05633802816888 55
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 30.985915492957588 80
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 30.985915492957588 89
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bfd0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cd68> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 9.154929577464742 20
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 9.859154929577414 21
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 19.71830985915483 39
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 26.05633802816888 56
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 30.985915492957588 81
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 30.985915492957588 90
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 9.859154929577414 22
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 19.71830985915483 40
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 26.05633802816888 57
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 30.985915492957588 82
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 30.985915492957588 91
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 9.859154929577414 21
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 10.563380281690087 23
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 20.4225352112675 41
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 26.760563380281553 58
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 31.69014084507026 83
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 31.69014084507026 92
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->8->15->6->0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e00397f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068be0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd860> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0898> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbac8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 10.563380281690087 22
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 11.26760563380276 24
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 21.126760563380174 42
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 27.464788732394226 59
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 32.39436619718293 84
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 32.39436619718293 93
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 11.26760563380276 23
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 11.971830985915432 25
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 21.830985915492846 43
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 28.169014084506898 60
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 33.098591549295605 85
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 33.098591549295605 94
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0a58> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 11.26760563380276 24
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 11.971830985915432 26
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 21.830985915492846 44
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 28.169014084506898 61
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 33.098591549295605 86
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 33.098591549295605 95
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0a58> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 11.26760563380276 25
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 11.971830985915432 27
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 21.830985915492846 45
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 28.169014084506898 62
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 33.098591549295605 87
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 33.098591549295605 96
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 11.971830985915432 26
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 12.676056338028104 28
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 22.53521126760552 46
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 28.87323943661957 63
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 33.80281690140828 88
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 33.80281690140828 97
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975e10> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 11.971830985915432 27
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 12.676056338028104 29
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 22.53521126760552 47
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 28.87323943661957 64
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 33.80281690140828 89
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 33.80281690140828 98
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bba90> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 12.676056338028104 28
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 13.380281690140777 30
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 23.23943661971819 48
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 29.577464788732243 65
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 34.50704225352095 90
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 34.50704225352095 99
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39846d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb588> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 13.380281690140777 29
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 14.084507042253449 31
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 23.943661971830863 49
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 30.281690140844916 66
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 35.21126760563362 91
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 35.21126760563362 100
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd668> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 13.380281690140777 30
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 14.084507042253449 32
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 23.943661971830863 50
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 30.281690140844916 67
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 35.21126760563362 92
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 35.21126760563362 101
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0898> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbac8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 14.084507042253449 31
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 14.788732394366122 33
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 24.647887323943536 51
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 30.985915492957588 68
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 35.915492957746295 93
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 35.915492957746295 102
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975e10> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 14.788732394366122 32
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 15.492957746478794 34
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 25.35211267605621 52
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 31.69014084507026 69
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 36.61971830985897 94
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 36.61971830985897 103
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0390> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0898> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbac8> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 14.788732394366122 33
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 15.492957746478794 35
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 25.35211267605621 53
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 31.69014084507026 70
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 36.61971830985897 95
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 36.61971830985897 104
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39848d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0898> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbac8> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 15.492957746478794 34
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 16.197183098591466 36
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 26.05633802816888 54
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 32.39436619718293 71
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 37.32394366197164 96
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 37.32394366197164 105
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->8->15->6->0->6
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 16.197183098591466 35
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 16.90140845070414 37
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 26.760563380281553 55
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 33.098591549295605 72
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 38.02816901408431 97
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 38.02816901408431 106
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39967b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39965f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984710> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 16.90140845070414 36
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 17.60563380281681 38
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 27.464788732394226 56
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 33.80281690140828 73
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 38.732394366196985 98
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 38.732394366196985 107
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920160> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 17.60563380281681 37
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 18.309859154929484 39
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 28.169014084506898 57
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 34.50704225352095 74
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 39.43661971830966 99
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 39.43661971830966 108
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 18.309859154929484 38
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 19.014084507042156 40
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 28.87323943661957 58
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 35.21126760563362 75
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 40.14084507042233 100
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 40.14084507042233 109
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbcf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920160> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 19.014084507042156 39
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 19.71830985915483 41
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 29.577464788732243 59
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 35.915492957746295 76
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 40.845070422535 101
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 40.845070422535 110
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 19.71830985915483 40
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 20.4225352112675 42
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 30.281690140844916 60
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 36.61971830985897 77
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 41.549295774647675 102
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 41.549295774647675 111
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984a90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 20.4225352112675 41
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 21.126760563380174 43
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 30.985915492957588 61
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 37.32394366197164 78
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 42.25352112676035 103
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 42.25352112676035 112
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 21.126760563380174 42
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 21.830985915492846 44
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 31.69014084507026 62
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 38.02816901408431 79
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 42.95774647887302 104
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 42.95774647887302 113
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 21.830985915492846 43
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 22.53521126760552 45
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 32.39436619718293 63
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 38.732394366196985 80
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 43.66197183098569 105
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 43.66197183098569 114
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 22.53521126760552 44
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 23.23943661971819 46
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 33.098591549295605 64
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 39.43661971830966 81
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 44.366197183098365 106
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 44.366197183098365 115
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39204a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 10.563380281690087 16
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 23.23943661971819 45
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 23.943661971830863 47
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 33.80281690140828 65
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 40.14084507042233 82
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 45.07042253521104 107
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 45.07042253521104 116
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939160> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920f60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975ac8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 11.26760563380276 17
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 23.943661971830863 46
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 24.647887323943536 48
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 34.50704225352095 66
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 40.845070422535 83
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 45.77464788732371 108
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 45.77464788732371 117
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39396a0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39204a8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920470> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 11.971830985915432 18
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 24.647887323943536 47
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 25.35211267605621 49
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 35.21126760563362 67
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 41.549295774647675 84
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 46.47887323943638 109
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 46.47887323943638 118
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975f28> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996da0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 12.676056338028104 19
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 25.35211267605621 48
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 26.05633802816888 50
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 35.915492957746295 68
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 42.25352112676035 85
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 47.183098591549054 110
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 47.183098591549054 119
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->8->15->6->0->6->16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 13.380281690140777 20
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 26.05633802816888 49
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 26.760563380281553 51
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 36.61971830985897 69
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 42.95774647887302 86
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 47.88732394366173 111
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 47.88732394366173 120
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb588> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 14.084507042253449 21
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 26.760563380281553 50
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 27.464788732394226 52
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 37.32394366197164 70
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 43.66197183098569 87
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 48.5915492957744 112
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 48.5915492957744 121
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920cc0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 10.563380281690087 16
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 14.788732394366122 22
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 27.464788732394226 51
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 28.169014084506898 53
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 38.02816901408431 71
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 44.366197183098365 88
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 49.29577464788707 113
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 49.29577464788707 122
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 11.26760563380276 17
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 15.492957746478794 23
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 28.169014084506898 52
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 28.87323943661957 54
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 38.732394366196985 72
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 45.07042253521104 89
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 49.999999999999744 114
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 49.999999999999744 123
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984da0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984908> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb588> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 11.971830985915432 18
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 16.197183098591466 24
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 28.87323943661957 53
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 29.577464788732243 55
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 39.43661971830966 73
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 45.77464788732371 90
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 50.70422535211242 115
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 50.70422535211242 124
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbcf8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb940> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920160> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 12.676056338028104 19
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 16.90140845070414 25
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 29.577464788732243 54
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 30.281690140844916 56
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 40.14084507042233 74
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 46.47887323943638 91
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 51.40845070422509 116
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 51.40845070422509 125
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920160> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 12.676056338028104 20
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 16.90140845070414 26
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 29.577464788732243 55
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 30.281690140844916 57
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 40.14084507042233 75
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 46.47887323943638 92
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 51.40845070422509 117
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 51.40845070422509 126
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939c50> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbcf8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb940> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920160> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 12.676056338028104 21
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 16.90140845070414 27
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 29.577464788732243 56
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 30.281690140844916 58
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 40.14084507042233 76
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 46.47887323943638 93
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 51.40845070422509 118
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 51.40845070422509 127
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dda90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939438> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 13.380281690140777 22
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 17.60563380281681 28
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 30.281690140844916 57
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 30.985915492957588 59
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 40.845070422535 77
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 47.183098591549054 94
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 52.11267605633776 119
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 52.11267605633776 128
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cac8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 14.084507042253449 23
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 18.309859154929484 29
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 30.985915492957588 58
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 31.69014084507026 60
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 41.549295774647675 78
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 47.88732394366173 95
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 52.816901408450434 120
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 52.816901408450434 129
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39395c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 14.788732394366122 24
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 19.014084507042156 30
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 31.69014084507026 59
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 32.39436619718293 61
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 42.25352112676035 79
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 48.5915492957744 96
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 53.52112676056311 121
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 53.52112676056311 130
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951a20> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984278> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 15.492957746478794 25
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 19.71830985915483 31
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 32.39436619718293 60
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 33.098591549295605 62
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 42.95774647887302 80
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 49.29577464788707 97
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 54.22535211267578 122
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 54.22535211267578 131
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->8->15->6->0->6->16->0
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e61d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 16.197183098591466 26
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 20.4225352112675 32
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 33.098591549295605 61
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 33.80281690140828 63
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 43.66197183098569 81
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 49.999999999999744 98
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 54.92957746478845 123
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 54.92957746478845 132
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39967b8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39965f8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984710> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 16.197183098591466 27
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 20.4225352112675 33
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 33.098591549295605 62
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 33.80281690140828 64
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 43.66197183098569 82
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 49.999999999999744 99
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 54.92957746478845 124
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 54.92957746478845 133
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6e80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6400> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e61d0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 16.90140845070414 28
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 21.126760563380174 34
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 33.80281690140828 63
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 34.50704225352095 65
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 44.366197183098365 83
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 50.70422535211242 100
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 55.633802816901124 125
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 55.633802816901124 134
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 17.60563380281681 29
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 21.830985915492846 35
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 34.50704225352095 64
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 35.21126760563362 66
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 45.07042253521104 84
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 51.40845070422509 101
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 56.338028169013796 126
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 56.338028169013796 135
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996748> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 18.309859154929484 30
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 22.53521126760552 36
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 35.21126760563362 65
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 35.915492957746295 67
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 45.77464788732371 85
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 52.11267605633776 102
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 57.04225352112647 127
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 57.04225352112647 136
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39396d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39399b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939160> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920f60> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975ac8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 19.014084507042156 31
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 23.23943661971819 37
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 35.915492957746295 66
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 36.61971830985897 68
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 46.47887323943638 86
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 52.816901408450434 103
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 57.74647887323914 128
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 57.74647887323914 137
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39518d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984710> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 19.71830985915483 32
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 23.943661971830863 38
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 36.61971830985897 67
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 37.32394366197164 69
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 47.183098591549054 87
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 53.52112676056311 104
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 58.450704225351814 129
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 58.450704225351814 138
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39965f8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984710> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 10.563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 20.4225352112675 33
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 24.647887323943536 39
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 37.32394366197164 68
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 38.02816901408431 70
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 47.88732394366173 88
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 54.22535211267578 105
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 59.154929577464486 130
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 59.154929577464486 139
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39750b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 21.126760563380174 34
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 25.35211267605621 40
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 38.02816901408431 69
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 38.732394366196985 71
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 48.5915492957744 89
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 54.92957746478845 106
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 59.85915492957716 131
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 59.85915492957716 140
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951048> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39750b8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 11.971830985915432 19
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 21.830985915492846 35
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 26.05633802816888 41
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 38.732394366196985 70
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 39.43661971830966 72
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 49.29577464788707 90
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 55.633802816901124 107
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 60.56338028168983 132
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 60.56338028168983 141
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39200f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2080> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6e80> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6400> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e61d0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 12.676056338028104 20
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 22.53521126760552 36
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 26.760563380281553 42
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 39.43661971830966 71
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 40.14084507042233 73
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 49.999999999999744 91
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 56.338028169013796 108
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 61.2676056338025 133
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 61.2676056338025 142
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951048> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39750b8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 12.676056338028104 21
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 22.53521126760552 37
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 26.760563380281553 43
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 39.43661971830966 72
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 40.14084507042233 74
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 49.999999999999744 92
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 56.338028169013796 109
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 61.2676056338025 134
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 61.2676056338025 143
Completed Iteration #21
Best Reward: 0.7042253521126725
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 12.676056338028104 22
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 22.53521126760552 38
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 26.760563380281553 44
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 39.43661971830966 73
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 40.14084507042233 75
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 49.999999999999744 93
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 56.338028169013796 110
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 61.2676056338025 135
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 61.2676056338025 144
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd710> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd4a8> 13.380281690140777 23
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd400> 23.23943661971819 39
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0550> 27.464788732394226 45
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 40.14084507042233 74
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 40.845070422535 76
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039208> 50.70422535211242 94
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 57.04225352112647 111
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 61.971830985915176 136
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 61.971830985915176 145
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->8->15->6->0->6->16->0->2
Best Reward: 0.7042253521126725
iteration: 30
found coverage increase 0.7042253521126725
Current Total Coverage 69.71830985915493
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e69b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e69b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e69b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39519b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f27f0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f28d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39397b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3ac8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 15
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 10
Completed Iteration #17
Best Reward: 0
coverage_call_count 1100
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38257f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38257f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38257f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38522b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38258d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38258d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00114e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00117f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00116d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39519b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39519b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39519b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00486a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 10
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64642e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64642e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38521d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38521d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64314a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64317f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64314a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64317f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d6d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64314a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64316d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39205c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39200f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39200f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39200f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39757b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39200f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39204a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39204a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6860> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a68d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 1600
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c69b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c69b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 1
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00391d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00394a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00399b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0feccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b6a0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39515f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39754e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 1700
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00683c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39208d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00683c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39208d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00683c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c97f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c97f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39511d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39200f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 17
Completed Iteration #24
Best Reward: 0
coverage_call_count 1800
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 1
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146845f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f60> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146950f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146950f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd8d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcb38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcb38> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e530f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e536a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2ff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7be0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146a0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbc88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbc88> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7320> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146845f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38529b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38529b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 17
Completed Iteration #19
Best Reward: 0
coverage_call_count 2000
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 6
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64786d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 69.71830985915493
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146952e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 13
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 14
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 15
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 16
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 17
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.7042253521126725 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 18
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38522b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 19
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146952e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 20
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64314a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 21
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 22
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.7042253521126725 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 23
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.7042253521126725 8
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 24
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.7042253521126725 9
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 25
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.7042253521126725 10
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 26
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.7042253521126725 11
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 27
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.7042253521126725 12
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 28
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.7042253521126725 13
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 29
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 0.7042253521126725 14
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 0.7042253521126725 30
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->1
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bda0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 1.408450704225345 15
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 1.408450704225345 31
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 2.1126760563380174 16
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 2.1126760563380174 32
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 2.81690140845069 17
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 2.81690140845069 33
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 3.5211267605633623 18
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 3.5211267605633623 34
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
coverage_call_count 2100
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f885f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 4.225352112676035 19
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 4.225352112676035 35
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->1->27
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bc50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 4.929577464788707 20
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 4.929577464788707 36
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f0f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 5.63380281690138 21
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 5.63380281690138 37
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 6.338028169014052 22
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 6.338028169014052 38
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 7.0422535211267245 23
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 7.0422535211267245 39
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 7.746478873239397 24
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 7.746478873239397 40
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 8.45070422535207 25
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 8.45070422535207 41
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d32e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 9.154929577464742 26
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 9.154929577464742 42
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->1->27->0
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 9.859154929577414 27
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 9.859154929577414 43
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38992e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 10.563380281690087 16
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 10.563380281690087 28
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 10.563380281690087 44
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453be0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 10.563380281690087 16
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 11.26760563380276 17
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 11.26760563380276 29
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 11.26760563380276 45
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bd30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 11.26760563380276 17
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 11.971830985915432 18
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 11.971830985915432 30
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 11.971830985915432 46
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 11.971830985915432 18
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 12.676056338028104 19
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 12.676056338028104 31
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 12.676056338028104 47
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->1->27->0->0
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2e80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6630> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 12.676056338028104 19
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 13.380281690140777 20
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 13.380281690140777 32
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 13.380281690140777 48
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 13.380281690140777 20
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 14.084507042253449 21
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 14.084507042253449 33
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 14.084507042253449 49
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899c50> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 14.084507042253449 21
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 14.788732394366122 22
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 14.788732394366122 34
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 14.788732394366122 50
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 14.788732394366122 22
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 15.492957746478794 23
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 15.492957746478794 35
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 15.492957746478794 51
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825eb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 15.492957746478794 23
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 16.197183098591466 24
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 16.197183098591466 36
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 16.197183098591466 52
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 16.197183098591466 24
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 16.90140845070414 25
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 16.90140845070414 37
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 16.90140845070414 53
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->1->27->0->0->0
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d39969b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 10.563380281690087 16
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 16.90140845070414 25
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 17.60563380281681 26
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 17.60563380281681 38
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 17.60563380281681 54
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 10.563380281690087 16
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 11.26760563380276 17
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 17.60563380281681 26
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 18.309859154929484 27
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 18.309859154929484 39
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 18.309859154929484 55
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 11.26760563380276 17
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 11.971830985915432 18
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 18.309859154929484 27
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 19.014084507042156 28
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 19.014084507042156 40
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 19.014084507042156 56
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b710> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 11.971830985915432 18
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 12.676056338028104 19
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 19.014084507042156 28
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 19.71830985915483 29
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 19.71830985915483 41
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 19.71830985915483 57
Completed Iteration #18
Best Reward: 0.7042253521126725
coverage_call_count 2200
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 12.676056338028104 19
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 13.380281690140777 20
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 19.71830985915483 29
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 20.4225352112675 30
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 20.4225352112675 42
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 20.4225352112675 58
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9d00489b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 13.380281690140777 20
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 14.084507042253449 21
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 20.4225352112675 30
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 21.126760563380174 31
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 21.126760563380174 43
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 21.126760563380174 59
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->1->27->0->0->0->1
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e05f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 14.084507042253449 21
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 14.788732394366122 22
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 21.126760563380174 31
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 21.830985915492846 32
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 21.830985915492846 44
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 21.830985915492846 60
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff96afd55f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 14.788732394366122 22
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 15.492957746478794 23
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 21.830985915492846 32
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 22.53521126760552 33
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 22.53521126760552 45
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 22.53521126760552 61
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048128> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 15.492957746478794 23
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 16.197183098591466 24
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 22.53521126760552 33
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 23.23943661971819 34
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 23.23943661971819 46
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 23.23943661971819 62
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->1->27->0->0->0->1->0
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5eb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082da0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b710> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 16.197183098591466 24
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 16.90140845070414 25
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 23.23943661971819 34
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 23.943661971830863 35
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 23.943661971830863 47
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 23.943661971830863 63
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082da0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b710> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb9b0> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b00> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 16.90140845070414 25
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 17.60563380281681 26
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b6a0> 23.943661971830863 35
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dc18> 24.647887323943536 36
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886208> 24.647887323943536 48
backprop <src.mcts.MCTS_Node object at 0x7ff9d38520f0> 24.647887323943536 64
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->1->27->0->0->0->1->0->2
Best Reward: 0.7042253521126725
iteration: 71
found coverage increase 0.7042253521126725
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96affff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af939b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af935c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af935c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 2300
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af934e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af934e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af93eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96affff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af226a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af224a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af222b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af224a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 14
Completed Iteration #13
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af224a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af229b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af224a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af227f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af754e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af754e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af518d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0cf8> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea898> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 11
Completed Iteration #9
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8df98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af221d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc88> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea79b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea71d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea79b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae552e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 2600
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2be80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39961d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae559b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e1d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00821d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38990b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00824a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38990b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082f98> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 2700
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38251d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38256d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38251d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38256d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39396d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39395c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bcf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38aff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38869e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38869e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38866d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38866d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38866d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Completed Iteration #0
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39396d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146a0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53e80> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d08d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4cfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0ccc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39518d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7de48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f885f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7de48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ba8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ba8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ba8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ba8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ba8> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ba8> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ba8> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39512b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00395f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00397b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0feccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00399e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00399e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 3100
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00399e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048908> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bcc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec828> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a66a0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00119e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a64783c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00683c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea75c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431550> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64314a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64314a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64314a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64314a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64314a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39512b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a69e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee98d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee98d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 3300
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee98d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5dd8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af75748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa29b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64537f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 12
Completed Iteration #11
Best Reward: 0
coverage_call_count 3400
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af229e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af229e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af229e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5cf8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8df60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af227f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d39206a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe940> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae029b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a1177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1176a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1176a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a1172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1173c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae029b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02550> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afffda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af225c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af933c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af225c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af226d8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0eddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0eddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 3700
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04da20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04da20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d7f0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace48> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af224a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af224a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 21
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 22
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed5f8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed978> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0172b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0172b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af224a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d5c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699efb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde48> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699894a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969989048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699eff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699eff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699454a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699454a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699454a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699454a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699454a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699458d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699537b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699efbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 4000
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699539e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96997a8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96996a9b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a1177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1173c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1178d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1173c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a1178d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969953160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00117f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64645c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64645c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64645c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64645c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fafda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464940> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a1177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a1173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0feccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0feccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0feccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 19
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf9e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 4200
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dca90> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ffa4d8ebcf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a1176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1173c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f4ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14684f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146957b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a668> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a668> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a668> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a668> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a668> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a668> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a668> 0.0 8
Completed Iteration #13
Best Reward: 0
coverage_call_count 4300
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a668> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a668> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a668> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a668> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146950f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146950f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa146843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ffa14684fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd75c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39397b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c32e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d36a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af9e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38998d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38998d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 4400
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38998d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38998d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39391d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39394a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00119e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00119e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00119e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a1173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a1173c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c30b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa14695198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39750b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 21
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 22
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 23
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e7f0> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 4500
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96996a860> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae024a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae024a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699456a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699450f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaf60> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae022e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae022e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02a90> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00480f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00480f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0178d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945780> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64786d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64789b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64789b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64789b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64789b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96af22e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699894e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af22208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699899b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969989630> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e537f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e533c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96affffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0b70> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 4900
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af93be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef1d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699454e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699454e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbda0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0eda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d02e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb00> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96af75780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acf60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af937f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af937f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699efa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699efa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9692355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699efa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af937f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968befb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968befcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968beff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968befd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968befd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968befba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968befd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9692357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968befd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968befc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968beff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b912b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968befc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968befef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b914e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdd30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af937f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235908> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af937f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 16
Completed Iteration #16
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699efa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699efa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235a90> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b57da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968befbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968befd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 14
Completed Iteration #13
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b009e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968befd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b230b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968acea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968acec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968acea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968acec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968acea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968acee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b231d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b231d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b230b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b231d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b3ddd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b570f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b570f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 5300
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b570f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e470> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a438> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a438> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a438> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a438> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a438> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a438> 0.0 9
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a438> 0.0 10
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a438> 0.0 11
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7e80> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 2
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 3
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adf8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adf8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 6
Completed Iteration #7
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b005f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b005f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cf8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a277f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a277f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a277f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a274a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 5500
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685cef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685cec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685cebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685cee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968a27dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685cecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685cecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685cecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685cefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a275f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a279b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a275f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b460f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b005f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a046d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b005f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a046d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968544978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685441d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685444e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685674a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685520f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685520f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685520f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685674a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685672e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685672e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685672e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685672b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a279b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a279b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968aceeb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685295c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685392e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ceef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685392e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ceef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968529ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968539e80> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a04a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684845c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968484630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a1177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af75588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af937f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af937f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a117fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a117ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684844e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684849e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684849e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a278d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a270b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a270b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0d0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a27240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a272b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a14400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa1468ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af93470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab86d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685520f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b235c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b235c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b007b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968adf6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96849d828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968adf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a27898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968acefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968acef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968acefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968acefd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a14f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9685f63c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968befcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968befdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968befef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b23668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685520f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968befef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685520f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b57b38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968beffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968befa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968beff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968befeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968befcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968beff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968beff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968befcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968befcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b576a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a14828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bef470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968befcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd240> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b6ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b57940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b57940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b23cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f66d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aceba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685520f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968552ba8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b918d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b91390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b918d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9692358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff968b91be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 10
Completed Iteration #13
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9692357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9692357f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990ee48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff969235710> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e002bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96849d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e002b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685870f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685870f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac5c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968484ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b46208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b57518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484940> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96affffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96affffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96afff4a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af22ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 6300
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae8dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6478278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96affffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b464e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b57320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968484128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968552550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ace828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969989128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96990e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b00780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab84a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04df60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969235358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ab8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d4e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae021d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae021d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a017d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96990eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b00898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af51a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968ace8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968ab84a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02080> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af51198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969989978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bb908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685f6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d4e0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaeb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaeb8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969989128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeadd8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6453eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968b3d518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 6500
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968b91dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b46668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c37f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968bfdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c37f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38c37f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968587470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968587470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3975c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39395f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00826a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d08d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2f2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0eb2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f0c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fd7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38869e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39395f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38869e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d383ba58> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa14695588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b6e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969996940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d39a6eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96ae6eb38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af2bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa147d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aedf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00684e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d383b518> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aedfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0faf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6431a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aefec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01dc390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a63c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d978> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0068390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae55d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00395f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00396a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969996518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3939f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96af2b2b0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3984b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c96a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3825e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ebc358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a64649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a641dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00112e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a64646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3996710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a02d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96996a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a0fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96996aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699539e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e40eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96afd5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96afd53c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e406a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00117b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9699452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38f25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0082908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e406a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d38e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e406a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ecdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e7def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 14
Completed Iteration #22
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeeaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afa2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a017b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699451d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e00687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96af0b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f2fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9699451d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9d3920908> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f6cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d32b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a494a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3e48> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3e48> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d32b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a040f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a49710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3852f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ffa146848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3899668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968567358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e00687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0ee9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968567c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00826a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d39845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e005bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3951f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a04d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0039b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 19
Completed Iteration #19
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d006aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96ae02470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968a49828> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00117b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685cee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685cee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685cee80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff969945b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0fa76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685397b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96997a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685398d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afd57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685390f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969953eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d390c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685399b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d0011b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96a00be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9685299e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff969945390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969945da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685449b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff969953c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968544dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aeea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968539c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff968544470> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a6464860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d3886d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684abf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684abba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00826a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a498d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684abf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a498d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d00826a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3d68> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 0
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac1d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac1d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953644470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac1d0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac1d0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac1d0> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953644b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac1d0> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953644c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac1d0> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac1d0> 0.0 9
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e406a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac1d0> 0.0 10
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9e0e406a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac1d0> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac1d0> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac1d0> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96afe5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953644ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e01c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953644160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953644a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953656a58> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536accf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9a641d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968b91dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536accf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953644c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685449b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685442e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685442e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 18
Completed Iteration #16
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953644978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a04f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 21
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 22
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 23
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968a49da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 24
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536accf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 25
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536acbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 26
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96997af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536560f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9d0048d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953630240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953630518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953630208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953630c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953630ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361deb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953630438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361de48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc50> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9685442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a04f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96849d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953644eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ace48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ace48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953644390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363f978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e82b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685449b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536acc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ace48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab7b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953182550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953182550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953182550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953182f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953193358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953182550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953182f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953193710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531826a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531934a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953193828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953193710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953193710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953182630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531936d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9e0f88e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96851bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96851bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e82e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968539cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95361d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 7300
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96aea7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95316b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95315deb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9d00482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968544be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ffa147e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9536086a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953630588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953630588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff95315da90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 13
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 6
Completed Iteration #7
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531287f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cdb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530df400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530df6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530df978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530df5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530dfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cdb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cdeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cdeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cdeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cdb00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9530df1d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 15
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531288d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968529160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317b828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953608ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530dfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530df7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95309b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95317ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317ba20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953608710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95363fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95316bb38> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95309bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 7500
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685449b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95309bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95309bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530be940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530be240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9530a51d0> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953051240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530bef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953051630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530bef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530be0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530be0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530beb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530beb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530bec88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530dfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95309b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530dfb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530dfb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953193b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95309b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530dfb38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968529160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95309b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95317bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530dfb38> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953051470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953051208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953051a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953051eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953051898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953656c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953051908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953138208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953128710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953128da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 7600
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953019198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953019470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953019208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953019c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953019f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953019978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953019eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953019128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953019e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953019a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953019908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953019630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953019860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953019710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953019a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953182da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953019908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953019198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953019a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530199e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531383c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a518> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530199e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff95302aef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968567ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953019278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9536307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95361d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9685449b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95315d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953019278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bda278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953019e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bda5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bda518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95302a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bda940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bdab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bdaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bda390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bda6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bdafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bdaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bdaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953019e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 23
Completed Iteration #24
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bdaa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bda080> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b81128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bda6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b81240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b81908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b81780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf19e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b81e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b81710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953138278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf19e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b817f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b81828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b817f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b81630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b81e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bda748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b81e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bdad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b81be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bda908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b817f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bda1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953019320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b81198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953051f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9684d3a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531939b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968aa7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bda160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95315d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b81550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95309bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95309bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bdaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b81550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bdada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bdaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b81550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b42278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b81550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b42470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95309bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b42898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b42320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b42ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b50080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b50390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b42f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b50d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b50e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b60278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95309bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 7800
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b50cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b429e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b606a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b60860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b60cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b60ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b42128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b601d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b60b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b60588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b60978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b60438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b50588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b50ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b50c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b60ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b42518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b42080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b60198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff968a9a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95316ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95309bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b60240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95316b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b420b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff95309bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b420b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b50828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b420b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b42a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42438> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953051d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b42e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953051c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bda400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bdada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95302ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bdab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95363f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9530cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bdab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bdab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b50f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bda860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9531a5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9531285c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953051a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bda5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 18
Completed Iteration #20
Best Reward: 0
coverage_call_count 7900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b50e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bb3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9530a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953128828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952ad55f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff952ad50b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 70.4225352112676
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953000e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952bf16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952ad52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b37ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9684abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9531e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff95317bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff953000c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff953656be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b7f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff952b37c50> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 70.4225352112676
initial coverage: 69.0141
time passed (minutes): 60.1862
iterations: 294
number of new inputs: 128
final coverage: 70.4225
total coverage increase: 1.40845
