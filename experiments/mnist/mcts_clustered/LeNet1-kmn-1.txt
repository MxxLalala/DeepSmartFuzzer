Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'kmn'], random_seed=1, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7f7ad6cfff28>, tc2=<function tc2 at 0x7f7ad6d10048>, tc3=<function tc3 at 0x7f7ad6d10158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 25.625
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.10416666666666785 3
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.10416666666666785 4
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.10416666666666785 5
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc284a20> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284780> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.2083333333333357 6
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc284e10> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284c88> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.31250000000000355 7
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2844a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.31250000000000355 8
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.31250000000000355 9
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.31250000000000355 10
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284c88> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.31250000000000355 11
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2844a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.31250000000000355 12
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284390> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.4166666666666714 13
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.4166666666666714 14
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284390> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.4166666666666714 15
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.4166666666666714 16
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.4166666666666714 17
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.4166666666666714 18
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.4166666666666714 19
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284c88> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.4166666666666714 20
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.4166666666666714 21
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.4166666666666714 22
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 0.2083333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.4166666666666714 23
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc284da0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 0.31250000000000355 7
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.5208333333333393 24
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc284710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 0.4166666666666714 8
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.6250000000000071 25
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc214e48> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 0.5208333333333393 9
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.729166666666675 26
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a160> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 0.6250000000000071 10
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.8333333333333428 27
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a828> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284780> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 0.729166666666675 11
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 0.9375000000000107 28
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc214c50> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214780> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284da0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 0.8333333333333428 12
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.0416666666666785 29
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc277860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214780> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc284da0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 0.9375000000000107 13
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.1458333333333464 30
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc22add8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a908> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284710> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.0416666666666785 14
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.2500000000000142 31
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb2e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb358> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284da0> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.1458333333333464 15
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.354166666666682 32
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.1458333333333464 16
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.354166666666682 33
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbb00> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a908> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc284710> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.2500000000000142 17
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.45833333333335 34
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbf98> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.354166666666682 18
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.5625000000000178 35
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.354166666666682 19
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.5625000000000178 36
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc284128> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.45833333333335 20
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.6666666666666856 37
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.45833333333335 21
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.6666666666666856 38
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfcf8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf940> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214e48> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.5625000000000178 22
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.7708333333333535 39
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #1
root->1
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.6666666666666856 23
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.8750000000000213 40
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.5208333333333393 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.6666666666666856 24
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.8750000000000213 41
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a828> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc284780> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.5208333333333393 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.6666666666666856 25
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.8750000000000213 42
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc214a20> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2143c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbf98> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.6250000000000071 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.7708333333333535 26
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 1.9791666666666892 43
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc284eb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf2b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.729166666666675 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.8750000000000213 27
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.083333333333357 44
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a8d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.8333333333333428 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.9791666666666892 28
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.187500000000025 45
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.8333333333333428 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.9791666666666892 29
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.187500000000025 46
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.8333333333333428 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.9791666666666892 30
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.187500000000025 47
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.8333333333333428 14
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 1.9791666666666892 31
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.187500000000025 48
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 0.9375000000000107 15
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 2.083333333333357 32
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.2916666666666927 49
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #2
root->1->2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb278> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.0416666666666785 16
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 2.187500000000025 33
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.3958333333333606 50
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb748> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.1458333333333464 17
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 2.2916666666666927 34
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.5000000000000284 51
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.2500000000000142 18
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 2.3958333333333606 35
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.6041666666666963 52
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1deef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.354166666666682 19
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 2.5000000000000284 36
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.708333333333364 53
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.45833333333335 20
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 2.6041666666666963 37
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.812500000000032 54
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbf98> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.0416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.45833333333335 21
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 2.6041666666666963 38
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.812500000000032 55
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.0416666666666785 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.45833333333335 22
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 2.6041666666666963 39
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.812500000000032 56
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a748> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.1458333333333464 14
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.5625000000000178 23
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 2.708333333333364 40
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 2.9166666666667 57
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb6d8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.2500000000000142 15
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.6666666666666856 24
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 2.812500000000032 41
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.0208333333333677 58
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
coverage_call_count 100
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #3
root->1->2->0
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c748> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.354166666666682 16
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.7708333333333535 25
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 2.9166666666667 42
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.1250000000000355 59
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.354166666666682 17
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.7708333333333535 26
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 2.9166666666667 43
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.1250000000000355 60
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaa20> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.4166666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.45833333333335 18
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.8750000000000213 27
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.0208333333333677 44
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.2291666666667034 61
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.4166666666666714 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.45833333333335 19
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.8750000000000213 28
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.0208333333333677 45
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.2291666666667034 62
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.4166666666666714 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.45833333333335 20
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.8750000000000213 29
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.0208333333333677 46
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.2291666666667034 63
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.4166666666666714 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.45833333333335 21
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.8750000000000213 30
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.0208333333333677 47
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.2291666666667034 64
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.4166666666666714 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.45833333333335 22
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.8750000000000213 31
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.0208333333333677 48
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.2291666666667034 65
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.4166666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.45833333333335 23
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.8750000000000213 32
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.0208333333333677 49
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.2291666666667034 66
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.4166666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.5208333333333393 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.5625000000000178 24
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 1.9791666666666892 33
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.1250000000000355 50
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.3333333333333712 67
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ad68> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.5208333333333393 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.6250000000000071 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.6666666666666856 25
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.083333333333357 34
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.2291666666667034 51
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.437500000000039 68
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #4
root->1->2->0->3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc2840f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.6250000000000071 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.729166666666675 14
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.7708333333333535 26
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.187500000000025 35
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.3333333333333712 52
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.541666666666707 69
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c208> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.729166666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.8333333333333428 15
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.8750000000000213 27
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.2916666666666927 36
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.437500000000039 53
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.645833333333375 70
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa20> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba5f8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c748> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.8333333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 0.9375000000000107 16
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 1.9791666666666892 28
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.3958333333333606 37
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.541666666666707 54
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.7500000000000426 71
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa3c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa6a0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c748> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.0416666666666785 17
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.083333333333357 29
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.5000000000000284 38
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.645833333333375 55
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.8541666666667105 72
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.9375000000000107 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.0416666666666785 18
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.083333333333357 30
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.5000000000000284 39
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.645833333333375 56
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.8541666666667105 73
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.9375000000000107 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.0416666666666785 19
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.083333333333357 31
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.5000000000000284 40
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.645833333333375 57
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.8541666666667105 74
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.9375000000000107 14
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.0416666666666785 20
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.083333333333357 32
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.5000000000000284 41
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.645833333333375 58
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.8541666666667105 75
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa2b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.0416666666666785 15
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.1458333333333464 21
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.187500000000025 33
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.6041666666666963 42
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.7500000000000426 59
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 3.9583333333333783 76
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #5
root->1->2->0->3->5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c208> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.1458333333333464 16
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.2500000000000142 22
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.2916666666666927 34
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.708333333333364 43
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.8541666666667105 60
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.062500000000046 77
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc18cdd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.2500000000000142 17
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.354166666666682 23
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.3958333333333606 35
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.812500000000032 44
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.9583333333333783 61
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.166666666666714 78
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 0.6250000000000071 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.2500000000000142 18
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.354166666666682 24
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.3958333333333606 36
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.812500000000032 45
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 3.9583333333333783 62
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.166666666666714 79
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 0.729166666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.354166666666682 19
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.45833333333335 25
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.5000000000000284 37
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 2.9166666666667 46
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.062500000000046 63
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.270833333333382 80
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c22b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2a58> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 0.8333333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.45833333333335 20
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.5625000000000178 26
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.6041666666666963 38
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.0208333333333677 47
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.166666666666714 64
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.37500000000005 81
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7748> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2840f0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.4166666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.5625000000000178 21
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.6666666666666856 27
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.708333333333364 39
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.1250000000000355 48
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.270833333333382 65
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.479166666666718 82
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 0.9375000000000107 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.5625000000000178 22
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.6666666666666856 28
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.708333333333364 40
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.1250000000000355 49
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.270833333333382 66
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.479166666666718 83
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4128> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c29e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.0416666666666785 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.6666666666666856 23
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.7708333333333535 29
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.812500000000032 41
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.2291666666667034 50
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.37500000000005 67
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.583333333333385 84
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4588> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7748> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc2840f0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.5208333333333393 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.1458333333333464 14
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.7708333333333535 24
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.8750000000000213 30
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.9166666666667 42
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.3333333333333712 51
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.479166666666718 68
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.687500000000053 85
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c29e8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.1458333333333464 15
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.7708333333333535 25
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.8750000000000213 31
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 2.9166666666667 43
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.3333333333333712 52
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.479166666666718 69
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.687500000000053 86
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc284908> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfa58> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.2500000000000142 16
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.8750000000000213 26
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.9791666666666892 32
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.0208333333333677 44
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.437500000000039 53
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.583333333333385 70
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.791666666666721 87
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba438> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.2500000000000142 17
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.8750000000000213 27
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 1.9791666666666892 33
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.0208333333333677 45
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.437500000000039 54
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.583333333333385 71
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.791666666666721 88
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c1d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7518> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.354166666666682 18
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 1.9791666666666892 28
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.083333333333357 34
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.1250000000000355 46
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.541666666666707 55
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.687500000000053 72
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 4.895833333333389 89
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #6
root->1->2->0->3->5->1
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2eb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.6250000000000071 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.45833333333335 19
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.083333333333357 29
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.187500000000025 35
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.2291666666667034 47
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.645833333333375 56
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.791666666666721 73
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.000000000000057 90
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.6250000000000071 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.45833333333335 20
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.083333333333357 30
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.187500000000025 36
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.2291666666667034 48
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.645833333333375 57
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.791666666666721 74
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.000000000000057 91
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.6250000000000071 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.45833333333335 21
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.083333333333357 31
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.187500000000025 37
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.2291666666667034 49
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.645833333333375 58
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.791666666666721 75
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.000000000000057 92
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2840f0> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.6250000000000071 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.45833333333335 22
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.083333333333357 32
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.187500000000025 38
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.2291666666667034 50
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.645833333333375 59
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.791666666666721 76
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.000000000000057 93
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e477d358> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d198> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ad68> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.729166666666675 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.5625000000000178 23
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.187500000000025 33
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.2916666666666927 39
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.3333333333333712 51
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.7500000000000426 60
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 4.895833333333389 77
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.104166666666725 94
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e477d7f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.8333333333333428 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.6666666666666856 24
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.2916666666666927 34
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.3958333333333606 40
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.437500000000039 52
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.8541666666667105 61
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.000000000000057 78
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.2083333333333925 95
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ad68> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.8333333333333428 14
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.6666666666666856 25
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.2916666666666927 35
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.3958333333333606 41
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.437500000000039 53
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.8541666666667105 62
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.000000000000057 79
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.2083333333333925 96
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbba8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ce10> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2eb8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.9375000000000107 15
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.7708333333333535 26
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.3958333333333606 36
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.5000000000000284 42
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.541666666666707 54
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.9583333333333783 63
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.104166666666725 80
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.31250000000006 97
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 0.9375000000000107 16
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.7708333333333535 27
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.3958333333333606 37
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.5000000000000284 43
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.541666666666707 55
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 3.9583333333333783 64
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.104166666666725 81
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.31250000000006 98
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e477d630> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d0f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ad68> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 1.0416666666666785 17
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.8750000000000213 28
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.5000000000000284 38
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.6041666666666963 44
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.645833333333375 56
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 4.062500000000046 65
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.2083333333333925 82
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.416666666666728 99
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e477d400> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dda0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d7f0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 1.1458333333333464 18
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 1.9791666666666892 29
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.6041666666666963 39
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.708333333333364 45
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.7500000000000426 57
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 4.166666666666714 66
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.31250000000006 83
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.520833333333396 100
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #7
root->1->2->0->3->5->1->5
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e47904a8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790518> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2eb8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 1.2500000000000142 19
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 2.083333333333357 30
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.708333333333364 40
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.812500000000032 46
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.8541666666667105 58
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 4.270833333333382 67
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.416666666666728 84
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.625000000000064 101
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e4790a90> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47908d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2eb8> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 1.354166666666682 20
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 2.187500000000025 31
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.812500000000032 41
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.9166666666667 47
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.9583333333333783 59
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 4.37500000000005 68
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.520833333333396 85
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.729166666666732 102
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47908d0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2eb8> 0.4166666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 1.354166666666682 21
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 2.187500000000025 32
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.812500000000032 42
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 2.9166666666667 48
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 3.9583333333333783 60
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 4.37500000000005 69
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.520833333333396 86
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.729166666666732 103
Completed Iteration #3
Best Reward: 0.10416666666666785
coverage_call_count 200
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e4799588> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2eb8> 0.5208333333333393 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 1.45833333333335 22
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 2.2916666666666927 33
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.9166666666667 43
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 3.0208333333333677 49
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 4.062500000000046 61
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 4.479166666666718 70
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.625000000000064 87
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.8333333333334 104
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2eb8> 0.5208333333333393 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 1.45833333333335 23
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 2.2916666666666927 34
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.9166666666667 44
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 3.0208333333333677 50
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 4.062500000000046 62
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 4.479166666666718 71
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.625000000000064 88
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.8333333333334 105
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47908d0> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2eb8> 0.5208333333333393 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 1.45833333333335 24
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 2.2916666666666927 35
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 2.9166666666667 45
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 3.0208333333333677 51
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 4.062500000000046 63
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 4.479166666666718 72
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.625000000000064 89
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.8333333333334 106
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e4790fd0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790438> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2eb8> 0.6250000000000071 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 1.5625000000000178 25
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 2.3958333333333606 36
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 3.0208333333333677 46
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 3.1250000000000355 52
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 4.166666666666714 64
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 4.583333333333385 73
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.729166666666732 90
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 5.9375000000000675 107
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e4799240> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ce10> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2eb8> 0.729166666666675 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbbe0> 1.6666666666666856 26
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ca58> 2.5000000000000284 37
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 3.1250000000000355 47
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de390> 3.2291666666667034 53
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe48> 4.270833333333382 65
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e10> 4.687500000000053 74
backprop <src.mcts.MCTS_Node object at 0x7f79fc277fd0> 5.8333333333334 91
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab1d0> 6.041666666666735 108
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #8
root->1->2->0->3->5->1->5->0
Best Reward: 0.10416666666666785
iteration: 0
found coverage increase 0.10416666666666785
Current Total Coverage 25.729166666666664
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 19
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4799fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473dcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e473d160> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47997f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47997f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d5f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47021d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47024e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47021d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47021d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47139e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47139e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47139e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47139b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47286a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47130b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47286a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e45c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e476e6d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47024a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46835c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 20
Completed Iteration #20
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e477df28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46838d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46838d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46838d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46837b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e477d390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa5239358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46837f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46837f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46837f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683208> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46832e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a04e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a04e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46832e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a04e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46832e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683e48> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c048> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba20> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1dea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc214c18> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.1041666666666714 9
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2147f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.1041666666666714 10
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc214860> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.2083333333333428 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.2083333333333428 11
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.2083333333333428 12
Completed Iteration #16
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1dea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.2083333333333428 13
Completed Iteration #17
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.2083333333333428 14
Completed Iteration #18
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.2083333333333428 15
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de4e0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de3c8> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.3125000000000142 16
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.2083333333333428 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.3125000000000142 17
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de3c8> 0.1041666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.3125000000000142 18
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.2083333333333428 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.3125000000000142 19
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.2083333333333428 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.3125000000000142 20
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.2083333333333428 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.3125000000000142 21
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.2083333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.3125000000000142 22
Completed Iteration #3
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.3125000000000142 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.4166666666666856 23
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e46bde80> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.4166666666666856 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.520833333333357 24
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd1d0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdc88> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bde80> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.520833333333357 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.6250000000000284 25
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdf28> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.6250000000000284 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.7291666666666998 26
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.6250000000000284 14
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.7291666666666998 27
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a400> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd9b0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.7291666666666998 15
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.8333333333333712 28
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.7291666666666998 16
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.8333333333333712 29
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.7291666666666998 17
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.8333333333333712 30
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba0f0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.8333333333333712 18
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 0.9375000000000426 31
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e4790550> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790390> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214860> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.9375000000000426 19
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 1.041666666666714 32
Completed Iteration #16
Best Reward: 0.1041666666666714
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.9375000000000426 20
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 1.041666666666714 33
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e47900b8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 1.041666666666714 21
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 1.1458333333333854 34
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 1.041666666666714 22
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 1.1458333333333854 35
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa390> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd9b0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 1.1458333333333854 23
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 1.2500000000000568 36
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 1.2500000000000568 24
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 1.3541666666667282 37
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4dd8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 1.3541666666667282 25
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 1.4583333333333997 38
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #2
root->0->5
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd240> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 1.4583333333333997 26
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 1.562500000000071 39
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ae10> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 1.562500000000071 27
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 1.6666666666667425 40
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc2147b8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 1.6666666666667425 28
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 1.7708333333334139 41
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e47904e0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 1.7708333333334139 29
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 1.8750000000000853 42
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #3
root->0->5->2
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 1.8750000000000853 30
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 1.9791666666667567 43
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d76d8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c88> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 1.9791666666667567 31
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 2.083333333333428 44
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc284080> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 2.083333333333428 32
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 2.1875000000000995 45
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc2845f8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 2.1875000000000995 33
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 2.291666666666771 46
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 2.291666666666771 34
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 2.3958333333334423 47
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #4
root->0->5->2->1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e46bda90> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 2.3958333333334423 35
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 2.5000000000001137 48
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae80> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 2.5000000000001137 36
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 2.604166666666785 49
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e4790358> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 2.604166666666785 37
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 2.7083333333334565 50
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc284860> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284c18> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2845f8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 2.7083333333334565 38
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 2.812500000000128 51
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e4728978> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 2.812500000000128 39
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 2.9166666666667993 52
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de128> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 2.9166666666667993 40
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 3.0208333333334707 53
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7518> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 3.0208333333334707 41
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 3.125000000000142 54
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #5
root->0->5->2->1->6
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
coverage_call_count 700
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e476e400> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c88> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 3.125000000000142 42
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 3.2291666666668135 55
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd940> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799748> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 3.2291666666668135 43
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 3.333333333333485 56
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #6
root->0->5->2->1->6->0
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baf28> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c88> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 2.5000000000001137 25
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 3.333333333333485 44
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 3.4375000000001563 57
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e47024e0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c88> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 2.604166666666785 26
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 3.4375000000001563 45
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 3.5416666666668277 58
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e476e9e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c88> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 2.7083333333334565 27
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 3.5416666666668277 46
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 3.645833333333499 59
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baf28> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c88> 0.520833333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 0.7291666666666998 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 1.7708333333334139 19
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 1.8750000000000853 20
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 2.3958333333334423 25
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 2.7083333333334565 28
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 3.5416666666668277 47
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 3.645833333333499 60
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2240> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c88> 0.6250000000000284 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 0.8333333333333712 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 1.8750000000000853 20
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 1.9791666666667567 21
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 2.5000000000001137 26
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 2.812500000000128 29
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 3.645833333333499 48
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 3.7500000000001705 61
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc284518> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c88> 0.7291666666666998 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 0.9375000000000426 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 1.9791666666667567 21
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 2.083333333333428 22
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 2.604166666666785 27
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 2.9166666666667993 30
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 3.7500000000001705 49
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 3.854166666666842 62
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e4713e48> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790ba8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47024e0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c88> 0.8333333333333712 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 1.041666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 2.083333333333428 22
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 2.1875000000000995 23
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 2.7083333333334565 28
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 3.0208333333334707 31
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 3.854166666666842 50
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 3.9583333333335133 63
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #7
root->0->5->2->1->6->0->6
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e46af400> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790ba8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47024e0> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c88> 0.9375000000000426 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 1.1458333333333854 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 2.1875000000000995 23
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 2.291666666666771 24
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 2.812500000000128 29
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 3.125000000000142 32
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 3.9583333333335133 51
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 4.062500000000185 64
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c0f0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799630> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713e48> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4790ba8> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47024e0> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c88> 1.041666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 1.2500000000000568 14
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 2.291666666666771 24
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 2.3958333333334423 25
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 2.9166666666667993 30
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 3.2291666666668135 33
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 4.062500000000185 52
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 4.166666666666856 65
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f79e47022b0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713e80> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af400> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4790ba8> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f79e47024e0> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c88> 1.1458333333333854 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a90> 1.3541666666667282 15
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7668> 2.3958333333334423 25
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 2.5000000000001137 26
backprop <src.mcts.MCTS_Node object at 0x7f79e47909b0> 3.0208333333334707 31
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 3.333333333333485 34
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 4.166666666666856 53
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de160> 4.2708333333335275 66
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #8
root->0->5->2->1->6->0->6->21
Best Reward: 0.1041666666666714
iteration: 14
found coverage increase 0.1041666666666714
Current Total Coverage 25.833333333333336
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e41095f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47136d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41095c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41091d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41097f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47136d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e41094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41097f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41095c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41095c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41097f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e41091d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41091d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 800
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e41092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41096d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41096d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411cac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41095c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41095c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e411c518> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f01d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8438> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 18
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b19e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40411d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e41094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e41090f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e89b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e89b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0630> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40416a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40416a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40090b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 20
Completed Iteration #21
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40416a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40412e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e41094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e80f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407acc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4009668> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 1100
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40095f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe13c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f532b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f539e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f532b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f539e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f532b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f532b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f532b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 16
Completed Iteration #16
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f532b0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f532b0> 0.0 9
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3cf8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401bda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40095f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f209b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f324e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f324a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f329e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f206d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f324a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 9
Completed Iteration #13
Best Reward: 0
coverage_call_count 1300
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f320b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8240> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f203c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f203c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f329e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f200b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f329e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f329e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e881d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e880f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e880f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e885f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e885f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e887b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e881d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e884e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e887f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 13
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f329e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed32e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b00> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 18
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e41095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41090f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e41096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41090f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41090f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47026a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47026d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e41092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e41098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afb00> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46afbe0> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.10416666666666785 5
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.10416666666666785 6
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.10416666666666785 7
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.10416666666666785 8
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.10416666666666785 9
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e47283c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.2083333333333357 10
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.2083333333333357 11
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.2083333333333357 12
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.2083333333333357 13
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa4a8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aad30> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47283c8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.31250000000000355 14
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa400> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.4166666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.4166666666666714 15
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.4166666666666714 16
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.4166666666666714 17
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.4166666666666714 18
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7518> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728320> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa400> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.5208333333333393 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.5208333333333393 19
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.5208333333333393 20
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4828> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.6250000000000071 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.6250000000000071 21
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.6250000000000071 22
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e477d278> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d240> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa4a8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aad30> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47283c8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.729166666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.729166666666675 23
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.729166666666675 24
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7208> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d79e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.8333333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.8333333333333428 25
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc284518> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284048> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4828> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 0.9375000000000107 26
Completed Iteration #2
Best Reward: 0.10416666666666785
coverage_call_count 1700
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc284be0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d79e8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.0416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.0416666666666785 27
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e474f668> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284048> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4828> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.1458333333333464 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.1458333333333464 28
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e477deb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.2500000000000142 14
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.2500000000000142 29
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa400> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.2500000000000142 15
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.2500000000000142 30
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e473d550> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728400> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa400> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.354166666666682 16
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.354166666666682 31
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e4799208> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799b38> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47283c8> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.45833333333335 17
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.45833333333335 32
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e4702e48> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.5625000000000178 18
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.5625000000000178 33
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b9b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.6666666666666856 19
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.6666666666666856 34
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1550> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.7708333333333535 20
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.7708333333333535 35
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e40090f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.8750000000000213 21
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.8750000000000213 36
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e41097b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa400> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.8750000000000213 22
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.8750000000000213 37
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.8750000000000213 23
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.8750000000000213 38
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4630> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 1.9791666666666892 24
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 1.9791666666666892 39
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e474f2b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 2.083333333333357 25
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 2.083333333333357 40
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e476eeb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 2.187500000000025 26
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 2.187500000000025 41
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728cf8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 2.2916666666666927 27
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 2.2916666666666927 42
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb6d8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 2.3958333333333606 28
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 2.3958333333333606 43
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d79e8> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 0.729166666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 2.3958333333333606 29
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 2.3958333333333606 44
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e411ccc0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2845f8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4728cf8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 0.8333333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 2.5000000000000284 30
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 2.5000000000000284 45
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e40b17f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 2.6041666666666963 31
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 2.6041666666666963 46
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009780> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.0416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 2.708333333333364 32
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 2.708333333333364 47
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.1458333333333464 13
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 2.812500000000032 33
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 2.812500000000032 48
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e412e2e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728cf8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.2500000000000142 14
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 2.9166666666667 34
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 2.9166666666667 49
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009780> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.354166666666682 15
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.0208333333333677 35
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.0208333333333677 50
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e4790358> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284be0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d79e8> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.45833333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.1250000000000355 36
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.1250000000000355 51
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.45833333333335 17
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.1250000000000355 37
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.1250000000000355 52
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2400> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009780> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.5625000000000178 18
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.2291666666667034 38
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.2291666666667034 53
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009780> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.6666666666666856 19
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.3333333333333712 39
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.3333333333333712 54
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa58> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.7708333333333535 20
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.437500000000039 40
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.437500000000039 55
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41094e0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4009780> 0.4166666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.7708333333333535 21
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.437500000000039 41
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.437500000000039 56
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc2843c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790128> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.8750000000000213 22
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.541666666666707 42
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.541666666666707 57
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790128> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.8750000000000213 23
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.541666666666707 43
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.541666666666707 58
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #2
root->2->11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477deb8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.6250000000000071 8
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.8750000000000213 24
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.541666666666707 44
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.541666666666707 59
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e473d320> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.729166666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 1.9791666666666892 25
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.645833333333375 45
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.645833333333375 60
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e477df98> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.8333333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 2.083333333333357 26
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.7500000000000426 46
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.7500000000000426 61
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc284240> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 2.187500000000025 27
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.8541666666667105 47
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.8541666666667105 62
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c25c0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2c50> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 1.0416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 2.2916666666666927 28
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 3.9583333333333783 48
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 3.9583333333333783 63
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bada0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bad68> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477deb8> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 1.1458333333333464 13
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 2.3958333333333606 29
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 4.062500000000046 49
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 4.062500000000046 64
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba8d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477df98> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 1.2500000000000142 14
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 2.5000000000000284 30
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 4.166666666666714 50
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 4.166666666666714 65
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ab00> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bab70> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b17f0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 1.354166666666682 15
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 2.6041666666666963 31
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 4.270833333333382 51
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 4.270833333333382 66
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a518> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790ac8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702e48> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 1.45833333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 2.708333333333364 32
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 4.37500000000005 52
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 4.37500000000005 67
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 1.5625000000000178 17
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 2.812500000000032 33
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 4.479166666666718 53
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 4.479166666666718 68
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 1.6666666666666856 18
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 2.9166666666667 34
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 4.583333333333385 54
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 4.583333333333385 69
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e473d0b8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bab70> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b17f0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 1.7708333333333535 19
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 3.0208333333333677 35
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 4.687500000000053 55
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 4.687500000000053 70
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e401b2b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 1.8750000000000213 20
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 3.1250000000000355 36
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 4.791666666666721 56
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 4.791666666666721 71
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb6d8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 1.8750000000000213 21
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 3.1250000000000355 37
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 4.791666666666721 57
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 4.791666666666721 72
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #3
root->2->11->2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba198> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 1.9791666666666892 22
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 3.2291666666667034 38
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 4.895833333333389 58
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 4.895833333333389 73
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ab38> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 2.083333333333357 23
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 3.3333333333333712 39
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 5.000000000000057 59
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 5.000000000000057 74
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a3c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1decc0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 2.187500000000025 24
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 3.437500000000039 40
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 5.104166666666725 60
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 5.104166666666725 75
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 2.2916666666666927 25
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 3.541666666666707 41
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 5.2083333333333925 61
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 5.2083333333333925 76
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d72b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 2.3958333333333606 26
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 3.645833333333375 42
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 5.31250000000006 62
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 5.31250000000006 77
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e477d518> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 2.5000000000000284 27
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 3.7500000000000426 43
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 5.416666666666728 63
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 5.416666666666728 78
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1deb38> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 2.6041666666666963 28
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 3.8541666666667105 44
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 5.520833333333396 64
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 5.520833333333396 79
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46af908> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1b70> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b2b0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 2.708333333333364 29
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 3.9583333333333783 45
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 5.625000000000064 65
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 5.625000000000064 80
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #4
root->2->11->2->17
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c9b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba198> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 1.5625000000000178 16
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 2.812500000000032 30
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 4.062500000000046 46
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 5.729166666666732 66
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 5.729166666666732 81
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
coverage_call_count 1800
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc284860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 1.6666666666666856 17
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 2.9166666666667 31
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 4.166666666666714 47
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 5.8333333333334 67
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 5.8333333333334 82
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e474fcf8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 1.7708333333333535 18
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 3.0208333333333677 32
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 4.270833333333382 48
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 5.9375000000000675 68
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 5.9375000000000675 83
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1deeb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790978> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 1.8750000000000213 19
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 3.1250000000000355 33
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 4.37500000000005 49
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 6.041666666666735 69
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 6.041666666666735 84
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf5f8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 1.9791666666666892 20
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 3.2291666666667034 34
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 4.479166666666718 50
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 6.145833333333403 70
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 6.145833333333403 85
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbd68> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 1.5625000000000178 16
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 2.083333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 3.3333333333333712 35
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 4.583333333333385 51
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 6.250000000000071 71
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 6.250000000000071 86
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbd68> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 1.6666666666666856 17
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 2.187500000000025 22
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 3.437500000000039 36
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 4.687500000000053 52
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 6.354166666666739 72
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 6.354166666666739 87
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfeb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbb00> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbd68> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 1.7708333333333535 18
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 2.2916666666666927 23
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 3.541666666666707 37
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 4.791666666666721 53
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 6.458333333333407 73
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 6.458333333333407 88
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46838d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683eb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de710> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 1.8750000000000213 19
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 2.3958333333333606 24
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 3.645833333333375 38
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 4.895833333333389 54
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 6.562500000000075 74
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 6.562500000000075 89
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdac8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683c50> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284860> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 1.9791666666666892 20
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 2.5000000000000284 25
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 3.7500000000000426 39
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 5.000000000000057 55
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 6.6666666666667425 75
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 6.6666666666667425 90
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #5
root->2->11->2->17->0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e4790160> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284208> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 2.083333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 2.6041666666666963 26
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 3.8541666666667105 40
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 5.104166666666725 56
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 6.77083333333341 76
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 6.77083333333341 91
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2a20> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 2.187500000000025 22
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 2.708333333333364 27
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 3.9583333333333783 41
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 5.2083333333333925 57
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 6.875000000000078 77
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 6.875000000000078 92
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 2.2916666666666927 23
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 2.812500000000032 28
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 4.062500000000046 42
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 5.31250000000006 58
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 6.979166666666746 78
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 6.979166666666746 93
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfd30> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 2.3958333333333606 24
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 2.9166666666667 29
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 4.166666666666714 43
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 5.416666666666728 59
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 7.083333333333414 79
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 7.083333333333414 94
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e4683470> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 2.5000000000000284 25
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 3.0208333333333677 30
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 4.270833333333382 44
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 5.520833333333396 60
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 7.187500000000082 80
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 7.187500000000082 95
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1decc0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 2.6041666666666963 26
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 3.1250000000000355 31
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 4.37500000000005 45
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 5.625000000000064 61
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 7.29166666666675 81
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 7.29166666666675 96
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd4e0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 2.708333333333364 27
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 3.2291666666667034 32
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 4.479166666666718 46
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 5.729166666666732 62
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 7.395833333333417 82
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 7.395833333333417 97
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 2.812500000000032 28
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 3.3333333333333712 33
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 4.583333333333385 47
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 5.8333333333334 63
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 7.500000000000085 83
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 7.500000000000085 98
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7978> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0160> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 2.9166666666667 29
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 3.437500000000039 34
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 4.687500000000053 48
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 5.9375000000000675 64
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 7.604166666666753 84
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 7.604166666666753 99
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc1def60> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284208> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 3.0208333333333677 30
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 3.541666666666707 35
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 4.791666666666721 49
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 6.041666666666735 65
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 7.708333333333421 85
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 7.708333333333421 100
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc284908> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214ef0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 3.1250000000000355 31
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 3.645833333333375 36
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 4.895833333333389 50
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 6.145833333333403 66
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 7.812500000000089 86
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 7.812500000000089 101
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 1.45833333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 3.1250000000000355 32
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 3.645833333333375 37
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 4.895833333333389 51
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 6.145833333333403 67
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 7.812500000000089 87
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 7.812500000000089 102
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0b8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 1.5625000000000178 17
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 3.2291666666667034 33
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 3.7500000000000426 38
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 5.000000000000057 52
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 6.250000000000071 68
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 7.916666666666757 88
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 7.916666666666757 103
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #6
root->2->11->2->17->0->3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46a07f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 1.6666666666666856 18
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 3.3333333333333712 34
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 3.8541666666667105 39
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 5.104166666666725 53
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 6.354166666666739 69
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 8.020833333333425 89
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 8.020833333333425 104
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7cf8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0160> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 1.7708333333333535 19
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 3.437500000000039 35
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 3.9583333333333783 40
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 5.2083333333333925 54
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 6.458333333333407 70
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 8.125000000000092 90
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 8.125000000000092 105
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7d68> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0160> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 1.8750000000000213 20
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 3.541666666666707 36
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 4.062500000000046 41
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 5.31250000000006 55
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 6.562500000000075 71
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 8.22916666666676 91
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 8.22916666666676 106
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46f74e0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 1.9791666666666892 21
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 3.645833333333375 37
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 4.166666666666714 42
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 5.416666666666728 56
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 6.6666666666667425 72
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 8.333333333333428 92
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 8.333333333333428 107
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a07f0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 1.9791666666666892 22
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 3.645833333333375 38
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 4.166666666666714 43
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 5.416666666666728 57
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 6.6666666666667425 73
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 8.333333333333428 93
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 8.333333333333428 108
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8390> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 1.0416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 2.083333333333357 23
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 3.7500000000000426 39
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 4.270833333333382 44
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 5.520833333333396 58
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 6.77083333333341 74
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 8.437500000000096 94
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 8.437500000000096 109
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79fc214ac8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 1.1458333333333464 13
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 2.187500000000025 24
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 3.8541666666667105 40
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 4.37500000000005 45
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 5.625000000000064 59
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 6.875000000000078 75
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 8.541666666666764 95
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 8.541666666666764 110
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e4790940> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a07f0> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 1.2500000000000142 14
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 2.2916666666666927 25
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 3.9583333333333783 41
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 4.479166666666718 46
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 5.729166666666732 60
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 6.979166666666746 76
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 8.645833333333432 96
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 8.645833333333432 111
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46a04e0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 1.354166666666682 15
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 2.3958333333333606 26
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 4.062500000000046 42
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 4.583333333333385 47
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 5.8333333333334 61
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 7.083333333333414 77
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 8.7500000000001 97
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 8.7500000000001 112
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #7
root->2->11->2->17->0->3->3
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a20> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0160> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 1.45833333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 2.5000000000000284 27
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 4.166666666666714 43
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 4.687500000000053 48
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 5.9375000000000675 62
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 7.187500000000082 78
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 8.854166666666767 98
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 8.854166666666767 113
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1668> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0160> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 1.5625000000000178 17
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 2.6041666666666963 28
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 4.270833333333382 44
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 4.791666666666721 49
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 6.041666666666735 63
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 7.29166666666675 79
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 8.958333333333435 99
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 8.958333333333435 114
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe10f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 1.6666666666666856 18
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 2.708333333333364 29
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 4.37500000000005 45
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 4.895833333333389 50
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 6.145833333333403 64
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 7.395833333333417 80
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 9.062500000000103 100
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 9.062500000000103 115
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3f60> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd37b8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7978> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0160> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 1.7708333333333535 19
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 2.812500000000032 30
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 4.479166666666718 46
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 5.000000000000057 51
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 6.250000000000071 65
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 7.500000000000085 81
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 9.16666666666677 101
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 9.16666666666677 116
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3e80> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0160> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 1.8750000000000213 20
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 2.9166666666667 31
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 4.583333333333385 47
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 5.104166666666725 52
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 6.354166666666739 66
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 7.604166666666753 82
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 9.270833333333439 102
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 9.270833333333439 117
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.20833333333333215
backprop <src.mcts.MCTS_Node object at 0x7f79e47992b0> 0.20833333333333215 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c828> 0.20833333333333215 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7978> 0.41666666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0160> 0.9375000000000071 9
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 1.1458333333333428 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 2.0833333333333535 21
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 3.125000000000032 32
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 4.791666666666718 48
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 5.312500000000057 53
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 6.562500000000071 67
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 7.812500000000085 83
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 9.47916666666677 103
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 9.47916666666677 118
Completed Iteration #9
Best Reward: 0.20833333333333215
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd6d8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0160> 1.041666666666675 10
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 1.2500000000000107 12
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 2.1875000000000213 22
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 3.2291666666667 33
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 4.895833333333385 49
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 5.416666666666725 54
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 6.666666666666739 68
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 7.916666666666753 84
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 9.583333333333439 104
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 9.583333333333439 119
Completed Iteration #10
Best Reward: 0.20833333333333215
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7f98> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7048> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 1.3541666666666785 13
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 2.291666666666689 23
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 3.3333333333333677 34
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 5.000000000000053 50
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 5.5208333333333925 55
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 6.770833333333407 69
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 8.020833333333421 85
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 9.687500000000107 105
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 9.687500000000107 120
Completed Iteration #11
Best Reward: 0.20833333333333215
Completed Iteration #12
Best Reward: 0.20833333333333215
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0ac8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe10f0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 1.4583333333333464 14
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 2.395833333333357 24
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 3.4375000000000355 35
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 5.104166666666721 51
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 5.62500000000006 56
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 6.875000000000075 70
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 8.125000000000089 86
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 9.791666666666774 106
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 9.791666666666774 121
Completed Iteration #13
Best Reward: 0.20833333333333215
Completed Iteration #14
Best Reward: 0.20833333333333215
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1c18> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1a58> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 1.5625000000000142 15
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 2.500000000000025 25
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 3.5416666666667034 36
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 5.208333333333389 52
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 5.729166666666728 57
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 6.9791666666667425 71
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 8.229166666666757 87
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 9.895833333333442 107
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 9.895833333333442 122
Completed Iteration #15
Best Reward: 0.20833333333333215
Completed Iteration #16
Best Reward: 0.20833333333333215
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1e80> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7048> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 1.666666666666682 16
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 2.6041666666666927 26
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 3.6458333333333712 37
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 5.312500000000057 53
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 5.833333333333396 58
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 7.08333333333341 72
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 8.333333333333425 88
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 10.00000000000011 108
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 10.00000000000011 123
Completed Iteration #17
Best Reward: 0.20833333333333215
Completed Iteration #18
Best Reward: 0.20833333333333215
Completed Iteration #19
Best Reward: 0.20833333333333215
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3c50> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd34e0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63a20> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0160> 1.1458333333333428 11
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 1.77083333333335 17
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 2.7083333333333606 27
backprop <src.mcts.MCTS_Node object at 0x7f79e40b18d0> 3.750000000000039 38
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 5.416666666666725 54
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 5.937500000000064 59
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 7.187500000000078 73
backprop <src.mcts.MCTS_Node object at 0x7f79e47e47f0> 8.437500000000092 89
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 10.104166666666778 109
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7f98> 10.104166666666778 124
Completed Iteration #20
Best Reward: 0.20833333333333215
Completed Iteration #21
Best Reward: 0.20833333333333215
Completed Iteration #22
Best Reward: 0.20833333333333215
Completed Iteration #23
Best Reward: 0.20833333333333215
Completed Iteration #24
Best Reward: 0.20833333333333215
Completed Iteration #25
Best Reward: 0.20833333333333215
Completed MCTS Level/Depth: #8
root->2->11->2->17->0->3->3->19
Best Reward: 0.20833333333333215
iteration: 50
found coverage increase 0.20833333333333215
Current Total Coverage 26.041666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 3
Completed Iteration #3
Best Reward: 0
coverage_call_count 1900
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f323c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f322e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47134a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40411d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40411d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40414a8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f324e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f322b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f852b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40415c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40415c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40415c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1438> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409df98> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409df98> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409df98> 0.0 4
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409df98> 0.0 5
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40805f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e409df98> 0.0 6
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409df98> 0.0 7
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409df98> 0.0 8
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409df98> 0.0 9
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e409df98> 0.0 10
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1dec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40802e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff14a8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f530f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e884e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb39e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb39e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 21
Completed Iteration #23
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f534a8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e887f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25defd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25defd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25defd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25defd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25deeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25deeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25deda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e639e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d692e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e409d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d692e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f322e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 19
Completed Iteration #20
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de860> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e887f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d015c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79e4041278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d011d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d019b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d019b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30ba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb30b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d25de208> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b320> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25dec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea278> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d019b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d308d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 15
Completed Iteration #14
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d308d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c436d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c002b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b0b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c261d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c261d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c148d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c439b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de48> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25dec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 12
Completed Iteration #10
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd78d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15dff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d2b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15efda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15851d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15851d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1585860> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d15efba8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4041a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a6c6ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e81d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e81d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3b70> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd30b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb32b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1deb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1deb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2145f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2776d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2776d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec87f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec87f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb38d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47903c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47903c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaa90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47991d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41090f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
coverage_call_count 3000
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47022b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46aff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46aff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f9e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41097b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41097b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e41090f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41097b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41097b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47991d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 17
Completed Iteration #22
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47991d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4799358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e636a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40090f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40090f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e636a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40090f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40090f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 19
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 18
Completed Iteration #18
Best Reward: 0
coverage_call_count 3200
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d569b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d564e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d564e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d564e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd73c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c145c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f327b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f327b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f327b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d694e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25deb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d694e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30470> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d696a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d696a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d696a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25decc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47136a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d696a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f321d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c141d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c269e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c269e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbeb8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 14
Completed Iteration #13
Best Reward: 0
coverage_call_count 3400
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaa58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f406a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f201d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f201d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e882b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f539e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8be10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c007f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15952e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15952e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15958d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15958d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15958d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca95f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca95f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00ef0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f206d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c633c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c633c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6feb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63550> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d2f402e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a90> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c585f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c585f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c585f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05536d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05536d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05536a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 3900
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0540a58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05401d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05401d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d058a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05402e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05405c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c582b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553208> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553208> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0553208> 0.0 5
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553208> 0.0 6
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0553208> 0.0 7
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553208> 0.0 8
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0553208> 0.0 9
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553208> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0553208> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05533c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0553208> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0553208> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15950b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 19
Completed Iteration #21
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d052cac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05401d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05401d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058af28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffb00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a28d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a26d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c007b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c007b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41098d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47139b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccac18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e41098d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca400> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 8
Completed Iteration #13
Best Reward: 0
coverage_call_count 4200
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4713518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25de278> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccabe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40b17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c006a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c145c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 4300
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4109780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca5c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d568d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63278> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c269b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c269b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 4400
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c262e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c269b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea630> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e476eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b5f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2842e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47282b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2848d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc284d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47026d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46afcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4790a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb710> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc18cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2848d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2848d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2848d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc277cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c260b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4702438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e477da20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a01d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46838d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22afd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22afd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aa9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15855f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15852e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15855f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec84a8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2848d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e36a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
coverage_call_count 4700
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40094a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1defd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40413c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e39b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e39b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e39b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d30> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c587b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c631d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05400b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05400b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c631d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05400b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05409b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15efb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4799e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e473d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0561dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05533c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05533c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d05535c0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb72b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca95f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb72b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05612b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477dc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c6d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2140b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc2140b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d052c550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7becc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5f28> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7231d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7236d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7236d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bea90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bea90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab723208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a20> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7beba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7232e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723550> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c439b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c439b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab723278> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7beb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7beb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7beb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acd30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7becc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7375f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7becc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6bef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6beb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7375f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6beb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6beb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6722b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6beb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15efc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6729e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d208> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7becc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6114a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6115c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6115c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6110b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6bef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6110b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6bef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6110b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 16
Completed Iteration #23
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1552b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1687b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1552b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168240> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1552b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1559b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6720f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6720f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6720f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7beeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7beeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1223c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1221d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1229e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f5c0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1229e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1222b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f5c0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1220f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1220f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fda58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1220f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 12
Completed Iteration #17
Best Reward: 0
coverage_call_count 5700
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1220f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0861d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0864e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b46d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b46d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a390> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0640f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0644a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0640f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 5800
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0640f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f9b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1684e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1684e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0646d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1684e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab064048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabd75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab023240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabebcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabebcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabd79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabebcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabebbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c001d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabebbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e15c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c3c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ace80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6bec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6bec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac4a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabd77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6befd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be940> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c00080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac6d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab723a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fde10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab155f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c436d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e9d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e411cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cdd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cdd8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cdd8> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f79e411c5c0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e411cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052ce80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1baa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d057c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab67def0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 6200
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f40cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb77b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c2b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0561d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051ca20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d30908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0470> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabeb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d052cf28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05537b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbcc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0553da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0561da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1585278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4041c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15df860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2ec8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15852b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15ef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1585278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1585940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d2fd3080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c587b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c635c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabd7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63c50> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab155080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e412e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4683ba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4683a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f85160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc2148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc22ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc18ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc214668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc214400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e473da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc22a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d057c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cb470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0ca99e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1fbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab69b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15df198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab67df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fb32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab155080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4683f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab737438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0c18> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1ba2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04c0c18> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f79e46f7b70> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc284dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc284978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e7b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4728748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d058a0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e401b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab62c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e401b048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d052ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4790b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c58438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e412e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47993c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d56a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47993c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c584a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e47e49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c584a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0553d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc277a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40e8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f438> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4009438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cbe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4009438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d051ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c262b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4109b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c262b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25def28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25decc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f6fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c262b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d240> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e407a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7c7abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c142b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d057c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40090f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f53828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f20080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e4713828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab67d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e63630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab723d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25deb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c63940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25deb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e477d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0553d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c1f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d2e886a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d048cef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 19
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 6700
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d048cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d048cef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3668> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d058ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4702ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2710> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e477d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e4009c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2eb4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79fc1aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e884e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1c142b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c6df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cd7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79e407a080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab12ff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab086b38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0860f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05402e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2ff1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 6800
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d0540f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0540eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2f32898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e47284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d697b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2e88c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c630b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e46afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e401be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d2ed3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1d697b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0c630b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c8bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40809b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d25dee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c26898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e474f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab086c88> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d048c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4790940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5390> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e46839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e409d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0236a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 13
Completed Iteration #12
Best Reward: 0
coverage_call_count 6900
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d15953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0236a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0236a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0cb7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0236a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab672a20> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ceaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1ccae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05c56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4009630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15958d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d2fe1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1cb2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15958d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e476ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40809b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79e40809b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab023630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 21
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d0540eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 22
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15958d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 23
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 24
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1c14d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d15958d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 25
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 26
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672c88> 0.0 27
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e409d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f14e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f14e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6110f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6110f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6110f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6110f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6112e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e40809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 7000
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab672320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab672320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7708d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7708d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab770748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab086828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d01278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab7be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79d1595b70> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1227f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1222b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab122898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168630> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1222b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1684a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b48d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1684a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1595d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b48d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4fd0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab672438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab122908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d05409e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab611eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0109e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79d04a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab07ff28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1221d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8de10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8de10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab086828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8dda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1240> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabfee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab023710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e4728358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabfee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6116d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6116d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab18fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabfee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabfee80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79aabfee80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab6116d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1c18> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d044e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d044e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d045f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d045f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d045f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6aeb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79e474fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab611240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab770cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d223c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d225f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d225f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8de48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab12f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab09aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab010080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab054a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbabe0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d8d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0780> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdcdd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d223c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d220f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab010b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab064ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc320> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc19b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6dae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d05e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab09a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab168470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79ab7709b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbfa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbfa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c859b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c858d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c858d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c858d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab6da198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c858d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d0c6f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c858d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c850f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c408d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab07f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d1d69c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab13e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9da1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 7500
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22e10> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c354e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d04a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c259e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c250f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c257b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c250f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab054a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab064ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79aabfe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cdc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9dbaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d04ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab168470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f97b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f97b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9599080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9599240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9599208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9599940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9599cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9599208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9599d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9599d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9599ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9599d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f96d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9599390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9599208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95d33c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9599f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0547b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab1f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9599128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9599710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9599ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9320> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c254a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c254a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95acc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9551208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9551240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9551780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9551828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9551a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9551a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9551470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9551a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95517f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c254a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9551e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9551278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d223c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9551ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a956e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a956eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a955a278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a956edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a956e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a956ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a950e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a950e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a950e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a950e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a950e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a950e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a950eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a950edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a950eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a956e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950e4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9551e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9551828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a956e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950efd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c25fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9551978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a950e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9551dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a956e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9551908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a956e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a950ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9551978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9551978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c251d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79ab0107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c17470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95512e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9599ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cc16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9599128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9599128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cf0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 7800
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a951d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9599128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a951d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9599c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9599128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c35a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a951db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c171d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94d15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a950ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a951db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c171d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a951db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c171d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a951db38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a955a518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f79a95acb00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94fc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94fc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94fc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94fc160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94fcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9cbf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94fc160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79d25de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94fcac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a94e69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94e60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a94e6d30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a951dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a951d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a94d10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d22eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c6ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9d229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a951dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9c40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95acc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a95991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a9c172b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a951d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a951d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95acc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a955a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a951d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a9d0f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f79a956eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f79a95d32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f79a95f9e10> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 26.041666666666668
initial coverage: 25.625
time passed (minutes): 60.1112
iterations: 284
number of new inputs: 192
final coverage: 26.0417
total coverage increase: 0.416667
