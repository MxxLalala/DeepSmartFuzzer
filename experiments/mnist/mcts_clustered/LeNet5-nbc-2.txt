Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'nbc'], random_seed=2, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7fa52fe53f28>, tc2=<function tc2 at 0x7fa52fe64048>, tc3=<function tc3 at 0x7fa52fe64158>, tfc_threshold=121, time_period=3600, verbose=True)
initial coverage: 7.82443
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47454a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ee48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745470> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47243c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47345c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47346d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470de80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f33c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46959b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 200
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46950f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46950f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47245f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47245f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47245f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47245f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47245f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46745f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 300
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1668> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967845f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784588> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4ec1bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47346d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47346d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d15f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47342b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47346d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f29b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46857f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46857f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46956a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46956a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f37b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46745f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695128> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470de48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47247b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47244a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47243c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46955c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46955c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4fe41c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47244a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 600
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f31d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f26a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46855c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46632e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46632e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46639b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46639b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46639b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966979b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46744a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46744a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46744a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b44e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 700
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966536d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966535f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966693c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966693c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966535f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496697780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669e10> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966696d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4ec1bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46855c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46855c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa46403db70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47243c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4ec1bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44421b710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4ec1bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46639b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46639b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf358> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d60b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 900
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b550> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b45c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44421bdd8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441485f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 1000
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5dd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441091d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444148978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441182e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441180f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441182e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441182e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441182e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa444109208> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 1100
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441188d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441187b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441187b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444134a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444134b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b77f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5080> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 1200
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440491d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440562e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440562e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440562e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440807f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440807f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440495c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440568d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444049828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440360b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444161d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444080518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfd68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4fe41cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966690b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46955c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46955c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46955c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663f28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47450f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47459e8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4ec11afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679df28> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679df28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679df28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679df28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966970f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679df28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679df28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49679df28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679df28> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa49679df28> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966970f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49679df28> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679d128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa49679df28> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679df28> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbca90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf6a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440876a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440876a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440877f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440876a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444036898> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440367f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440361d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440361d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444087a20> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440808d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440808d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966978d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49667a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496653710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 1700
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966530f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b475efd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a59e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966536d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a53c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a53c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a59e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4fe41cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e56d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa444080828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa44420cbe0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4ec11afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966530f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fda58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49663f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441488d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 15
Completed Iteration #24
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441d62e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4fe41cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441341d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440365c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444036390> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441180f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441099e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440567b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441092e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441099e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440675c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c908> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d193c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4fe41cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b475edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fbe0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440566d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d196a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d191d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d191d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1390> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d196d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d196d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce18d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 16
Completed Iteration #14
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d192b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4fe41cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce18d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d196d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d192b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cedba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cedda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cedc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ceddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c983c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cabf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c986a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c986a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c986a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427ced748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427caba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c405c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cabf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cedd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cedf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444134080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427cab400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cedeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cedef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c589b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c586d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c589b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cab438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c231d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1af28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cedf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cabb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c1aeb8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d50f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277eca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec518> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecfd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec390> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cabe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cedc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c584e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c584e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c584e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c584e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 2500
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277934e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277934e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277938d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277938d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277934e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277934e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277934e0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277934e0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fa427793860> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427756080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427756128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cedf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c083c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427756080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427756a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427756128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427756a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427756080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427756128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c58d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277565c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403d780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403d780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444161b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440499b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d17f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d10f0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49663f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441618d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ac18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ac18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441618d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d7f978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427756320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277564e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966975c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966977f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679dba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277564e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966975c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a470> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49663fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b475ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c08828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c087b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c087b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44413f9b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4663668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440870f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f24e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a51d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f24e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440806d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444087e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080f28> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440806d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440f40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c08cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444087b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080da0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966696a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496669b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966533c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966533c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966533c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444134a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441180f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967f2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440f44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440367f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444161eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4966539b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444148588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444036160> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b479ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967cfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b479c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0240> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440367f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44420c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440367f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440365c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496784780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441fde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44413f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967847f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4967847f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49667a7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b47248d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4ec1bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b47247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 3000
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf748> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427756d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444056048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4724ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa496653d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444080cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444118ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4440366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427756d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa49679d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44421b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496653d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5be0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496669f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427d5cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967cf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440678d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427747908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427747e10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c582e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4b476bdd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44421bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa46403deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d7fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d5ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ce1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496697be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ce16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfcfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9cc0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277933c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277931d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277933c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496653320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277933c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441097f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f98> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cedf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4966539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c231d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c235f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c235f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c235c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c235f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c23e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c235c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c23358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c235f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c235f8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d19860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4440677f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444148518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4734e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427756d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c58320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cedc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ceda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa496784390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c404e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c404e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c404e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa444067ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cede80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4b4685f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cede80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ceda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427793dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cede80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277565f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa46403deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c405c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409d5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444049320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4695198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa44409d240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427ced160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c1af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427cabc88> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e87278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e87278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e87278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e87e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e87550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e87eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e877f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277eca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e87390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e87588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e87a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e87e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e87dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e877f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e871d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e87550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e87908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e87cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e87c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4745e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b470d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e87e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e87f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e87908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427cedda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e87c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb40b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4dc65e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e1d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b4674908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e87c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c98ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49679d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa44409dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cabba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d3fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427771cc0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427793f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426eb44e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c1a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42cfbc0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c40390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa444109dd8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444109518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa426e62a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa49667a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427747eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427cab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427c989b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e7cfd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427ced4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e87c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277710f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e059b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277710f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e057f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e057f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e059b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e059b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e87748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e341d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e341d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e059b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4277719e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444118ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e340f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e05fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e34978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4967b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e057f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444049320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44420c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e051d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e057f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d5c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d19e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426e34a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e9ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa444036828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e345f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e345f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e345f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e9ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e345f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426946470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426946860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426946a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269b74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4441e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c98860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426946dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426946940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426946390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426967048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426967320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426946f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269467b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426946940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426946048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426946390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426967be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269674a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426967a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426967860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426946080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426967d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269078d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269074a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269078d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426918dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 3700
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426907390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b47ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426967630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426967ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426946908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269672e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426946c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269294e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426946f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426946940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427c40fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269292b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426946940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4b46d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269294e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426946940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426946be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269672e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269292b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426907cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427747f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444067f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269463c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e34550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269463c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269078d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269463c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa44409def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269078d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e34e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269070b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269071d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426967160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269184a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269070b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269070b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269070b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269184a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268f42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269184a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426918a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426881400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269293c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269293c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e22e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4518> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa444036828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426967b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4277ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426918c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268f49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426918c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426881780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426946cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e05198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426918ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426881a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426881c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426881128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426881518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426881e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426881e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426929c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426881cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426881128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426881cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426881b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42684f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42684f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42684f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42684f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42684fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426863390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426881ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa496697b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42684f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426863080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426863240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42684f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42684fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42684f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426840780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42684fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42684fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42684fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269b7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e05ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840a20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426eb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427771898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426881f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269a8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426881518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268f4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269186d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426881908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268e28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426881a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426881a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426881dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426840b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426907b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268acc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426929cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269186d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426967c18> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426863be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426863dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426907128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426840da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268817f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42684f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426817208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426863ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426863e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268637f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268817f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269077f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268817f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426817e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4268174a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426817208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426863a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268174a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269073c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426946048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426863898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426863f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42683a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42683a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42683a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42683a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa42683a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42683a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42683a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa42683a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268f45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426829860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268290f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268630f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa427d6af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268630f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268290f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa427d6a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4268290f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4268176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426829f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa426863c88> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426829b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426817550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426817390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426817550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e62b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e62080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cde48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cde48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa426817390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa426817550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269dc828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa426e7c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa4269cd208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa4269dceb8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 7.8244274809160315
initial coverage: 7.82443
time passed (minutes): 60.2502
iterations: 157
number of new inputs: 0
final coverage: 7.82443
total coverage increase: 0
