Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='CIFAR10', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 32, 32, 3), input_upper_limit=255, model='CIFAR_CNN', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['cifar10', 'CIFAR_CNN', 'mcts', 'nbc'], random_seed=2, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7fa905836f28>, tc2=<function tc2 at 0x7fa905847048>, tc3=<function tc3 at 0x7fa905847158>, tfc_threshold=9, time_period=3600, verbose=True)
initial coverage: 2.02145
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([ 1, 10, 10,  3])},
 {'lower_limits': array([ 0,  0, 10,  0]),
  'upper_limits': array([ 1, 10, 20,  3])},
 {'lower_limits': array([ 0,  0, 20,  0]),
  'upper_limits': array([ 1, 10, 32,  3])},
 {'lower_limits': array([ 0, 10,  0,  0]),
  'upper_limits': array([ 1, 20, 10,  3])},
 {'lower_limits': array([ 0, 10, 10,  0]),
  'upper_limits': array([ 1, 20, 20,  3])},
 {'lower_limits': array([ 0, 10, 20,  0]),
  'upper_limits': array([ 1, 20, 32,  3])},
 {'lower_limits': array([ 0, 20,  0,  0]),
  'upper_limits': array([ 1, 32, 10,  3])},
 {'lower_limits': array([ 0, 20, 10,  0]),
  'upper_limits': array([ 1, 32, 20,  3])},
 {'lower_limits': array([ 0, 20, 20,  0]),
  'upper_limits': array([ 1, 32, 32,  3])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d545c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d545c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d705f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa81670d278> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 2.0214521452145213
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d546d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d898> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 2.0214521452145213
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fdd8> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 2.0214521452145213
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d546d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 20
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811dc39b0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 2.0214521452145213
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811ceaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811ceacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811ceab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811ceaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cea588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811ceaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d094e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cea5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811ceaba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70cc0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 2.0214521452145213
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d09eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d09eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d095f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d09a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d09eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d09d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d09eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d546d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d095c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d09a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811ceaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811ceae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d09eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811ceaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811ceaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cea470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d095f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d54860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d54b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d09b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d09eb8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c630> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 2.0214521452145213
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811ceafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811ceaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d701d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d701d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811ceafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811ceacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d701d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811ceaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811d49438> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 2.0214521452145213
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c5d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c5d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c5d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c5da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c5d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 17
Completed Iteration #15
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c5dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c5deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c5d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c5de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9ce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c5da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc55f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c5d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c702b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c5da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5128> 0.0 25
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 2.0214521452145213
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811dc3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d2f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811ceac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811ceafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d49470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811ceafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d8d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811cead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d70a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811c9ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c70128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811d70160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c70978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c70b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811cc5a58> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811d497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811ceafd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fa811c70c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fa811ceafd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fa811c9cc50> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 2.0214521452145213
initial coverage: 2.02145
time passed (minutes): 61.6027
iterations: 9
number of new inputs: 0
final coverage: 2.02145
total coverage increase: 0
