Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='CIFAR10', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 32, 32, 3), input_upper_limit=255, model='CIFAR_CNN', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['cifar10', 'CIFAR_CNN', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f8914e31f28>, tc2=<function tc2 at 0x7f8914e42048>, tc3=<function tc3 at 0x7f8914e42158>, tfc_threshold=9, time_period=3600, verbose=True)
initial coverage: 2.02145
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([ 1, 10, 10,  3])},
 {'lower_limits': array([ 0,  0, 10,  0]),
  'upper_limits': array([ 1, 10, 20,  3])},
 {'lower_limits': array([ 0,  0, 20,  0]),
  'upper_limits': array([ 1, 10, 32,  3])},
 {'lower_limits': array([ 0, 10,  0,  0]),
  'upper_limits': array([ 1, 20, 10,  3])},
 {'lower_limits': array([ 0, 10, 10,  0]),
  'upper_limits': array([ 1, 20, 20,  3])},
 {'lower_limits': array([ 0, 10, 20,  0]),
  'upper_limits': array([ 1, 20, 32,  3])},
 {'lower_limits': array([ 0, 20,  0,  0]),
  'upper_limits': array([ 1, 32, 10,  3])},
 {'lower_limits': array([ 0, 20, 10,  0]),
  'upper_limits': array([ 1, 32, 20,  3])},
 {'lower_limits': array([ 0, 20, 20,  0]),
  'upper_limits': array([ 1, 32, 32,  3])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888812f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880cab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880cae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880caf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812fd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f888869fd68> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 2.0214521452145213
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888865bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880ca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888120c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880823c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888865b080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 2.0214521452145213
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888865bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8888082e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 2.0214521452145213
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880b3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88c8175860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888865bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888865be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888863acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f88880b3898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 2.0214521452145213
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880820b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888809d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880829e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880824e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f888812f860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 2.0214521452145213
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880ca828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888120d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880cabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880caac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888120ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880e44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e44a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e49b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f88880e4a58> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 2.0214521452145213
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888055780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888055b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888055d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888055ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888055940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888055dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880cac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880555c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880cabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888055710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880550b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880554a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888055908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888865bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880caf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880ca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888055c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888055eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880caa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880caf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88880cac50> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 2.0214521452145213
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880ca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880ca550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880b3358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888035588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880e4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888812f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888082630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888035978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88880829b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888082828> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 2.0214521452145213
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888035390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f888809d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888035c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888035e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88807bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88807bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88807bb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88807bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88807bb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88807bbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807ca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88807bb2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88c81756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88880e4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88807bbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 21
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888120f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 22
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888082ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 23
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88807bbc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 24
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8888035ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88807bbf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88807ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8888035f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8888035cf8> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 2.0214521452145213
initial coverage: 2.02145
time passed (minutes): 61.6838
iterations: 9
number of new inputs: 0
final coverage: 2.02145
total coverage increase: 0
